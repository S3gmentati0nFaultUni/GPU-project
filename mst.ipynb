{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Y_SjlAhe6L-"
   },
   "source": [
    "# Setup section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pG2d4EbyeMga",
    "outputId": "94e94330-bf26-4199-be04-e0ab2e38b255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXvV86RSebx8",
    "outputId": "c5c5b1be-6919-45b0-f467-5fc8003a22c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  7 15:23:48 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6nEpZlmmeesZ",
    "outputId": "0aaf812b-77f4-423a-ccdf-5bcce0ceb40f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'GPUcomputing': No such file or directory\n",
      "Cloning into 'GPUcomputing'...\n",
      "remote: Enumerating objects: 766, done.\u001b[K\n",
      "remote: Counting objects: 100% (419/419), done.\u001b[K\n",
      "remote: Compressing objects: 100% (233/233), done.\u001b[K\n",
      "remote: Total 766 (delta 239), reused 340 (delta 174), pack-reused 347 (from 1)\u001b[K\n",
      "Receiving objects: 100% (766/766), 2.81 MiB | 10.14 MiB/s, done.\n",
      "Resolving deltas: 100% (396/396), done.\n"
     ]
    }
   ],
   "source": [
    "# Download repositories\n",
    "\n",
    "!sudo rm -dr GPUcomputing\n",
    "!git clone https://github.com/S3gmentati0nFault/GPUcomputing.git\n",
    "!mkdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjcFCeg2erat",
    "outputId": "ef58cb80-86b5-411e-dabf-8b1c7eb96a83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/GPUcomputing/utils/nvcc4jupyter-master\n",
      "/usr/bin/python3: No module named build\n",
      "Source files will be saved in \"./src\".\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd GPUcomputing/utils/nvcc4jupyter-master/\n",
    "!python3 -m build\n",
    "%load_ext nvcc4jupyter\n",
    "%cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NaynNOTreu9O",
    "outputId": "3de4246d-f45a-43d9-b01a-00b475df0e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CUDA Device Query (Runtime API) version (CUDART static linking)\n",
      "\n",
      "Detected 1 CUDA Capable device(s)\n",
      "\n",
      "Device 0: \"Tesla T4\"\n",
      "  CUDA Driver Version / Runtime Version          12.2 / 12.2\n",
      "  GPU arch name:                                 Turing\n",
      "  CUDA Capability Major/Minor version number:    7.5\n",
      "  Total amount of global memory:                 15102 MBytes (15835660288 bytes)\n",
      "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
      "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
      "  Memory Clock rate:                             5001 Mhz\n",
      "  Memory Bus Width:                              256-bit\n",
      "  L2 Cache Size:                                 4194304 bytes\n",
      "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
      "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
      "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
      "  Total amount of constant memory                65536 bytes\n",
      "  Total amount of shared memory per block        49152 bytes\n",
      "  Total number of registers available per block  65536\n",
      "  Warp size                                      32\n",
      "  Maximum number of threads per multiprocessor   1024\n",
      "  Maximum number of threads per block            1024\n",
      "  Max dimension size of a thread block (x,y,z)  (1024, 1024, 64)\n",
      "  Max dimension size of a grid size    (x,y,z)  (2147483647, 65535, 65535)\n",
      "  Maximum memory pitch                           2147483647 bytes\n",
      "  Texture alignment                              512 bytes\n",
      "  Concurrent copy and kernel execution           Yes with 3 copy engine(s)\n",
      "  Run time limit on kernels                      No\n",
      "  Integrated GPU sharing Host Memory             No\n",
      "  Support host page-locked memory mapping        Yes\n",
      "  Alignment requirement for Surfaces             Yes\n",
      "  Device has ECC support                         Enabled\n",
      "  Device supports Unified Addressing (UVA):      Yes\n",
      "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n"
     ]
    }
   ],
   "source": [
    "# DeviceQuery dell'attuale device (su Colab!)\n",
    "\n",
    "!nvcc -arch=sm_75 /content/GPUcomputing/utils/deviceQuery.cu -o deviceQuery\n",
    "!./deviceQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgIfmOPIA5hu",
    "outputId": "96ff5b86-c70f-46a8-eec9-f726a01e3186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  gdb libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n",
      "  libsource-highlight-common libsource-highlight4v5\n",
      "Suggested packages:\n",
      "  gdb-doc gdbserver valgrind-dbg valgrind-mpi kcachegrind alleyoop valkyrie\n",
      "The following NEW packages will be installed:\n",
      "  gdb libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n",
      "  libsource-highlight-common libsource-highlight4v5 valgrind\n",
      "0 upgraded, 9 newly installed, 0 to remove and 49 not upgraded.\n",
      "Need to get 32.3 MB of archives.\n",
      "After this operation, 111 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod-common all 0.186-1build1 [7,878 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libbabeltrace1 amd64 1.5.8-2build1 [160 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod1 amd64 0.186-1build1 [12.7 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libipt2 amd64 2.0.5-1 [46.4 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight-common all 3.1.9-4.1build2 [64.5 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight4v5 amd64 3.1.9-4.1build2 [207 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gdb amd64 12.1-0ubuntu1~22.04.2 [3,920 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc6-dbg amd64 2.35-0ubuntu3.8 [13.8 MB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 valgrind amd64 1:3.18.1-1ubuntu2 [14.1 MB]\n",
      "Fetched 32.3 MB in 5s (6,882 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package libdebuginfod-common.\n",
      "(Reading database ... 123623 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libdebuginfod-common_0.186-1build1_all.deb ...\n",
      "Unpacking libdebuginfod-common (0.186-1build1) ...\n",
      "Selecting previously unselected package libbabeltrace1:amd64.\n",
      "Preparing to unpack .../1-libbabeltrace1_1.5.8-2build1_amd64.deb ...\n",
      "Unpacking libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
      "Selecting previously unselected package libdebuginfod1:amd64.\n",
      "Preparing to unpack .../2-libdebuginfod1_0.186-1build1_amd64.deb ...\n",
      "Unpacking libdebuginfod1:amd64 (0.186-1build1) ...\n",
      "Selecting previously unselected package libipt2.\n",
      "Preparing to unpack .../3-libipt2_2.0.5-1_amd64.deb ...\n",
      "Unpacking libipt2 (2.0.5-1) ...\n",
      "Selecting previously unselected package libsource-highlight-common.\n",
      "Preparing to unpack .../4-libsource-highlight-common_3.1.9-4.1build2_all.deb ...\n",
      "Unpacking libsource-highlight-common (3.1.9-4.1build2) ...\n",
      "Selecting previously unselected package libsource-highlight4v5.\n",
      "Preparing to unpack .../5-libsource-highlight4v5_3.1.9-4.1build2_amd64.deb ...\n",
      "Unpacking libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
      "Selecting previously unselected package gdb.\n",
      "Preparing to unpack .../6-gdb_12.1-0ubuntu1~22.04.2_amd64.deb ...\n",
      "Unpacking gdb (12.1-0ubuntu1~22.04.2) ...\n",
      "Selecting previously unselected package libc6-dbg:amd64.\n",
      "Preparing to unpack .../7-libc6-dbg_2.35-0ubuntu3.8_amd64.deb ...\n",
      "Unpacking libc6-dbg:amd64 (2.35-0ubuntu3.8) ...\n",
      "Selecting previously unselected package valgrind.\n",
      "Preparing to unpack .../8-valgrind_1%3a3.18.1-1ubuntu2_amd64.deb ...\n",
      "Unpacking valgrind (1:3.18.1-1ubuntu2) ...\n",
      "Setting up libdebuginfod-common (0.186-1build1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\n",
      "Creating config file /etc/profile.d/debuginfod.sh with new version\n",
      "\n",
      "Creating config file /etc/profile.d/debuginfod.csh with new version\n",
      "Setting up libdebuginfod1:amd64 (0.186-1build1) ...\n",
      "Setting up libsource-highlight-common (3.1.9-4.1build2) ...\n",
      "Setting up libc6-dbg:amd64 (2.35-0ubuntu3.8) ...\n",
      "Setting up libipt2 (2.0.5-1) ...\n",
      "Setting up libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
      "Setting up valgrind (1:3.18.1-1ubuntu2) ...\n",
      "Setting up libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
      "Setting up gdb (12.1-0ubuntu1~22.04.2) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Installation of the Valgrind utility\n",
    "\n",
    "!sudo apt install valgrind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKn7gG7FdeYe"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDQeHkBtddXu"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"sharedMacros.h\" --group \"COMMON\"\n",
    "\n",
    "#ifndef SHARED_MACROS_H\n",
    "#define SHARED_MACROS_H\n",
    "\n",
    "#define DEBUGGING 0\n",
    "#define SIZE 20000\n",
    "#define MAX_WEIGHT 50000\n",
    "#define BLOCK_SIZE 1024\n",
    "#define PROBABILITY .0025\n",
    "#define TESTING 1\n",
    "#define TEST \"/content/tests/east.txt\"\n",
    "#define TEST_SIZE 3\n",
    "#define FIXED_SEED 51286\n",
    "#define LOGPATH \"/content/result_\"\n",
    "#define NO_VALUE -42\n",
    "#define TIME_ARRAY_SIZE 20\n",
    "\n",
    "#endif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQaog4xclkjc"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"readGraph.h\" --group \"COMMON\"\n",
    "\n",
    "#ifndef READ_GRAPH_H\n",
    "#define READ_GRAPH_H\n",
    "\n",
    "#include <fstream>\n",
    "#include <string>\n",
    "#include <iostream>\n",
    "#include <sstream>\n",
    "#include <vector>\n",
    "\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "struct Edge {\n",
    "    int src, dest, weight;\n",
    "\n",
    "    Edge() {\n",
    "        this->src = 0;\n",
    "        this->dest = 0;\n",
    "        this->weight = 0;\n",
    "    }\n",
    "\n",
    "    Edge(int src, int dest, int weight) {\n",
    "        this->src = src;\n",
    "        this->dest = dest;\n",
    "        this->weight = weight;\n",
    "    }\n",
    "\n",
    "    void print() {\n",
    "        cout << this->src << \" \" << this->dest << \" \" << this->weight << endl;\n",
    "    }\n",
    "};\n",
    "\n",
    "\n",
    "\n",
    "struct CPUGraph {\n",
    "    int nodeSize, edgeSize;\n",
    "    vector<Edge> edges;\n",
    "\n",
    "    CPUGraph(int nodeSize, int edgeSize) {\n",
    "        this->nodeSize = nodeSize;\n",
    "        this->edgeSize = edgeSize;\n",
    "        this->edges = vector<Edge>(edgeSize - 1);\n",
    "    }\n",
    "\n",
    "    void print() {\n",
    "        cout << this->nodeSize << \"   \" << this->edgeSize << endl;\n",
    "        for (int i = 0; i < this->edgeSize - 1; i++) {\n",
    "            this->edges[i].print();\n",
    "        }\n",
    "    }\n",
    "};\n",
    "\n",
    "Graph *initializeGraph(string line, bool GPUenabled);\n",
    "void readEdge(string line, vector<uint> *edges, vector<int> *weights, GraphStruct *str);\n",
    "void readEdgeCPU(string line, vector<Edge> *edges, uint pos);\n",
    "Graph *rgraph(string path, bool GPUenabled);\n",
    "CPUGraph *rgraphCPU(string path);\n",
    "\n",
    "#endif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iFiby1i5k729"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"readGraph.cu\" --group \"COMMON\"\n",
    "\n",
    "#include <fstream>\n",
    "#include <string>\n",
    "#include <iostream>\n",
    "#include <sstream>\n",
    "\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "#include \"readGraph.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "Graph *initializeGraph(string line, bool GPUenabled) {\n",
    "    stringstream ss(line);\n",
    "    string element;\n",
    "    uint nodeSize;\n",
    "    uint edgeSize;\n",
    "\n",
    "    ss >> element;\n",
    "    nodeSize = stoi(element);\n",
    "    ss >> element;\n",
    "    edgeSize = stoi(element);\n",
    "\n",
    "    Graph *graph = new Graph(nodeSize, edgeSize, GPUenabled);\n",
    "    return graph;\n",
    "}\n",
    "\n",
    "void readEdge(string line, vector<uint> *edges, vector<int> *weights, GraphStruct *str) {\n",
    "    stringstream ss(line);\n",
    "    string element;\n",
    "    node source, destination;\n",
    "    int weight;\n",
    "\n",
    "    ss >> element;\n",
    "    source = stoi(element) - 1;\n",
    "    ss >> element;\n",
    "    destination = stoi(element) - 1;\n",
    "    ss >> element;\n",
    "    weight = stoi(element);\n",
    "\n",
    "    str->cumDegs[source + 1]++;\n",
    "\n",
    "    edges[source].push_back(destination);\n",
    "    weights[source].push_back(weight);\n",
    "}\n",
    "\n",
    "void readEdgeCPU(string line, CPUGraph *graph, uint pos) {\n",
    "    stringstream ss(line);\n",
    "    string element;\n",
    "    node source, destination;\n",
    "    int weight;\n",
    "\n",
    "    ss >> element;\n",
    "    source = stoi(element) - 1;\n",
    "    ss >> element;\n",
    "    destination = stoi(element) - 1;\n",
    "    ss >> element;\n",
    "    weight = stoi(element);\n",
    "\n",
    "    graph->edges[pos] = Edge(source, destination, weight);\n",
    "}\n",
    "\n",
    "Graph *rgraph(string path, bool GPUenabled) {\n",
    "    ifstream inFile;\n",
    "    string line;\n",
    "    Graph *graph;\n",
    "\n",
    "    inFile.open(path);\n",
    "\n",
    "    if (!inFile) {\n",
    "        cout << \"Unable to open file\";\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    getline(inFile, line);\n",
    "    graph = initializeGraph(line, GPUenabled);\n",
    "    GraphStruct *str = graph->getStruct();\n",
    "    uint nodeSize = str->nodeSize;\n",
    "    uint edgeSize = str->edgeSize;\n",
    "    printf(\"%d\\t%d\\n\", nodeSize, edgeSize);\n",
    "    vector<uint> *edges = new vector<uint>[edgeSize];\n",
    "\t  vector<int> *weights = new vector<int>[edgeSize];\n",
    "\n",
    "    while (getline(inFile, line)) {\n",
    "        readEdge(line, edges, weights, str);\n",
    "    }\n",
    "\n",
    "    for (node i = 0; i < nodeSize; ++i) {\n",
    "        str->cumDegs[i + 1] += str->cumDegs[i];\n",
    "    }\n",
    "\n",
    "    for (node i = 0; i < nodeSize; ++i) {\n",
    "        memcpy((str->neighs + str->cumDegs[i]), edges[i].data(), sizeof(uint) * edges[i].size());\n",
    "\t\t    memcpy((str->weights + str->cumDegs[i]), weights[i].data(), sizeof(int) * weights[i].size());\n",
    "    }\n",
    "\n",
    "    printf(\"Closing the file and freeing memory\\n\");\n",
    "\n",
    "    inFile.close();\n",
    "    delete[] edges;\n",
    "    edges = NULL;\n",
    "    delete[] weights;\n",
    "    weights = NULL;\n",
    "\n",
    "/*\n",
    "    graph->print(true);\n",
    "    print_d <<<1, 1>>> (str, 1);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "*/\n",
    "    return graph;\n",
    "}\n",
    "\n",
    "CPUGraph *rgraphCPU(string path) {\n",
    "    ifstream inFile;\n",
    "    string line;\n",
    "\n",
    "    inFile.open(path);\n",
    "\n",
    "    if (!inFile) {\n",
    "        cout << \"Unable to open file\";\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    getline(inFile, line);\n",
    "    stringstream ss(line);\n",
    "    string element;\n",
    "    uint nodeSize;\n",
    "    uint edgeSize;\n",
    "\n",
    "    ss >> element;\n",
    "    nodeSize = stoi(element);\n",
    "    ss >> element;\n",
    "    edgeSize = stoi(element);\n",
    "    CPUGraph *graph = new CPUGraph(nodeSize, edgeSize);\n",
    "\n",
    "    uint i = 0;\n",
    "    while (getline(inFile, line)) {\n",
    "        readEdgeCPU(line, graph, i);\n",
    "        i++;\n",
    "    }\n",
    "\n",
    "    printf(\"Closing the file and freeing memory\\n\");\n",
    "\n",
    "    inFile.close();\n",
    "\n",
    "    return graph;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAlR4gVr3pnu",
    "outputId": "25d01f3c-d079-439f-b956-a9b8b129e677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deviceQuery  GPUcomputing  logs  result_cpu  result_gpuU  sample_data  src  tests.zip\n",
      "Archive:  tests.zip\n",
      "   creating: tests/\n",
      "  inflating: tests/lakes.txt         \n",
      "  inflating: tests/cal.txt           \n",
      "  inflating: tests/bay.txt           \n",
      "  inflating: tests/col.txt           \n",
      "  inflating: tests/small.txt         \n",
      "  inflating: tests/east.txt          \n",
      "  inflating: tests/fla.txt           \n",
      "  inflating: tests/ny.txt            \n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!unzip tests.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKk2Iwm4J90R"
   },
   "source": [
    "## GPU experimental approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ki-gfLXKB8l"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"mstGPUE.cu\" --group \"GPU\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "#include <fstream>\n",
    "#include <string>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <limits.h>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "#include \"../COMMON/readGraph.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "/*****\n",
    "* Device function that gets the degree of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The node we are interested in\n",
    "*****/\n",
    "__device__ node d_deg (GraphStruct *str, node i) {\n",
    "    return str->cumDegs[i + 1] - str->cumDegs[i];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the weight of a certain edge\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ int d_getWeight (GraphStruct *str, node i, uint offset) {\n",
    "    return str->weights[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the neighbour of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
    "    return str->neighs[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "__device__ uint d_getRoot (uint i, uint *d_flag, uint *d_colors) {\n",
    "    return max(0, d_flag[d_colors[i]]);\n",
    "}\n",
    "\n",
    "uint getRoot (uint i, uint *flag, uint *colors) {\n",
    "    return max(0, flag[colors[i]]);\n",
    "}\n",
    "\n",
    "\n",
    "__device__ uint binarySearch (uint *d_cumDegs, uint neighPosition, uint cumDegSize) {\n",
    "    uint left = 0;\n",
    "    uint right = cumDegSize - 1;\n",
    "\n",
    "    if (d_cumDegs[right] <= neighPosition) {\n",
    "        return right;\n",
    "    }\n",
    "\n",
    "    while (left <= right) {\n",
    "        uint mid = (left + right) / 2;\n",
    "        if (d_cumDegs[mid] <= neighPosition) {\n",
    "            left = mid + 1;\n",
    "        }\n",
    "        else {\n",
    "            right = mid - 1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (left == right) {\n",
    "        return left;\n",
    "    }\n",
    "    return left - 1;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that finds the cheapest edge in the adjacency list of every node\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "*****/\n",
    "__global__ void findCheapest (GraphStruct *str, uint *d_candidates) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // Initialize the minimum value\n",
    "    uint minimum = UINT_MAX;\n",
    "    int minimumWeight = INT_MAX;\n",
    "\n",
    "    // Find the cheapest edge in each adjacency list\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        int edgeWeight = d_getWeight(str, idx, i);\n",
    "        if (edgeWeight < minimumWeight) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "        else if (edgeWeight == minimumWeight &&\n",
    "                 d_getNeigh(str, idx, i) < d_getNeigh(str, idx, minimum)) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Update the return vector\n",
    "    d_candidates[idx] = minimum;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that removes the mirrored edges from the graph. A mirrored edge is\n",
    "* simply an edge pointing from the source to the destination and vice versa in\n",
    "* an oriented graph, the removal logic is to cut the edge with the lowest source\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "*****/\n",
    "__global__ void mirroredEdgesRemoval (GraphStruct *str, uint *d_candidates, unsigned long long int *d_weight) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint destinationOffset = d_candidates[idx];\n",
    "    node destination = d_getNeigh(str, idx, destinationOffset);\n",
    "    if (idx < destination) {\n",
    "        uint sourceOffset = d_candidates[destination];\n",
    "        node destinationNeigh = d_getNeigh(str, destination, sourceOffset);\n",
    "\n",
    "        // The vertex cannot be a candidate anymore because it would create a cycle\n",
    "        if (destinationNeigh == idx) {\n",
    "            d_candidates[idx] = UINT_MAX;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (d_candidates[idx] != UINT_MAX) {\n",
    "        atomicAdd(d_weight, d_getWeight(str, idx, d_candidates[idx]));\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/*****\n",
    "* Helper device function that recursively colors the nodes of the graph\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "* @param i - The index of the node to be colored\n",
    "* @param d_colors - The device-level array of colors assigned to each vertex\n",
    "*****/\n",
    "__device__ uint *d_recursiveColorationHelper (GraphStruct *str, uint *d_candidates, node i, uint *d_colors) {\n",
    "    uint color = UINT_MAX;\n",
    "    if (d_candidates[i] == UINT_MAX) {\n",
    "        color = i;\n",
    "    }\n",
    "    else {\n",
    "        node neigh = d_getNeigh(str, i, d_candidates[i]);\n",
    "        color = d_recursiveColorationHelper(str, d_candidates, neigh, d_colors)[neigh];\n",
    "    }\n",
    "\n",
    "    if (color != UINT_MAX) {\n",
    "        d_colors[i] = color;\n",
    "    }\n",
    "    return d_colors;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that recognizes the connected components in the graph and colors them\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree\n",
    "* @param d_colors - The device-level array of colors assigned to each vertex\n",
    "*****/\n",
    "__global__ void colorationProcess(GraphStruct *str, uint *d_candidates, uint *d_colors) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    d_recursiveColorationHelper(str, d_candidates, idx, d_colors);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void svIdentification (GraphStruct *str, uint *d_colors, uint *d_candidates, uint *d_flag) {\n",
    "    // Initialize one thread per node\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    if (d_colors[idx] == idx) {\n",
    "        d_flag[idx] = 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "//*** SCAN FUNCTIONS ***//\n",
    "\n",
    "__global__ void prescan(uint *g_odata, uint *g_idata, uint *aux, int n, int smemSize)\n",
    "{\n",
    "  extern __shared__ int temp[];// allocated on invocation\n",
    "  int thid = threadIdx.x;\n",
    "  int offset = 1;\n",
    "  int idx = blockIdx.x * blockDim.x + thid;\n",
    "\n",
    "  // load input into shared memory\n",
    "  temp[2 * thid] =  (2 * idx < n) ? g_idata[2 * idx] : 0;\n",
    "  temp[2 * thid + 1] = (2 * idx + 1 < n) ? g_idata[2 * idx + 1] : 0;\n",
    "  //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "      //printf(\"UPSWEEP\\n\");\n",
    "  //}\n",
    "\n",
    "  //printf(\"%d >> left: %d   right: %d\\n\", thid, temp[2 * thid], temp[2 * thid + 1]);\n",
    "\n",
    "  for (int d =smemSize>>1; d > 0; d >>= 1) // build sum in place up the tree\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        temp[bi] += temp[ai];\n",
    "      }\n",
    "    }\n",
    "    offset *= 2;\n",
    "  }\n",
    "\n",
    "  //printf(\"%d >> right: %d   left: %d\\n\", thid, temp[2 * thid], temp[2 * thid + 1]);\n",
    "\n",
    "  if (thid == 0)\n",
    "  {\n",
    "    aux[blockIdx.x] = temp[smemSize - 1];\n",
    "    temp[smemSize - 1] = 0;\n",
    "  }\n",
    "\n",
    "  //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "      //printf(\"DOWNSWEEP\\n\");\n",
    "  //}\n",
    "\n",
    "  for (int d = 1; d < smemSize; d *= 2) // traverse down tree & build scan\n",
    "  {\n",
    "      offset >>= 1;\n",
    "    __syncthreads();\n",
    "\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        //printf(\"%d >> ai: %d   bi: %d   temp[ai]: %d   temp[bi]: %d\\n\", thid, ai, bi, temp[ai], temp[bi]);\n",
    "        int t = temp[ai];\n",
    "        temp[ai] = temp[bi];\n",
    "        temp[bi] += t;\n",
    "      }\n",
    "    }\n",
    "    //if (2 * idx == n - 1) {\n",
    "        //printf(\"temp[n - 1]: %d\\n\", temp[2 * thid]);\n",
    "    //}\n",
    "    //if (2 * idx + 1 == n - 1) {\n",
    "        //printf(\"temp[n - 1]: %d\\n\", temp[2 * thid + 1]);\n",
    "    //}\n",
    "  }\n",
    "\n",
    "  //printf(\"%d >> right: %d   left: %d\\n\", thid, temp[2 * thid], temp[2 * thid + 1]);\n",
    "\n",
    "\n",
    "  __syncthreads();\n",
    "  if (idx <= (n / 2)) {\n",
    "      g_odata[2*idx] = temp[2*thid]; // write results to device memory\n",
    "      g_odata[2*idx+1] = temp[2*thid+1];\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "void cpuScan(uint *array, int start, int end) {\n",
    "    if (end - start <= 1) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    int temp = array[start + 1];\n",
    "    array[start + 1] = array[start];\n",
    "    array[start] = 0;\n",
    "\n",
    "    for (uint i = start + 1; i < end - 1; i++) {\n",
    "        int sum = array[i] + temp;\n",
    "        temp = array[i + 1];\n",
    "        array[i + 1] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void cfinal_sum(uint *g_odata, uint *aux, uint n)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "  if (blockIdx.x == 0 || 2 * idx >= n) {\n",
    "      return;\n",
    "  }\n",
    "\n",
    "  //printf(\"%d: ls - %d  rs - %d  aux - %d\\n\", idx, g_odata[2 * idx], g_odata[2 * idx + 1], aux[blockIdx.x - 1]);\n",
    "\n",
    "  uint sum = 0;\n",
    "  for (uint i = 0; i < blockIdx.x; ++i) {\n",
    "      sum += aux[i];\n",
    "  }\n",
    "\n",
    "  if (2 * idx == n - 1) {\n",
    "      g_odata[2 * idx] += sum;\n",
    "      return;\n",
    "  }\n",
    "\n",
    "  g_odata[2 * idx] += sum;\n",
    "  g_odata[2 * idx + 1] += sum;\n",
    "}\n",
    "\n",
    "//****************//\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void cumulatedDegreeUpdateCopy(GraphStruct *str, uint *d_cumDegs, uint *d_colors, uint *d_flag) {\n",
    "    // One thread per edge\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the thread is out of bounds returns immediately\n",
    "    if (idx >= str->edgeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // The thread is the destination of the considered edge\n",
    "    node destination = str->neighs[idx];\n",
    "    uint destColor = d_colors[destination];\n",
    "\n",
    "    // I look for the origin of the edge using the cumulated degrees array\n",
    "    uint origin = binarySearch(str->cumDegs, idx, str->nodeSize + 1);\n",
    "    uint originColor = d_colors[origin];\n",
    "\n",
    "    // Find the roots => the super-vertices\n",
    "    node oSuperVertex = d_getRoot(origin, d_flag, d_colors);\n",
    "\n",
    "    //printf(\"%d(%d)   destination: %d(%d)   origin: %d(%d)\\n\", idx, destination, destColor, origin, originColor);\n",
    "\n",
    "    // If the colors of the two vertices are different then they belong to different components\n",
    "    if (destColor != originColor) {\n",
    "        atomicAdd(&(d_cumDegs[oSuperVertex]), 1);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void graphContractionCopy(GraphStruct *str, uint *d_colors, uint *d_flag,\n",
    "                                 uint *d_cumDegs, node *d_newNeighs, uint *d_newWeights) {\n",
    "    // One index per edge\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->edgeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // The index is the destination of the considered edge\n",
    "    node destination = str->neighs[idx];\n",
    "    uint destColor = d_colors[destination];\n",
    "\n",
    "    // I look for the origin of the edge using the cumulated degrees array\n",
    "    uint origin = binarySearch(str->cumDegs, idx, str->nodeSize + 1);\n",
    "    uint originColor = d_colors[origin];\n",
    "\n",
    "    // Find the roots => the super-vertices\n",
    "    node oSuperVertex = d_getRoot(origin, d_flag, d_colors);\n",
    "    node dSuperVertex = d_getRoot(destination, d_flag, d_colors);\n",
    "\n",
    "    //printf(\"%d(%d)   destination: %d(%d)   origin: %d(%d)\\n\", idx, destination, destColor, origin, originColor);\n",
    "\n",
    "    // If the colors of the two vertices are different then they belong to different components\n",
    "    if (destColor != originColor) {\n",
    "        // I take the weight\n",
    "        int weight = str->weights[idx];\n",
    "\n",
    "        // Compute the comulatedDegrees increment\n",
    "        uint position = atomicAdd(&(d_cumDegs[oSuperVertex]), 1);\n",
    "\n",
    "        // Update the vectors\n",
    "        d_newNeighs[position] = dSuperVertex;\n",
    "        d_newWeights[position] = weight;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main () {\n",
    "    // Generation of a random graph\n",
    "    std::random_device rd;\n",
    "    std::default_random_engine eng(FIXED_SEED);\n",
    "    uint maxWeight = MAX_WEIGHT;\n",
    "    float prob = PROBABILITY;\n",
    "    bool GPUEnabled = 1;\n",
    "    Graph *graphPointer;\n",
    "\n",
    "    if (TESTING) {\n",
    "        string path(TEST);\n",
    "        printf(\"Generating graph from file\\n\");\n",
    "        graphPointer = rgraph(path, true);\n",
    "    }\n",
    "    else {\n",
    "        graphPointer = new Graph(SIZE, GPUEnabled);\n",
    "        graphPointer->randGraph(prob, true, maxWeight, eng);\n",
    "\n",
    "        if (!graphPointer->isConnected()) {\n",
    "            cout << \"The graph is not connected\" << endl;\n",
    "            return -1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    uint iterations = 0;\n",
    "\n",
    "\n",
    "    // Configuration of the GPU kernel\n",
    "    uint blockDim = BLOCK_SIZE;\n",
    "    uint *candidates;\n",
    "\n",
    "\n",
    "    // Events to measure time\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    float milliseconds;\n",
    "    float spliTime = 0;\n",
    "    float totalTime = 0;\n",
    "\n",
    "\n",
    "    // Variables calculating the MST weight\n",
    "    unsigned long long int mstWeight = 0;\n",
    "    unsigned long long int *d_mstWeight;\n",
    "    CHECK(cudaMalloc((void **)&d_mstWeight, sizeof(unsigned long long int)));\n",
    "    CHECK(cudaMemcpy(d_mstWeight, &mstWeight, sizeof(unsigned long long int), cudaMemcpyHostToDevice));\n",
    "\n",
    "\n",
    "    // Main block of the algorithm\n",
    "    while (graphPointer->getStruct()->nodeSize > 1) {\n",
    "        // Initialization of the variables associated with the graph\n",
    "        GraphStruct *str = graphPointer->getStruct();\n",
    "        uint size = str->nodeSize;\n",
    "        uint edgeSize = str->edgeSize;\n",
    "        cout << \"Processing a graph of size: \" << size << \" with \" << edgeSize << \" edges.\\n\\n\";\n",
    "        uint gridDim = (size + blockDim - 1) / blockDim;\n",
    "        if (DEBUGGING && size < 15 && str->edgeSize < 100) {\n",
    "            graphPointer->print(true);\n",
    "            print_d<<<1, 1>>>(str, 1);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "        }\n",
    "        candidates = new uint[size];\n",
    "\n",
    "        // First setp of the algorithm\n",
    "        uint *d_candidates;\n",
    "        CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
    "\n",
    "        uint searchGrid = (edgeSize + blockDim - 1) / blockDim;\n",
    "        cout << \"Launching kernel FIND CHEAPEST -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        findCheapest<<<gridDim, blockDim>>>(str, d_candidates);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // ~Debugging~ print the cheapest edge for every vertex\n",
    "        if (DEBUGGING && size < 15) {\n",
    "            cout << \"The cheapest edge for every vertex\" << endl;\n",
    "            CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"node (\" << i << \") -> \" << str->getNeigh(i, candidates[i]) << \"(\"\n",
    "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
    "            }\n",
    "            cout << \"\\n\\n\\n\";\n",
    "        }\n",
    "        /*******************/\n",
    "\n",
    "\n",
    "\n",
    "        // Second step of the algorithm\n",
    "        cout << \"Launching kernel MIRRORED EDGES REMOVAL -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        mirroredEdgesRemoval<<<gridDim, blockDim>>>(str, d_candidates, d_mstWeight);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        CHECK(cudaMemcpy(&mstWeight, d_mstWeight, sizeof(unsigned long long int), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "        /********************/\n",
    "\n",
    "        // ~Debugging~ print the cheapest edge for every vertex update\n",
    "        if (DEBUGGING && size < 15) {\n",
    "            cout << \"Update of the cheapest edge for every vertex\" << endl;\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"node (\" << i << \") -> \";\n",
    "                if (candidates[i] != UINT_MAX) {\n",
    "                    cout << str->getNeigh(i, candidates[i]) << \"(\"\n",
    "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
    "                }\n",
    "                else {\n",
    "                    cout << \"NULL\" << endl;\n",
    "                }\n",
    "            }\n",
    "            printf (\"%llu\\n\", mstWeight);\n",
    "        }\n",
    "        /*****************************/\n",
    "\n",
    "        cout << \"The MST weight at the end of iteration \" << iterations + 1 << \" is: \" << mstWeight << endl;\n",
    "\n",
    "\n",
    "\n",
    "        // Third step of the algorithm\n",
    "        cout << \"Launching kernel COLORATION PROCESS -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "\n",
    "        // Initialize the color array\n",
    "        uint *colors = new uint[size];\n",
    "        uint *d_colors;\n",
    "        CHECK(cudaMalloc((void**)&d_colors, size * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_colors, UINT_MAX, size * sizeof(uint)));\n",
    "        /**************************************************/\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        colorationProcess<<<gridDim, blockDim>>>(str, d_candidates, d_colors);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(colors, d_colors, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"The coloration procedure took: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        // Print the coloring\n",
    "        if (DEBUGGING) {\n",
    "            uint *checkColoring = new uint[size];\n",
    "\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                checkColoring[i] = 0;\n",
    "            }\n",
    "\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                checkColoring[colors[i]]++;\n",
    "            }\n",
    "\n",
    "            uint nonZeroColors = 0;\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                if (checkColoring[i] != 0) {\n",
    "                    nonZeroColors++;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            cout << \"There is a total of \" << nonZeroColors << \" colors\" << endl;\n",
    "\n",
    "            cout << \"\\n\\n\\n\";\n",
    "        }\n",
    "        /*******************/\n",
    "\n",
    "        /**\n",
    "         * If the coloring coming out of the last kernel contains only one color\n",
    "         * then it means that the edge added in the last step was the one needed\n",
    "         * to merge the partial trees\n",
    "         **/\n",
    "        uint color = colors[0];\n",
    "        bool uniqueColor = true;\n",
    "        for (uint i = 1; i < size; i++) {\n",
    "            if (colors[i] != color) {\n",
    "                uniqueColor = false;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "        if (uniqueColor) {\n",
    "            cout << \"THE CALCULATION OF THE MST IS COMPLETE\\n\";\n",
    "            cout << \"THE MST WEIGHT IS: \" << mstWeight << endl;\n",
    "            printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
    "\n",
    "            // Cuda event dealloc\n",
    "            CHECK(cudaEventDestroy(start));\n",
    "            CHECK(cudaEventDestroy(stop));\n",
    "\n",
    "            // Cuda memory deallocation\n",
    "            CHECK(cudaFree(d_candidates));\n",
    "            CHECK(cudaFree(d_colors));\n",
    "            CHECK(cudaFree(d_mstWeight));\n",
    "\n",
    "            // Host memory deallocation\n",
    "            delete[] candidates;\n",
    "            delete[] colors;\n",
    "            delete graphPointer;\n",
    "\n",
    "            // Logging results\n",
    "            string path(LOGPATH + string(\"gpuE\"));\n",
    "\n",
    "            ofstream logfile(path, ios_base::app);\n",
    "\n",
    "            if (logfile.is_open()){\n",
    "                cout << \"Writing to file \" << path << endl;\n",
    "                logfile << mstWeight << \"\\n\" << totalTime << \"\\n\";\n",
    "                logfile.close();\n",
    "            }\n",
    "            else {\n",
    "                cout << \"Unable to open file\";\n",
    "            }\n",
    "\n",
    "            return 0;\n",
    "        }\n",
    "        /***********/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Fourth step of the algorithm\n",
    "        cout << \"Doing a round of scan on the flag vector, size: \" << size << endl;\n",
    "        uint *flag = new uint[size];\n",
    "        uint *cFlag = new uint[size];\n",
    "        uint *d_flag, *d_ogFlag;\n",
    "\n",
    "        // setup di d_ogFlag\n",
    "        CHECK(cudaMalloc((void**)&d_ogFlag, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_ogFlag, 0, (size) * sizeof(uint)));\n",
    "        cudaEventRecord(start);\n",
    "        svIdentification <<< gridDim, blockDim >>> (str, d_colors, d_candidates, d_ogFlag);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Building the flag array took:   %.5f seconds\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            CHECK(cudaMemcpy(cFlag, d_ogFlag, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        }\n",
    "\n",
    "        // SMEM kernel configuration\n",
    "        uint smemSize = 2 * blockDim;\n",
    "        uint smem = smemSize * sizeof(uint);\n",
    "        uint numSmemBlock = (size + smemSize - 1) / smemSize;\n",
    "\n",
    "        // Setup the auxiliary array\n",
    "        uint *aux, *d_aux;\n",
    "        aux = new uint[numSmemBlock];\n",
    "        CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_aux, 0, (numSmemBlock) * sizeof(uint)));\n",
    "\n",
    "        // Setup of the d_flag array\n",
    "        CHECK(cudaMalloc((void**)&d_flag, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_flag, 0, (size) * sizeof(uint)));\n",
    "\n",
    "        printf(\"prescan procedure on the flag array of size: %d ...\\n\", size);\n",
    "        cudaEventRecord(start);\n",
    "        prescan <<<  numSmemBlock, blockDim, smem >>> (d_flag, d_ogFlag, d_aux, size, smemSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"The first prescan procedure took:   %.5f seconds\\n\", spliTime);\n",
    "\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        // Put everything together\n",
    "        printf(\"final summation procedure...\\n\");\n",
    "        cudaEventRecord(start);\n",
    "        cfinal_sum <<< gridDim, blockDim >>> (d_flag, d_aux, size);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"The final summation procedure took:   %.5f seconds\\n\\n\", spliTime);\n",
    "\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        CHECK(cudaMemcpy(flag, d_flag, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            cpuScan(cFlag, 0, size);\n",
    "\n",
    "            for (uint i = 0; i < size - 1; i++) {\n",
    "                if (cFlag[i] != flag[i]) {\n",
    "                    cout << \"I due array sono diversi in posizione \" << i << \"   \" << cFlag[i] << \"   \" << flag[i] << endl;\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            delete[] cFlag;\n",
    "        }\n",
    "        cout << \"The contracted graph will contain \" << flag[size - 1] << \" supervertices\\n\\n\" << endl;\n",
    "        // Spring Cleaning\n",
    "        delete[] (aux);\n",
    "        CHECK(cudaFree(d_aux));\n",
    "        CHECK(cudaFree(d_ogFlag));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Fifth step of the algorithm\n",
    "\n",
    "        // Allocating resources for the new cumulated degrees array\n",
    "        uint newNodeSize = flag[size - 1];\n",
    "        uint cumDegSize = newNodeSize + 1;\n",
    "        uint *cumDegs = new uint[cumDegSize];\n",
    "        uint *d_cumDegs;\n",
    "        CHECK(cudaMalloc((void**)&d_cumDegs, (cumDegSize) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
    "        /***********************************/\n",
    "\n",
    "        cout << \"Launching kernel CUMULATED DEGREE UPDATE -- (\" << blockDim << \", 1, 1) -- (\" << searchGrid << \", 1, 1)\" << endl;\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        cumulatedDegreeUpdateCopy<<<searchGrid, blockDim>>>(str, d_cumDegs, d_colors, d_flag);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Doing the computation of the cumulated degrees took: %.5f seconds\\n\\n\", spliTime);\n",
    "        CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Perform another prefix sum on the cumDegrees array\n",
    "        aux = new uint[numSmemBlock];\n",
    "        CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_aux, 0, (numSmemBlock) * sizeof(uint)));\n",
    "\n",
    "        uint *cCumDegs;\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            cCumDegs = new uint[cumDegSize];\n",
    "            for (uint i = 0; i < cumDegSize; i++) {\n",
    "                cCumDegs[i] = cumDegs[i];\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Setup d_ogCumDegs\n",
    "        uint *d_ogCumDegs;\n",
    "        CHECK(cudaMalloc((void **) &d_ogCumDegs, cumDegSize * sizeof(uint)));\n",
    "        CHECK(cudaMemcpy(d_ogCumDegs, cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "        printf(\"prescan procedure on the cumDegs array of size: %d ...\\n\", size);\n",
    "        cudaEventRecord(start);\n",
    "        prescan <<<  numSmemBlock, blockDim, smem >>> (d_cumDegs, d_ogCumDegs, d_aux, cumDegSize, smemSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"The first prescan procedure took:   %.5f seconds\\n\", spliTime);\n",
    "\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        // Put everything together\n",
    "        printf(\"final summation procedure...\\n\");\n",
    "        cudaEventRecord(start);\n",
    "        cfinal_sum <<< gridDim, blockDim >>> (d_cumDegs, d_aux, cumDegSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"The final summation procedure took:   %.5f seconds\\n\\n\", spliTime);\n",
    "\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        CHECK(cudaMemcpy(cumDegs, d_cumDegs, cumDegSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        if (DEBUGGING) {\n",
    "            cpuScan(cCumDegs, 0, cumDegSize);\n",
    "\n",
    "            for (uint i = 0; i < cumDegSize - 1; i++) {\n",
    "                if (cCumDegs[i] != cumDegs[i]) {\n",
    "                    cout << \"I due array sono diversi in posizione \" << i << endl;\n",
    "                    cout << cCumDegs[i] << \"   \" << cumDegs[i];\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        cout << \"The contracted graph will contain \" << cumDegs[cumDegSize - 1] << \" edges\" << endl;\n",
    "        cout << \"The old graph structure contained \" << str->edgeSize << \" edges\\n\\n\" << endl;\n",
    "\n",
    "        // Spring cleaning\n",
    "        free(aux);\n",
    "        CHECK(cudaFree(d_aux));\n",
    "        CHECK(cudaFree(d_ogCumDegs));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Allocating space for the arrays in the newly contracted graph\n",
    "        uint newEdgeSize = cumDegs[cumDegSize - 1];\n",
    "        node *newNeighs = new node[newEdgeSize];\n",
    "        uint *newWeights = new uint[newEdgeSize];\n",
    "\n",
    "        uint *d_newNeighs, *d_newWeights;\n",
    "        CHECK(cudaMalloc((void **)&d_newNeighs, newEdgeSize * sizeof(node)));\n",
    "        CHECK(cudaMalloc((void **)&d_newWeights, newEdgeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_newNeighs, 0, newEdgeSize * sizeof(node)));\n",
    "        CHECK(cudaMemset(d_newWeights, 0, newEdgeSize * sizeof(uint)));\n",
    "\n",
    "        cout << \"Launching kernel GRAPH CONSTRUCTION -- (\" << blockDim << \", 1, 1) -- (\" << searchGrid << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        graphContractionCopy<<<searchGrid, blockDim>>>(str, d_colors, d_flag, d_cumDegs, d_newNeighs, d_newWeights);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        printf(\"The construction of the new neighbour and weight arrays took: %.5f seconds\\n\\n\", milliseconds/1000);\n",
    "        spliTime += milliseconds / 1000.0;\n",
    "        CHECK(cudaMemcpy(newNeighs, d_newNeighs, newEdgeSize * sizeof(node), cudaMemcpyDeviceToHost));\n",
    "        CHECK(cudaMemcpy(newWeights, d_newWeights, newEdgeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            node *checkNewNeighs = new node[newEdgeSize];\n",
    "            uint *checkNewWeights = new uint[newEdgeSize];\n",
    "            // Copy the contents of cumDegs into a new array\n",
    "            for (uint i = 0; i < cumDegSize; i++) {\n",
    "                cCumDegs[i] = cumDegs[i];\n",
    "            }\n",
    "\n",
    "            cudaEventRecord(start);\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                uint color = colors[i];\n",
    "                node superVertex = getRoot(i, flag, colors);\n",
    "\n",
    "                for (uint j = 0; j < str->deg(i); j++) {\n",
    "                    node neigh = str->getNeigh(i, j);\n",
    "                    uint neighColor = colors[neigh];\n",
    "\n",
    "                    if (color != neighColor) {\n",
    "                        int weight = str->getWeight(i, j);\n",
    "                        uint position = cCumDegs[superVertex];\n",
    "                        checkNewNeighs[position] = getRoot(neigh, flag, colors);\n",
    "                        checkNewWeights[position] = weight;\n",
    "                        cCumDegs[superVertex]++;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            //for (uint i = 0; i < newEdgeSize; i++) {\n",
    "                //if (newNeighs[i] != checkNewNeighs[i] || newWeights[i] != checkNewWeights[i]) {\n",
    "                    //cout << \"I due array sono diversi in posizione \" << i << endl;\n",
    "                    //return -1;\n",
    "                //}\n",
    "            //}\n",
    "\n",
    "            delete[] cCumDegs;\n",
    "        }\n",
    "\n",
    "        // Reconstructing the graph\n",
    "        graphPointer->copyConstructor(newNodeSize, newEdgeSize, newNeighs, newWeights, cumDegs);\n",
    "\n",
    "        //graphPointer->print(true);\n",
    "\n",
    "        printf(\"----------------------------------\\n\\n\");\n",
    "        /***********************************************/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Updating the iteration information\n",
    "        totalTime += spliTime;\n",
    "        iterations++;\n",
    "        /*****************************************/\n",
    "\n",
    "\n",
    "        // Cuda memory deallocation\n",
    "        CHECK(cudaFree(d_candidates));\n",
    "        CHECK(cudaFree(d_colors));\n",
    "        CHECK(cudaFree(d_flag));\n",
    "        CHECK(cudaFree(d_cumDegs));\n",
    "        CHECK(cudaFree(d_newNeighs));\n",
    "        CHECK(cudaFree(d_newWeights));\n",
    "        /****************************/\n",
    "\n",
    "        // Host memory deallocation\n",
    "        delete[] candidates;\n",
    "        delete[] colors;\n",
    "        delete[] flag;\n",
    "        delete[] cumDegs;\n",
    "        delete[] newNeighs;\n",
    "        delete[] newWeights;\n",
    "        /******************/\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDwnHcvWKIo_",
    "outputId": "3eb8fca2-f5f0-472e-913d-d1e6103610c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptxas warning : Stack size for entry function '_Z17colorationProcessP11GraphStructPjS1_' cannot be statically determined\n",
      "Generating graph from file\n",
      "3598623\t8778114\n",
      "Closing the file and freeing memory\n",
      "Processing a graph of size: 3598623 with 8778114 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (3515, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.03318 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (3515, 1, 1)\n",
      "Removing the mirrored edges required: 0.00392 seconds\n",
      "\n",
      "The MST weight at the end of iteration 1 is: 3600949096\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (3515, 1, 1)\n",
      "The coloration procedure took: 0.00854 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 3598623\n",
      "Building the flag array took:   0.00854 seconds\n",
      "prescan procedure on the flag array of size: 3598623 ...\n",
      "The first prescan procedure took:   0.00080 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00447 seconds\n",
      "\n",
      "The contracted graph will contain 1062155 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (8573, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00269 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 3598623 ...\n",
      "The first prescan procedure took:   0.00075 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00045 seconds\n",
      "\n",
      "The contracted graph will contain 3574296 edges\n",
      "The old graph structure contained 8778114 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (8573, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00336 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 1062155 with 3574296 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1038, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.01209 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1038, 1, 1)\n",
      "Removing the mirrored edges required: 0.00118 seconds\n",
      "\n",
      "The MST weight at the end of iteration 2 is: 5382536444\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1038, 1, 1)\n",
      "The coloration procedure took: 0.00142 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 1062155\n",
      "Building the flag array took:   0.00142 seconds\n",
      "prescan procedure on the flag array of size: 1062155 ...\n",
      "The first prescan procedure took:   0.00025 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00044 seconds\n",
      "\n",
      "The contracted graph will contain 306137 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (3491, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00104 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 1062155 ...\n",
      "The first prescan procedure took:   0.00023 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00007 seconds\n",
      "\n",
      "The contracted graph will contain 1687288 edges\n",
      "The old graph structure contained 3574296 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (3491, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00134 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 306137 with 1687288 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (299, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00371 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (299, 1, 1)\n",
      "Removing the mirrored edges required: 0.00037 seconds\n",
      "\n",
      "The MST weight at the end of iteration 3 is: 6129604033\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (299, 1, 1)\n",
      "The coloration procedure took: 0.00044 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 306137\n",
      "Building the flag array took:   0.00044 seconds\n",
      "prescan procedure on the flag array of size: 306137 ...\n",
      "The first prescan procedure took:   0.00008 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00006 seconds\n",
      "\n",
      "The contracted graph will contain 81798 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1648, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00047 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 306137 ...\n",
      "The first prescan procedure took:   0.00008 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00002 seconds\n",
      "\n",
      "The contracted graph will contain 780508 edges\n",
      "The old graph structure contained 1687288 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1648, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00125 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 81798 with 780508 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (80, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00172 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (80, 1, 1)\n",
      "Removing the mirrored edges required: 0.00012 seconds\n",
      "\n",
      "The MST weight at the end of iteration 4 is: 6388025914\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (80, 1, 1)\n",
      "The coloration procedure took: 0.00014 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 81798\n",
      "Building the flag array took:   0.00014 seconds\n",
      "prescan procedure on the flag array of size: 81798 ...\n",
      "The first prescan procedure took:   0.00003 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00002 seconds\n",
      "\n",
      "The contracted graph will contain 20199 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (763, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00022 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 81798 ...\n",
      "The first prescan procedure took:   0.00003 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 337754 edges\n",
      "The old graph structure contained 780508 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (763, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00038 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 20199 with 337754 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (20, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00097 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (20, 1, 1)\n",
      "Removing the mirrored edges required: 0.00004 seconds\n",
      "\n",
      "The MST weight at the end of iteration 5 is: 6464523609\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (20, 1, 1)\n",
      "The coloration procedure took: 0.00004 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 20199\n",
      "Building the flag array took:   0.00004 seconds\n",
      "prescan procedure on the flag array of size: 20199 ...\n",
      "The first prescan procedure took:   0.00003 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00002 seconds\n",
      "\n",
      "The contracted graph will contain 4695 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (330, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00010 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 20199 ...\n",
      "The first prescan procedure took:   0.00003 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 140182 edges\n",
      "The old graph structure contained 337754 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (330, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00023 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 4695 with 140182 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (5, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00065 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (5, 1, 1)\n",
      "Removing the mirrored edges required: 0.00003 seconds\n",
      "\n",
      "The MST weight at the end of iteration 6 is: 6485101575\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (5, 1, 1)\n",
      "The coloration procedure took: 0.00003 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 4695\n",
      "Building the flag array took:   0.00003 seconds\n",
      "prescan procedure on the flag array of size: 4695 ...\n",
      "The first prescan procedure took:   0.00003 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 1070 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (137, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00006 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 4695 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 57826 edges\n",
      "The old graph structure contained 140182 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (137, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00028 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 1070 with 57826 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (2, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00048 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (2, 1, 1)\n",
      "Removing the mirrored edges required: 0.00003 seconds\n",
      "\n",
      "The MST weight at the end of iteration 7 is: 6490534969\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (2, 1, 1)\n",
      "The coloration procedure took: 0.00004 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 1070\n",
      "Building the flag array took:   0.00004 seconds\n",
      "prescan procedure on the flag array of size: 1070 ...\n",
      "The first prescan procedure took:   0.00003 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 226 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (57, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00003 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 1070 ...\n",
      "The first prescan procedure took:   0.00003 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 23814 edges\n",
      "The old graph structure contained 57826 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (57, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00013 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 226 with 23814 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00042 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 8 is: 6491801063\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "The coloration procedure took: 0.00003 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 226\n",
      "Building the flag array took:   0.00003 seconds\n",
      "prescan procedure on the flag array of size: 226 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00002 seconds\n",
      "\n",
      "The contracted graph will contain 42 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (24, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00003 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 226 ...\n",
      "The first prescan procedure took:   0.00003 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 7840 edges\n",
      "The old graph structure contained 23814 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (24, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00012 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 42 with 7840 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00034 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 9 is: 6492055731\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "The coloration procedure took: 0.00002 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 42\n",
      "Building the flag array took:   0.00002 seconds\n",
      "prescan procedure on the flag array of size: 42 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 9 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (8, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00004 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 42 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 3054 edges\n",
      "The old graph structure contained 7840 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (8, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00011 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 9 with 3054 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00034 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 10 is: 6492111754\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "The coloration procedure took: 0.00002 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 9\n",
      "Building the flag array took:   0.00002 seconds\n",
      "prescan procedure on the flag array of size: 9 ...\n",
      "The first prescan procedure took:   0.00003 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 2 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (3, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00002 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 9 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 104 edges\n",
      "The old graph structure contained 3054 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (3, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00011 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 2 with 104 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00018 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 11 is: 6492121041\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "The coloration procedure took: 0.00002 seconds\n",
      "\n",
      "THE CALCULATION OF THE MST IS COMPLETE\n",
      "THE MST WEIGHT IS: 6492121041\n",
      "Total elapsed time: 0.09754 seconds\n",
      "\n",
      "Writing to file /content/result_gpuE\n"
     ]
    }
   ],
   "source": [
    "# Compilazione ed esecuzione\n",
    "# GPU-e\n",
    "!nvcc -arch=sm_75 GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/COMMON/readGraph.cu src/GPU/mstGPUE.cu -o mstGPUE\n",
    "!./mstGPUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylQrjuiVVrFZ",
    "outputId": "1e69f0b9-dcda-4971-b0d5-e98890ae4399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==47614== NVPROF is profiling process 47614, command: ./mstGPUE\n",
      "==47614== Profiling application: ./mstGPUE\n",
      "==47614== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   51.93%  59.429ms        11  5.4026ms  150.21us  33.172ms  findCheapest(GraphStruct*, unsigned int*)\n",
      "                   19.19%  21.961ms        83  264.59us  1.5680us  2.9845ms  [CUDA memcpy DtoH]\n",
      "                    5.93%  6.7910ms        11  617.36us  4.6400us  4.7082ms  colorationProcess(GraphStruct*, unsigned int*, unsigned int*)\n",
      "                    5.72%  6.5421ms        10  654.21us  99.199us  3.2898ms  graphContractionCopy(GraphStruct*, unsigned int*, unsigned int*, unsigned int*, unsigned int*, unsigned int*)\n",
      "                    4.82%  5.5206ms        11  501.87us  4.1590us  3.8447ms  mirroredEdgesRemoval(GraphStruct*, unsigned int*, __int64*)\n",
      "                    4.82%  5.5121ms        20  275.61us  2.3040us  4.4437ms  cfinal_sum(unsigned int*, unsigned int*, unsigned int)\n",
      "                    3.88%  4.4423ms        10  444.23us  5.3760us  2.6246ms  cumulatedDegreeUpdateCopy(GraphStruct*, unsigned int*, unsigned int*, unsigned int*)\n",
      "                    2.05%  2.3452ms        20  117.26us  14.943us  797.20us  prescan(unsigned int*, unsigned int*, unsigned int*, int, int)\n",
      "                    0.79%  904.18us        11  82.198us  1.1840us  747.73us  [CUDA memcpy HtoD]\n",
      "                    0.63%  717.65us        92  7.8000us     640ns  65.279us  [CUDA memset]\n",
      "                    0.24%  279.64us        10  27.964us  3.0080us  184.77us  svIdentification(GraphStruct*, unsigned int*, unsigned int*, unsigned int*)\n",
      "      API calls:   46.41%  125.13ms        44  2.8439ms  3.8000us  121.47ms  cudaMallocManaged\n",
      "                   34.05%  91.792ms       103  891.18us  5.3850us  33.193ms  cudaDeviceSynchronize\n",
      "                   11.31%  30.496ms        94  324.43us  5.4110us  3.3124ms  cudaMemcpy\n",
      "                    5.60%  15.107ms       147  102.77us  2.5900us  2.0892ms  cudaFree\n",
      "                    1.35%  3.6459ms       103  35.397us  2.6740us  356.82us  cudaMalloc\n",
      "                    0.40%  1.0741ms       103  10.428us  4.2750us  226.51us  cudaLaunchKernel\n",
      "                    0.31%  828.20us        92  9.0020us  1.9470us  43.238us  cudaMemset\n",
      "                    0.20%  551.85us        93  5.9330us  5.0150us  19.175us  cudaEventSynchronize\n",
      "                    0.20%  548.53us       206  2.6620us  1.3270us  17.766us  cudaEventRecord\n",
      "                    0.08%  223.34us       114  1.9590us     203ns  101.84us  cuDeviceGetAttribute\n",
      "                    0.05%  133.25us       103  1.2930us     780ns  3.3570us  cudaEventElapsedTime\n",
      "                    0.01%  27.152us         2  13.576us  1.1470us  26.005us  cudaEventCreate\n",
      "                    0.01%  13.500us         1  13.500us  13.500us  13.500us  cuDeviceGetName\n",
      "                    0.00%  8.4880us        40     212ns     147ns     384ns  cudaGetLastError\n",
      "                    0.00%  7.3310us         1  7.3310us  7.3310us  7.3310us  cuDeviceGetPCIBusId\n",
      "                    0.00%  5.6230us         1  5.6230us  5.6230us  5.6230us  cuDeviceTotalMem\n",
      "                    0.00%  1.8520us         3     617ns     302ns  1.1820us  cuDeviceGetCount\n",
      "                    0.00%  1.7920us         2     896ns     478ns  1.3140us  cudaEventDestroy\n",
      "                    0.00%  1.0980us         2     549ns     287ns     811ns  cuDeviceGet\n",
      "                    0.00%     716ns         1     716ns     716ns     716ns  cuModuleGetLoadingMode\n",
      "                    0.00%     451ns         1     451ns     451ns     451ns  cuDeviceGetUuid\n",
      "\n",
      "==47614== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    5784  24.973KB  4.0000KB  0.9961MB  141.0586MB  25.68459ms  Host To Device\n",
      "      42  32.000KB  4.0000KB  60.000KB  1.312500MB  170.9390us  Device To Host\n",
      "     241         -         -         -           -  59.52362ms  Gpu page fault groups\n",
      "Total CPU Page faults: 470\n"
     ]
    }
   ],
   "source": [
    "!nvprof ./mstGPUE > nvprof_gpuE.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1sV72w4W1S-"
   },
   "outputs": [],
   "source": [
    "!ncu ./mstGPUE > ncu_gpuE.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5kobMdtrh8v"
   },
   "source": [
    "## Work efficient scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHkAGz_qIEP_"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"scanTesting.cu\" --group \"TESTING\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <cstdlib>\n",
    "#include <ctime>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "__global__ void prescan(uint *g_odata, uint *g_idata, uint *aux, int n, int smemSize)\n",
    "{\n",
    "  extern __shared__ int temp[];// allocated on invocation\n",
    "  int thid = threadIdx.x;\n",
    "  int offset = 1;\n",
    "  int idx = blockIdx.x * blockDim.x + thid;\n",
    "\n",
    "  temp[2*thid] = g_idata[2*idx]; // load input into shared memory\n",
    "  temp[2*thid+1] = g_idata[2*idx+1];\n",
    "\n",
    "  for (int d = n>>1; d > 0; d >>= 1) // build sum in place up the tree\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset*(2*thid+1)-1;\n",
    "      int bi = offset*(2*thid+2)-1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        temp[bi] += temp[ai];\n",
    "      }\n",
    "    }\n",
    "    offset *= 2;\n",
    "  }\n",
    "\n",
    "  if (thid == 0)\n",
    "  {\n",
    "    aux[blockIdx.x] = temp[smemSize - 1];\n",
    "    temp[smemSize - 1] = 0;\n",
    "  } // clear the last element\n",
    "\n",
    "  for (int d = 1; d < n; d *= 2) // traverse down tree & build scan\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d && offset > 0)\n",
    "    {\n",
    "      int ai = offset*(2*thid+1)-1;\n",
    "      int bi = offset*(2*thid+2)-1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        int t = temp[ai];\n",
    "        temp[ai] = temp[bi];\n",
    "        temp[bi] += t;\n",
    "      }\n",
    "    }\n",
    "    offset >>= 1;\n",
    "  }\n",
    "\n",
    "\n",
    "  __syncthreads();\n",
    "  if (idx <= (n / 2) - 1) {\n",
    "      g_odata[2*idx] = temp[2*thid]; // write results to device memory\n",
    "      g_odata[2*idx+1] = temp[2*thid+1];\n",
    "  }\n",
    "}\n",
    "\n",
    "void cpuScan(uint *array, int start, int end) {\n",
    "    if (end - start <= 1) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    int temp = array[start + 1];\n",
    "    array[start + 1] = array[start];\n",
    "    array[start] = 0;\n",
    "\n",
    "    for (uint i = start + 1; i < end - 1; i++) {\n",
    "        int sum = array[i] + temp;\n",
    "        temp = array[i + 1];\n",
    "        array[i + 1] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void final_sum(uint *g_odata, uint *aux, uint n)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "  if (blockIdx.x == 0 || 2 * idx >= n) {\n",
    "      return;\n",
    "  }\n",
    "\n",
    "  //printf(\"%d: ls - %d  rs - %d  aux - %d\\n\", idx, g_odata[2 * idx], g_odata[2 * idx + 1], aux[blockIdx.x - 1]);\n",
    "\n",
    "  if (2 * idx == n - 1) {\n",
    "      g_odata[2 * idx] += aux[blockIdx.x];\n",
    "      return;\n",
    "  }\n",
    "  g_odata[2 * idx] += aux[blockIdx.x];\n",
    "  g_odata[2 * idx + 1] += aux[blockIdx.x];\n",
    "}\n",
    "\n",
    "\n",
    "/*\n",
    " * MAIN: test on parallel reduction\n",
    " */\n",
    "int main(void) {\n",
    "  uint *cpuArray, *gpuArray, *d_gpuArray, *gpuOutput, *d_gpuOutput, *aux, *d_aux;\n",
    "  uint blockSize = 128;\n",
    "  uint smemSize = 2 * blockSize;\n",
    "  uint n = 1500;\n",
    "\n",
    "  uint numSmemBlock = n / smemSize;\n",
    "  uint numBlock = (n + blockSize - 1) / blockSize;\n",
    "  uint gpuScanSize = numSmemBlock * smemSize;\n",
    "  uint residualSize = n - gpuScanSize;\n",
    "\n",
    "  // Memory allocation for the Host side\n",
    "  cpuArray = (uint *) malloc(n * sizeof(uint));\n",
    "  gpuArray = (uint *) malloc(n * sizeof(uint));\n",
    "  gpuOutput = (uint *) malloc(n * sizeof(uint));\n",
    "  aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
    "\n",
    "  // Memory allocation for the Device side\n",
    "  CHECK(cudaMalloc((void **) &d_gpuArray, gpuScanSize * sizeof(uint)));\n",
    "  CHECK(cudaMalloc((void **) &d_gpuOutput, n * sizeof(uint)));\n",
    "  CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
    "\n",
    "  printf(\"\\n****  test on parallel scan  ****\\n\");\n",
    "\tprintf(\"  Vector length: %d\\n\", n);\n",
    "\n",
    "  cudaEvent_t start, stop;\n",
    "\tcudaEventCreate(&start);\n",
    "\tcudaEventCreate(&stop);\n",
    "\n",
    "  // Generate the original array\n",
    "  srand(0);\n",
    "\tfor (uint i = 0; i < n; i++){\n",
    "     cpuArray[i] = 1;\n",
    "     gpuArray[i] = cpuArray[i];\n",
    "  }\n",
    "\n",
    "\tprintf(\"\\n  CPU procedure...\\n\");\n",
    "\tdouble go = seconds();\n",
    "  for (uint i = 1; i < n; i++) {\n",
    "      cpuArray[i] += cpuArray[i - 1];\n",
    "  }\n",
    "\tdouble CPUtime = seconds() - go;\n",
    "\tprintf(\"    Elapsed time: %f (sec) \\n\", CPUtime);\n",
    "\n",
    "  // Copy the contents of gpuArray in the Device memory\n",
    "  CHECK(cudaMemcpy(d_gpuArray, gpuArray, gpuScanSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "  CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
    "\n",
    "  printf(\"\\n  block scan...\\n\");\n",
    "\n",
    "  uint smem = smemSize * sizeof(uint);\n",
    "  printf(\"\\n  first prescan procedure on the Device: %d elements...\\n\", gpuScanSize);\n",
    "  cudaEventRecord(start);\n",
    "  prescan<<<  numSmemBlock, blockSize, smem >>>(d_gpuOutput, d_gpuArray, d_aux, n, smemSize);\n",
    "  printf(\"\\n  second scan procedure on the Host: %d elements...\\n\", residualSize);\n",
    "  cpuScan(gpuArray, gpuScanSize, n);\n",
    "  CHECK(cudaDeviceSynchronize());\n",
    "\tCHECK(cudaEventRecord(stop));\n",
    "\tCHECK(cudaEventSynchronize(stop));\n",
    "\tCHECK(cudaGetLastError());\n",
    "  float milliseconds;\n",
    "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\tdouble GPUtime = milliseconds / 1000.0;\n",
    "\tprintf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "  // Copy the contents of the aux array into Host memory and perform another scan\n",
    "  printf(\"\\n  third scan procedure on the Host: %d elements...\\n\", numSmemBlock);\n",
    "  CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "  cudaEventRecord(start);\n",
    "  cpuScan(aux, 0, numSmemBlock + 1);\n",
    "  CHECK(cudaEventRecord(stop));\n",
    "  CHECK(cudaEventSynchronize(stop));\n",
    "  CHECK(cudaGetLastError());\n",
    "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\tGPUtime += milliseconds / 1000.0;\n",
    "\tprintf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "  if (DEBUGGING) {\n",
    "      for (uint i = 0; i < numSmemBlock; i++) {\n",
    "          printf(\"Block(%d): %d\\n\", i, aux[i]);\n",
    "      }\n",
    "  }\n",
    "\n",
    "  // Copy the portions of the array computed on the Host to Device memory\n",
    "  CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "  CHECK(cudaMemcpy(&(d_gpuOutput[gpuScanSize]), &(gpuArray[gpuScanSize]), residualSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "  printf(\"\\n  final summation procedure...\\n\");\n",
    "  cudaEventRecord(start);\n",
    "  final_sum<<< numBlock, blockSize >>>(d_gpuOutput, d_aux, n);\n",
    "  CHECK(cudaDeviceSynchronize());\n",
    "\tCHECK(cudaEventRecord(stop));\n",
    "\tCHECK(cudaEventSynchronize(stop));\n",
    "\tCHECK(cudaGetLastError());\n",
    "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\tGPUtime += milliseconds / 1000.0;\n",
    "\tprintf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
    "\n",
    " \tprintf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", GPUtime);\n",
    "\n",
    "\tdouble speedup = CPUtime/GPUtime;\n",
    "\tprintf(\"    Speedup %.1f\\n\", speedup);\n",
    "\n",
    "  CHECK(cudaMemcpy(gpuOutput, d_gpuOutput, n * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "  if (DEBUGGING && n < 200) {\n",
    "      for (uint i = 0; i < n; i++) {\n",
    "          cout << gpuOutput[i] << endl;\n",
    "      }\n",
    "  }\n",
    "\n",
    "  for (uint i = 0; i < n - 1; i++) {\n",
    "      if (gpuOutput[i + 1] != cpuArray[i]) {\n",
    "          printf(\"%d: %d\\t%d\\n\", i - 1, gpuOutput[i - 1], cpuArray[i - 1]);\n",
    "          printf(\"%d: %d\\t%d\\n\", i, gpuOutput[i], cpuArray[i]);\n",
    "          printf(\"%d: %d\\t%d\\n\", i + 1, gpuOutput[i + 1], cpuArray[i + 1]);\n",
    "          return -1;\n",
    "      }\n",
    "  }\n",
    "\n",
    "  printf(\"%d - %d\\n\", gpuOutput[n - 1], cpuArray[n - 2]);\n",
    "  printf(\" andato tutto bene\\n\");\n",
    "\n",
    "  // Host memory deallocation\n",
    "  free(cpuArray);\n",
    "  free(gpuArray);\n",
    "  free(gpuOutput);\n",
    "  free(aux);\n",
    "\n",
    "  // Device memory deallocation\n",
    "  CHECK(cudaFree(d_gpuArray));\n",
    "  CHECK(cudaFree(d_gpuOutput));\n",
    "  CHECK(cudaFree(d_aux));\n",
    "\n",
    "\treturn 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2vSA87DOeCr",
    "outputId": "12011df1-ba2d-44e2-ad34-7a4b532feda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****  test on parallel scan  ****\n",
      "  Vector length: 1500\n",
      "\n",
      "  CPU procedure...\n",
      "    Elapsed time: 0.000006 (sec) \n",
      "\n",
      "  block scan...\n",
      "\n",
      "  first prescan procedure on the Device: 1280 elements...\n",
      "\n",
      "  second scan procedure on the Host: 220 elements...\n",
      "   elapsed time:   0.00024 (sec)\n",
      "\n",
      "  third scan procedure on the Host: 5 elements...\n",
      "   elapsed time:   0.00000 (sec)\n",
      "Block(0): 0\n",
      "Block(1): 256\n",
      "Block(2): 512\n",
      "Block(3): 768\n",
      "Block(4): 1024\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00003 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00028 (sec)\n",
      "    Speedup 0.0\n",
      "1499 - 1499\n",
      " andato tutto bene\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_75 src/TESTING/scanTesting.cu -o scanTesting\n",
    "!./scanTesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xvmvZC2mHq9"
   },
   "source": [
    "## Work efficient scan that can work with any array size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMbr8-g1mPZF"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"scanTestingUpgrade.cu\" --group \"TESTING\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <cstdlib>\n",
    "#include <ctime>\n",
    "#include <math.h>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "__global__ void prescan(uint *g_odata, uint *g_idata, uint *aux, int n, int smemSize)\n",
    "{\n",
    "  extern __shared__ int temp[];// allocated on invocation\n",
    "  int thid = threadIdx.x;\n",
    "  int offset = 1;\n",
    "  int idx = blockIdx.x * blockDim.x + thid;\n",
    "\n",
    "  // load input into shared memory\n",
    "  temp[2 * thid] =  (2 * idx < n) ? g_idata[2 * idx] : 0;\n",
    "  temp[2 * thid + 1] = (2 * idx + 1 < n) ? g_idata[2 * idx + 1] : 0;\n",
    "  //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "      //printf(\"UPSWEEP\\n\");\n",
    "  //}\n",
    "\n",
    "  //printf(\"%d >> left: %d   right: %d\\n\", thid, temp[2 * thid], temp[2 * thid + 1]);\n",
    "\n",
    "  for (int d =smemSize>>1; d > 0; d >>= 1) // build sum in place up the tree\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        temp[bi] += temp[ai];\n",
    "      }\n",
    "    }\n",
    "    offset *= 2;\n",
    "  }\n",
    "\n",
    "  //printf(\"%d >> right: %d   left: %d\\n\", thid, temp[2 * thid], temp[2 * thid + 1]);\n",
    "\n",
    "  if (thid == 0)\n",
    "  {\n",
    "    aux[blockIdx.x] = temp[smemSize - 1];\n",
    "    temp[smemSize - 1] = 0;\n",
    "  }\n",
    "\n",
    "  //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "      //printf(\"DOWNSWEEP\\n\");\n",
    "  //}\n",
    "\n",
    "  for (int d = 1; d < smemSize; d *= 2) // traverse down tree & build scan\n",
    "  {\n",
    "      offset >>= 1;\n",
    "    __syncthreads();\n",
    "\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        //printf(\"%d >> ai: %d   bi: %d   temp[ai]: %d   temp[bi]: %d\\n\", thid, ai, bi, temp[ai], temp[bi]);\n",
    "        int t = temp[ai];\n",
    "        temp[ai] = temp[bi];\n",
    "        temp[bi] += t;\n",
    "      }\n",
    "    }\n",
    "    //if (2 * idx == n - 1) {\n",
    "        //printf(\"temp[n - 1]: %d\\n\", temp[2 * thid]);\n",
    "    //}\n",
    "    //if (2 * idx + 1 == n - 1) {\n",
    "        //printf(\"temp[n - 1]: %d\\n\", temp[2 * thid + 1]);\n",
    "    //}\n",
    "  }\n",
    "\n",
    "  //printf(\"%d >> right: %d   left: %d\\n\", thid, temp[2 * thid], temp[2 * thid + 1]);\n",
    "\n",
    "\n",
    "  __syncthreads();\n",
    "  if (idx <= (n / 2)) {\n",
    "      g_odata[2*idx] = temp[2*thid]; // write results to device memory\n",
    "      g_odata[2*idx+1] = temp[2*thid+1];\n",
    "  }\n",
    "}\n",
    "\n",
    "void cpuScan(uint *array, int start, int end) {\n",
    "    if (end - start <= 1) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    int temp = array[start + 1];\n",
    "    array[start + 1] = array[start];\n",
    "    array[start] = 0;\n",
    "\n",
    "    for (uint i = start + 1; i < end - 1; i++) {\n",
    "        int sum = array[i] + temp;\n",
    "        temp = array[i + 1];\n",
    "        array[i + 1] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void final_sum(uint *g_odata, uint *aux, uint n)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "  if (blockIdx.x == 0 || 2 * idx >= n) {\n",
    "      return;\n",
    "  }\n",
    "\n",
    "  //printf(\"%d: ls - %d  rs - %d  aux - %d\\n\", idx, g_odata[2 * idx], g_odata[2 * idx + 1], aux[blockIdx.x - 1]);\n",
    "\n",
    "  if (2 * idx == n - 1) {\n",
    "      g_odata[2 * idx] += aux[blockIdx.x];\n",
    "      return;\n",
    "  }\n",
    "  g_odata[2 * idx] += aux[blockIdx.x];\n",
    "  g_odata[2 * idx + 1] += aux[blockIdx.x];\n",
    "}\n",
    "\n",
    "\n",
    "/*\n",
    " * MAIN: test on parallel reduction\n",
    " */\n",
    "int main(void) {\n",
    "  uint *cpuArray, *gpuArray, *gpuArrayNew, *d_gpuArrayNew, *d_gpuArray, *gpuOutput, *d_gpuOutput, *aux, *d_aux;\n",
    "  uint blockSize = 1024;\n",
    "  uint smemSize = 2 * blockSize;\n",
    "  uint n = 500001;\n",
    "\n",
    "  uint numSmemBlock = n / smemSize;\n",
    "  uint numBlock = (n + blockSize - 1) / blockSize;\n",
    "  uint gpuScanSize = numSmemBlock * smemSize;\n",
    "  uint residualSize = n - gpuScanSize;\n",
    "\n",
    "  // Memory allocation for the Host side\n",
    "  gpuArrayNew = (uint *) malloc(n * sizeof(uint));\n",
    "  cpuArray = (uint *) malloc(n * sizeof(uint));\n",
    "  gpuArray = (uint *) malloc(n * sizeof(uint));\n",
    "  gpuOutput = (uint *) malloc(n * sizeof(uint));\n",
    "  aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
    "\n",
    "  // Memory allocation for the Device side\n",
    "  CHECK(cudaMalloc((void **) &d_gpuArray, gpuScanSize * sizeof(uint)));\n",
    "  CHECK(cudaMalloc((void **) &d_gpuOutput, n * sizeof(uint)));\n",
    "  CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
    "\n",
    "  printf(\"\\n****  test on parallel scan  ****\\n\");\n",
    "\tprintf(\"  Vector length: %d\\n\", n);\n",
    "\n",
    "  cudaEvent_t start, stop;\n",
    "\tcudaEventCreate(&start);\n",
    "\tcudaEventCreate(&stop);\n",
    "\n",
    "  // Generate the original array\n",
    "  srand(0);\n",
    "\tfor (uint i = 0; i < n; i++){\n",
    "     cpuArray[i] = rand() % 100;\n",
    "     //cpuArray[i] = 1;\n",
    "     gpuArray[i] = cpuArray[i];\n",
    "     gpuArrayNew[i] = cpuArray[i];\n",
    "  }\n",
    "\n",
    "\tprintf(\"\\n  CPU procedure...\\n\");\n",
    "\tdouble go = seconds();\n",
    "  for (uint i = 1; i < n; i++) {\n",
    "      cpuArray[i] += cpuArray[i - 1];\n",
    "  }\n",
    "\tdouble CPUtime = seconds() - go;\n",
    "\tprintf(\"    Elapsed time: %f (sec) \\n\", CPUtime);\n",
    "\n",
    "  // Copy the contents of gpuArray in the Device memory\n",
    "  CHECK(cudaMemcpy(d_gpuArray, gpuArray, gpuScanSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "  CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
    "\n",
    "  printf(\"\\n  block scan...\\n\");\n",
    "\n",
    "  uint smem = smemSize * sizeof(uint);\n",
    "  printf(\"\\n  first prescan procedure on the Device: %d elements...\\n\", gpuScanSize);\n",
    "  cudaEventRecord(start);\n",
    "  prescan<<<  numSmemBlock, blockSize, smem >>>(d_gpuOutput, d_gpuArray, d_aux, n, smemSize);\n",
    "  printf(\"\\n  second scan procedure on the Host: %d elements...\\n\", residualSize);\n",
    "  cpuScan(gpuArray, gpuScanSize, n);\n",
    "  CHECK(cudaDeviceSynchronize());\n",
    "\tCHECK(cudaEventRecord(stop));\n",
    "\tCHECK(cudaEventSynchronize(stop));\n",
    "\tCHECK(cudaGetLastError());\n",
    "  float milliseconds;\n",
    "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\tdouble GPUtime = milliseconds / 1000.0;\n",
    "\tprintf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "  // Copy the contents of the aux array into Host memory and perform another scan\n",
    "  printf(\"\\n  third scan procedure on the Host: %d elements...\\n\", numSmemBlock);\n",
    "  CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "  cudaEventRecord(start);\n",
    "  cpuScan(aux, 0, numSmemBlock + 1);\n",
    "  CHECK(cudaEventRecord(stop));\n",
    "  CHECK(cudaEventSynchronize(stop));\n",
    "  CHECK(cudaGetLastError());\n",
    "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\tGPUtime += milliseconds / 1000.0;\n",
    "\tprintf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "  if (DEBUGGING && numSmemBlock < 15) {\n",
    "      for (uint i = 0; i < numSmemBlock; i++) {\n",
    "          printf(\"Block(%d): %d\\n\", i, aux[i]);\n",
    "      }\n",
    "  }\n",
    "\n",
    "  // Copy the portions of the array computed on the Host to Device memory\n",
    "  CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "  CHECK(cudaMemcpy(&(d_gpuOutput[gpuScanSize]), &(gpuArray[gpuScanSize]), residualSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "  printf(\"\\n  final summation procedure...\\n\");\n",
    "  cudaEventRecord(start);\n",
    "  final_sum<<< numBlock, blockSize >>>(d_gpuOutput, d_aux, n);\n",
    "  CHECK(cudaDeviceSynchronize());\n",
    "\tCHECK(cudaEventRecord(stop));\n",
    "\tCHECK(cudaEventSynchronize(stop));\n",
    "\tCHECK(cudaGetLastError());\n",
    "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\tGPUtime += milliseconds / 1000.0;\n",
    "\tprintf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
    "\n",
    " \tprintf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", GPUtime);\n",
    "\n",
    "  CHECK(cudaMemcpy(gpuOutput, d_gpuOutput, n * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "  /*\n",
    "  if (DEBUGGING && n < 200) {\n",
    "      for (uint i = 0; i < n; i++) {\n",
    "          cout << gpuOutput[i] << endl;\n",
    "      }\n",
    "  }\n",
    "  */\n",
    "\n",
    "  for (uint i = 0; i < n - 1; i++) {\n",
    "      if (gpuOutput[i + 1] != cpuArray[i]) {\n",
    "          printf(\"%d: %d\\t%d\\n\", i - 1, gpuOutput[i - 1], cpuArray[i - 1]);\n",
    "          printf(\"%d: %d\\t%d\\n\", i, gpuOutput[i], cpuArray[i]);\n",
    "          printf(\"%d: %d\\t%d\\n\", i + 1, gpuOutput[i + 1], cpuArray[i + 1]);\n",
    "          return -1;\n",
    "      }\n",
    "  }\n",
    "\n",
    "  printf(\"%d - %d\\n\", gpuOutput[n - 1], cpuArray[n - 2]);\n",
    "  printf(\" andato tutto bene\\n\");\n",
    "\n",
    "  CHECK(cudaFree(d_aux));\n",
    "  free(aux);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  printf(\"TEST DEL NUOVO KERNEL\");\n",
    "\n",
    "  double GPUTimeNew = 0;\n",
    "\n",
    "  // Copy the contents of gpuArray in the Device memory\n",
    "  numSmemBlock = (n + smemSize - 1) / smemSize;\n",
    "  aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
    "  CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
    "  CHECK(cudaMalloc((void **) &d_gpuArrayNew, n * sizeof(uint)));\n",
    "  CHECK(cudaMemcpy(d_gpuArrayNew, gpuArrayNew, n * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "  CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
    "  CHECK(cudaMemset(d_gpuOutput, 0, n * sizeof(uint)));\n",
    "\n",
    "  printf(\"\\n  block scan...\\n\");\n",
    "\n",
    "  smem = smemSize * sizeof(uint);\n",
    "  printf(\"\\n  prescan procedure on: %d elements...\\n\", n);\n",
    "  cudaEventRecord(start);\n",
    "  prescan<<<  numSmemBlock, blockSize, smem >>>(d_gpuOutput, d_gpuArrayNew, d_aux, n, smemSize);\n",
    "  CHECK(cudaDeviceSynchronize());\n",
    "\tCHECK(cudaEventRecord(stop));\n",
    "\tCHECK(cudaEventSynchronize(stop));\n",
    "\tCHECK(cudaGetLastError());\n",
    "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\tGPUTimeNew = milliseconds / 1000.0;\n",
    "\tprintf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "  /*\n",
    "  for (uint i = 0; i < numSmemBlock + 1; ++i) {\n",
    "      printf(\"%d\\n\", aux[i]);\n",
    "  }\n",
    "  */\n",
    "\n",
    "  printf(\"\\n  another prescan procedure on: %d elements...\\n\", numSmemBlock + 1);\n",
    "  uint *d_aaux;\n",
    "  CHECK(cudaMalloc((void **) &d_aaux, sizeof(uint)));\n",
    "  cudaEventRecord(start);\n",
    "  prescan<<<  1, blockSize, smem >>>(d_aux, d_aux, d_aaux, numSmemBlock + 1, smemSize);\n",
    "  CHECK(cudaDeviceSynchronize());\n",
    "\tCHECK(cudaEventRecord(stop));\n",
    "\tCHECK(cudaEventSynchronize(stop));\n",
    "\tCHECK(cudaGetLastError());\n",
    "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\tGPUTimeNew = milliseconds / 1000.0;\n",
    "\tprintf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "\n",
    "  CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "  if (DEBUGGING) {\n",
    "      for (uint i = 0; i < numSmemBlock + 1; i++) {\n",
    "          printf(\"Block(%d): %d\\n\", i, aux[i]);\n",
    "      }\n",
    "  }\n",
    "\n",
    "  printf(\"\\n  final summation procedure...\\n\");\n",
    "  cudaEventRecord(start);\n",
    "  final_sum<<< numBlock, blockSize >>>(d_gpuOutput, d_aux, n);\n",
    "  CHECK(cudaDeviceSynchronize());\n",
    "\tCHECK(cudaEventRecord(stop));\n",
    "\tCHECK(cudaEventSynchronize(stop));\n",
    "\tCHECK(cudaGetLastError());\n",
    "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\tGPUTimeNew += milliseconds / 1000.0;\n",
    "\tprintf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
    "\n",
    "  CHECK(cudaMemcpy(gpuOutput, d_gpuOutput, n * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "  /*\n",
    "  for (uint i = 0; i < n; ++i) {\n",
    "      printf(\"%d\\n\", gpuOutput[i]);\n",
    "  }\n",
    "  */\n",
    "\n",
    " \tprintf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", GPUTimeNew);\n",
    "\n",
    "  for (uint i = 0; i < n - 1; i++) {\n",
    "      if (gpuOutput[i + 1] != cpuArray[i]) {\n",
    "          printf(\"%d: %d\\t%d\\n\", i - 1, gpuOutput[i - 1], cpuArray[i - 1]);\n",
    "          printf(\"%d: %d\\t%d\\n\", i, gpuOutput[i], cpuArray[i]);\n",
    "          printf(\"%d: %d\\t%d\\n\", i + 1, gpuOutput[i + 1], cpuArray[i + 1]);\n",
    "          return -1;\n",
    "      }\n",
    "  }\n",
    "\n",
    "  printf(\"%d - %d\\n\", gpuOutput[n - 1], cpuArray[n - 2]);\n",
    "  printf(\" andato tutto bene\\n\");\n",
    "\n",
    "  printf(\"Speedup with respect to the CPU: %.5f\\nSpeedup with respect to the old GPU impl: %.5f\", CPUtime / GPUTimeNew, GPUtime / GPUTimeNew);\n",
    "\n",
    "  // Host memory deallocation\n",
    "  free(cpuArray);\n",
    "  free(gpuArray);\n",
    "  free(gpuOutput);\n",
    "  free(aux);\n",
    "\n",
    "  // Device memory deallocation\n",
    "  CHECK(cudaFree(d_gpuArray));\n",
    "  CHECK(cudaFree(d_gpuOutput));\n",
    "  CHECK(cudaFree(d_aux));\n",
    "\n",
    "\treturn 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IU7asC8pmPJZ",
    "outputId": "6398d618-d329-4386-f72b-8a39eefc3e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****  test on parallel scan  ****\n",
      "  Vector length: 500001\n",
      "\n",
      "  CPU procedure...\n",
      "    Elapsed time: 0.001797 (sec) \n",
      "\n",
      "  block scan...\n",
      "\n",
      "  first prescan procedure on the Device: 499712 elements...\n",
      "\n",
      "  second scan procedure on the Host: 289 elements...\n",
      "   elapsed time:   0.00025 (sec)\n",
      "\n",
      "  third scan procedure on the Host: 244 elements...\n",
      "   elapsed time:   0.00000 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00006 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00032 (sec)\n",
      "24745984 - 24745984\n",
      " andato tutto bene\n",
      "TEST DEL NUOVO KERNEL\n",
      "  block scan...\n",
      "\n",
      "  prescan procedure on: 500001 elements...\n",
      "   elapsed time:   0.00013 (sec)\n",
      "\n",
      "  another prescan procedure on: 246 elements...\n",
      "   elapsed time:   0.00003 (sec)\n",
      "Block(0): 0\n",
      "Block(1): 102716\n",
      "Block(2): 204244\n",
      "Block(3): 307416\n",
      "Block(4): 409245\n",
      "Block(5): 509061\n",
      "Block(6): 610259\n",
      "Block(7): 711011\n",
      "Block(8): 813989\n",
      "Block(9): 916448\n",
      "Block(10): 1018009\n",
      "Block(11): 1119958\n",
      "Block(12): 1219613\n",
      "Block(13): 1322218\n",
      "Block(14): 1423626\n",
      "Block(15): 1522298\n",
      "Block(16): 1623296\n",
      "Block(17): 1728314\n",
      "Block(18): 1829743\n",
      "Block(19): 1932331\n",
      "Block(20): 2034854\n",
      "Block(21): 2134949\n",
      "Block(22): 2237609\n",
      "Block(23): 2338522\n",
      "Block(24): 2441040\n",
      "Block(25): 2540446\n",
      "Block(26): 2639723\n",
      "Block(27): 2742438\n",
      "Block(28): 2842937\n",
      "Block(29): 2942810\n",
      "Block(30): 3043204\n",
      "Block(31): 3144839\n",
      "Block(32): 3248637\n",
      "Block(33): 3351206\n",
      "Block(34): 3453592\n",
      "Block(35): 3554198\n",
      "Block(36): 3656277\n",
      "Block(37): 3755391\n",
      "Block(38): 3857131\n",
      "Block(39): 3958964\n",
      "Block(40): 4059821\n",
      "Block(41): 4161656\n",
      "Block(42): 4261449\n",
      "Block(43): 4362403\n",
      "Block(44): 4461953\n",
      "Block(45): 4564005\n",
      "Block(46): 4666196\n",
      "Block(47): 4767831\n",
      "Block(48): 4868559\n",
      "Block(49): 4970052\n",
      "Block(50): 5071603\n",
      "Block(51): 5171673\n",
      "Block(52): 5271516\n",
      "Block(53): 5373239\n",
      "Block(54): 5475720\n",
      "Block(55): 5575763\n",
      "Block(56): 5676970\n",
      "Block(57): 5776954\n",
      "Block(58): 5877041\n",
      "Block(59): 5976348\n",
      "Block(60): 6078142\n",
      "Block(61): 6179488\n",
      "Block(62): 6281882\n",
      "Block(63): 6384029\n",
      "Block(64): 6487301\n",
      "Block(65): 6587189\n",
      "Block(66): 6689957\n",
      "Block(67): 6792420\n",
      "Block(68): 6894424\n",
      "Block(69): 6994119\n",
      "Block(70): 7093322\n",
      "Block(71): 7195713\n",
      "Block(72): 7296351\n",
      "Block(73): 7397262\n",
      "Block(74): 7500460\n",
      "Block(75): 7599523\n",
      "Block(76): 7701954\n",
      "Block(77): 7803026\n",
      "Block(78): 7905701\n",
      "Block(79): 8006309\n",
      "Block(80): 8107195\n",
      "Block(81): 8208340\n",
      "Block(82): 8310474\n",
      "Block(83): 8411774\n",
      "Block(84): 8514613\n",
      "Block(85): 8615988\n",
      "Block(86): 8717637\n",
      "Block(87): 8821179\n",
      "Block(88): 8922488\n",
      "Block(89): 9023847\n",
      "Block(90): 9124160\n",
      "Block(91): 9224721\n",
      "Block(92): 9326905\n",
      "Block(93): 9428427\n",
      "Block(94): 9528502\n",
      "Block(95): 9632611\n",
      "Block(96): 9734491\n",
      "Block(97): 9836266\n",
      "Block(98): 9937883\n",
      "Block(99): 10040845\n",
      "Block(100): 10141055\n",
      "Block(101): 10242165\n",
      "Block(102): 10344903\n",
      "Block(103): 10447862\n",
      "Block(104): 10549428\n",
      "Block(105): 10651049\n",
      "Block(106): 10753868\n",
      "Block(107): 10853834\n",
      "Block(108): 10955610\n",
      "Block(109): 11056206\n",
      "Block(110): 11154991\n",
      "Block(111): 11256103\n",
      "Block(112): 11356930\n",
      "Block(113): 11458242\n",
      "Block(114): 11559479\n",
      "Block(115): 11661748\n",
      "Block(116): 11761944\n",
      "Block(117): 11862426\n",
      "Block(118): 11963812\n",
      "Block(119): 12064172\n",
      "Block(120): 12163210\n",
      "Block(121): 12263030\n",
      "Block(122): 12364666\n",
      "Block(123): 12464596\n",
      "Block(124): 12568618\n",
      "Block(125): 12669525\n",
      "Block(126): 12769279\n",
      "Block(127): 12871766\n",
      "Block(128): 12972491\n",
      "Block(129): 13073931\n",
      "Block(130): 13175240\n",
      "Block(131): 13274764\n",
      "Block(132): 13377047\n",
      "Block(133): 13479349\n",
      "Block(134): 13580236\n",
      "Block(135): 13682369\n",
      "Block(136): 13783055\n",
      "Block(137): 13883403\n",
      "Block(138): 13985721\n",
      "Block(139): 14087751\n",
      "Block(140): 14188386\n",
      "Block(141): 14290352\n",
      "Block(142): 14391864\n",
      "Block(143): 14492494\n",
      "Block(144): 14593554\n",
      "Block(145): 14695589\n",
      "Block(146): 14795638\n",
      "Block(147): 14895523\n",
      "Block(148): 14995178\n",
      "Block(149): 15096046\n",
      "Block(150): 15197773\n",
      "Block(151): 15298389\n",
      "Block(152): 15400832\n",
      "Block(153): 15499480\n",
      "Block(154): 15599271\n",
      "Block(155): 15701628\n",
      "Block(156): 15803942\n",
      "Block(157): 15905701\n",
      "Block(158): 16009055\n",
      "Block(159): 16109553\n",
      "Block(160): 16210343\n",
      "Block(161): 16311271\n",
      "Block(162): 16411870\n",
      "Block(163): 16511804\n",
      "Block(164): 16611514\n",
      "Block(165): 16714088\n",
      "Block(166): 16814618\n",
      "Block(167): 16914917\n",
      "Block(168): 17016476\n",
      "Block(169): 17119065\n",
      "Block(170): 17222199\n",
      "Block(171): 17322924\n",
      "Block(172): 17423795\n",
      "Block(173): 17523988\n",
      "Block(174): 17623769\n",
      "Block(175): 17723433\n",
      "Block(176): 17825470\n",
      "Block(177): 17928797\n",
      "Block(178): 18031949\n",
      "Block(179): 18136277\n",
      "Block(180): 18238529\n",
      "Block(181): 18341102\n",
      "Block(182): 18440827\n",
      "Block(183): 18543492\n",
      "Block(184): 18642133\n",
      "Block(185): 18745828\n",
      "Block(186): 18846472\n",
      "Block(187): 18948711\n",
      "Block(188): 19049264\n",
      "Block(189): 19150704\n",
      "Block(190): 19250304\n",
      "Block(191): 19353515\n",
      "Block(192): 19455169\n",
      "Block(193): 19556714\n",
      "Block(194): 19656739\n",
      "Block(195): 19760814\n",
      "Block(196): 19862168\n",
      "Block(197): 19963801\n",
      "Block(198): 20065943\n",
      "Block(199): 20166728\n",
      "Block(200): 20267007\n",
      "Block(201): 20366790\n",
      "Block(202): 20465539\n",
      "Block(203): 20567876\n",
      "Block(204): 20668997\n",
      "Block(205): 20772694\n",
      "Block(206): 20876350\n",
      "Block(207): 20977025\n",
      "Block(208): 21079338\n",
      "Block(209): 21179992\n",
      "Block(210): 21280986\n",
      "Block(211): 21381824\n",
      "Block(212): 21483373\n",
      "Block(213): 21586170\n",
      "Block(214): 21689553\n",
      "Block(215): 21793436\n",
      "Block(216): 21894947\n",
      "Block(217): 21996453\n",
      "Block(218): 22097428\n",
      "Block(219): 22200304\n",
      "Block(220): 22302416\n",
      "Block(221): 22403243\n",
      "Block(222): 22505108\n",
      "Block(223): 22606122\n",
      "Block(224): 22705864\n",
      "Block(225): 22806413\n",
      "Block(226): 22908502\n",
      "Block(227): 23006729\n",
      "Block(228): 23108508\n",
      "Block(229): 23210391\n",
      "Block(230): 23312352\n",
      "Block(231): 23414085\n",
      "Block(232): 23513047\n",
      "Block(233): 23610687\n",
      "Block(234): 23713507\n",
      "Block(235): 23815473\n",
      "Block(236): 23916588\n",
      "Block(237): 24016991\n",
      "Block(238): 24121079\n",
      "Block(239): 24223901\n",
      "Block(240): 24325258\n",
      "Block(241): 24429179\n",
      "Block(242): 24529014\n",
      "Block(243): 24629188\n",
      "Block(244): 24731032\n",
      "Block(245): 24745996\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00004 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00007 (sec)\n",
      "24745984 - 24745984\n",
      " andato tutto bene\n",
      "Speedup with respect to the CPU: 26.70234\n",
      "Speedup with respect to the old GPU impl: 4.68188"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_75 src/TESTING/scanTestingUpgrade.cu -o scanTestingUpgrade\n",
    "!./scanTestingUpgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4teSJBKrl0F"
   },
   "source": [
    "## Dynamic parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_XR2SK7rAHy"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"dynaParallelism.cu\" --group \"TESTING\"\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void exclamationPoint () {\n",
    "    printf(\"!\\n\");\n",
    "    return;\n",
    "}\n",
    "\n",
    "__global__ void world () {\n",
    "    printf(\"world\");\n",
    "    exclamationPoint <<< 1, 1 >>> ();\n",
    "    return;\n",
    "}\n",
    "\n",
    "__global__ void hello () {\n",
    "    printf(\"Hello \");\n",
    "    world <<< 1, 1 >>> ();\n",
    "    return;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    uint blockDim = 32;\n",
    "    uint size = 101;\n",
    "    uint *array = new uint[size];\n",
    "    uint *d_array, *d_aux, *d_auxOffset;\n",
    "    hello <<< 1, 1 >>> ();\n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vekUM5cdrcpb",
    "outputId": "5635d9f6-aa6e-48b3-e1dc-a2f899ff144f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_75 -rdc=true -lcudadevrt src/TESTING/dynaParallelism.cu -o dynaParallelism\n",
    "!./dynaParallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADIG-V2U4Q0o"
   },
   "source": [
    "## Texture based fetches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgKgDSFm4XaR"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"mfTexture.cu\" --group \"TESTING\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <limits.h>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "/*****\n",
    "* Device function that gets the degree of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The node we are interested in\n",
    "*****/\n",
    "__device__ node d_deg (GraphStruct *str, node i) {\n",
    "    return str->cumDegs[i + 1] - str->cumDegs[i];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the weight of a certain edge\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ int d_getWeight (GraphStruct *str, node i, uint offset) {\n",
    "    return str->weights[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the neighbour of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
    "    return str->neighs[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "__device__ uint d_getPosition(GraphStruct *str, node i, uint offset) {\n",
    "    return str->cumDegs[i] + offset;\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void findCheapest (GraphStruct *str, uint *d_candidates) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // Initialize the minimum value\n",
    "    uint minimum = UINT_MAX;\n",
    "    int minimumWeight = INT_MAX;\n",
    "\n",
    "    // Find the cheapest edge in each adjacency list\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        int edgeWeight = d_getWeight(str, idx, i);\n",
    "        if (edgeWeight < minimumWeight) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "        else if (edgeWeight == minimumWeight &&\n",
    "                 d_getNeigh(str, idx, i) < d_getNeigh(str, idx, minimum)) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Update the return vector\n",
    "    d_candidates[idx] = minimum;\n",
    "}\n",
    "\n",
    "__global__ void findCheapestTexture (GraphStruct *str, uint *d_candidates, cudaTextureObject_t wtex, cudaTextureObject_t ntex) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // Initialize the minimum value\n",
    "    uint minimum = UINT_MAX;\n",
    "    int minimumWeight = INT_MAX;\n",
    "\n",
    "    // Find the cheapest edge in each adjacency list\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        uint pos = d_getPosition(str, idx, i);\n",
    "        int edgeWeight = tex1Dfetch<int>(wtex, pos);\n",
    "        if (edgeWeight < minimumWeight) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "        else {\n",
    "            uint neigh = tex1Dfetch<int>(ntex, pos);\n",
    "            pos = d_getPosition(str, idx, minimum);\n",
    "            uint miNeigh = (minimum == UINT_MAX) ?  UINT_MAX : tex1Dfetch<int>(ntex, pos);\n",
    "\n",
    "            if (edgeWeight == minimumWeight && neigh < miNeigh) {\n",
    "                minimumWeight = edgeWeight;\n",
    "                minimum = i;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Update the return vector\n",
    "    d_candidates[idx] = minimum;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Generation of a random graph\n",
    "    std::random_device rd;\n",
    "    std::default_random_engine eng(FIXED_SEED);\n",
    "    uint maxWeight = MAX_WEIGHT;\n",
    "    float prob = PROBABILITY;\n",
    "    bool GPUEnabled = 1;\n",
    "    Graph *graphPointer;\n",
    "    Graph graph(SIZE, GPUEnabled);\n",
    "    graphPointer = &graph;\n",
    "  \tgraphPointer->randGraph(prob, true, maxWeight, eng);\n",
    "    /**************************************************/\n",
    "\n",
    "\n",
    "    // Checking if the random graph is connected\n",
    "    if (!graphPointer->isConnected()) {\n",
    "        cout << \"The graph is not connected\" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "    /************/\n",
    "\n",
    "    // Initialization of the variables associated with the graph\n",
    "    GraphStruct *str = graphPointer->getStruct();\n",
    "    uint size = str->nodeSize;\n",
    "    uint edgeSize = str->edgeSize;\n",
    "    cout << \"Processing a graph of size: \" << size << \" with \" << edgeSize << \" edges.\\n\\n\";\n",
    "    uint *candidates = new uint[size];\n",
    "    uint *CPUCandidates = new uint[size];\n",
    "\n",
    "    // First setp of the algorithm\n",
    "    uint *d_candidates;\n",
    "    CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
    "    CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
    "\n",
    "    uint blockDim = BLOCK_SIZE;\n",
    "    uint gridDim = (size + blockDim - 1) / blockDim;\n",
    "\n",
    "    // Events to measure time\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    float milliseconds;\n",
    "    float cpuTime, gpuTime, gpuETime;\n",
    "\n",
    "    // create texture object\n",
    "    cudaResourceDesc weightsDesc;\n",
    "    memset(&weightsDesc, 0, sizeof(weightsDesc));\n",
    "    weightsDesc.resType = cudaResourceTypeLinear;\n",
    "    weightsDesc.res.linear.devPtr = str->weights;\n",
    "    weightsDesc.res.linear.desc.f = cudaChannelFormatKindSigned;\n",
    "    weightsDesc.res.linear.desc.x = 32; // bits per channel\n",
    "    weightsDesc.res.linear.sizeInBytes = edgeSize * sizeof(uint);\n",
    "\n",
    "    cudaResourceDesc neighDesc;\n",
    "    memset(&neighDesc, 0, sizeof(neighDesc));\n",
    "    neighDesc.resType = cudaResourceTypeLinear;\n",
    "    neighDesc.res.linear.devPtr = str->weights;\n",
    "    neighDesc.res.linear.desc.f = cudaChannelFormatKindUnsigned;\n",
    "    neighDesc.res.linear.desc.x = 32; // bits per channel\n",
    "    neighDesc.res.linear.sizeInBytes = edgeSize * sizeof(uint);\n",
    "\n",
    "    cudaTextureDesc weightsTexDesc, neighTexDesc;\n",
    "    memset(&weightsTexDesc, 0, sizeof(weightsTexDesc));\n",
    "    memset(&neighTexDesc, 0, sizeof(neighTexDesc));\n",
    "    weightsTexDesc.readMode = cudaReadModeElementType;\n",
    "    neighTexDesc.readMode = cudaReadModeElementType;\n",
    "\n",
    "    // create texture object: we only have to do this once!\n",
    "    cudaTextureObject_t weightsTex, neighsTex;\n",
    "    cudaCreateTextureObject(&weightsTex, &weightsDesc, &weightsTexDesc, NULL);\n",
    "    cudaCreateTextureObject(&neighsTex, &neighDesc, &neighTexDesc, NULL);\n",
    "\n",
    "    printf(\"CPU procedure...\\n\");\n",
    "\t  double go = seconds();\n",
    "    for (uint i = 0; i < size; i++) {\n",
    "        int min = INT_MAX;\n",
    "        uint minOffset = 0;\n",
    "        for (uint j = 0; j < str->deg(i); j++) {\n",
    "            if (str->getWeight(i, j) < min) {\n",
    "                min = str->getWeight(i, j);\n",
    "                minOffset = j;\n",
    "            }\n",
    "        }\n",
    "        CPUCandidates[i] = minOffset;\n",
    "    }\n",
    "    cpuTime = seconds() - go;\n",
    "    printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", cpuTime);\n",
    "\n",
    "    cudaEventRecord(start);\n",
    "    findCheapest <<<gridDim, blockDim>>> (str, d_candidates);\n",
    "    cudaEventRecord(stop);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    CHECK(cudaEventSynchronize(stop));\n",
    "    CHECK(cudaMemcpy(candidates, d_candidates, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "    gpuTime = milliseconds / 1000.0;\n",
    "    printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", gpuTime);\n",
    "\n",
    "    for (uint i = 0; i < size; i++) {\n",
    "        if (CPUCandidates[i] != candidates[i]) {\n",
    "            printf(\"The two vectors are different at position %d\\n\", i);\n",
    "            return -1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"The speedup is %.3f\\n\", cpuTime/gpuTime);\n",
    "\n",
    "    cudaEventRecord(start);\n",
    "    findCheapestTexture <<<gridDim, blockDim>>> (str, d_candidates, weightsTex, neighsTex);\n",
    "    cudaEventRecord(stop);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    CHECK(cudaEventSynchronize(stop));\n",
    "    CHECK(cudaMemcpy(candidates, d_candidates, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "    gpuETime = milliseconds / 1000.0;\n",
    "    printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", gpuETime);\n",
    "\n",
    "    for (uint i = 0; i < size; i++) {\n",
    "        if (CPUCandidates[i] != candidates[i]) {\n",
    "            printf(\"The two vectors are different at position %d\\n\", i);\n",
    "            printf(\"%d - %d\\n\", CPUCandidates[i], candidates[i]);\n",
    "            return -1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"The speedup is with respect to the CPU is %.3f\\n\", cpuTime/gpuETime);\n",
    "    printf(\"The speedup is with respect to the GPU is %.3f\\n\", gpuTime/gpuETime);\n",
    "\n",
    "    // destroy texture object\n",
    "    //cudaDestroyTextureObject(tex);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jED-4P-u4piR",
    "outputId": "da3fb5e8-c2bf-45fd-8524-05c14d8a85f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing a graph of size: 50000 with 25004636 edges.\n",
      "\n",
      "CPU procedure...\n",
      "Finding the cheapest edge for every vertex took: 0.15420 seconds\n",
      "\n",
      "Finding the cheapest edge for every vertex took: 0.03561 seconds\n",
      "\n",
      "The speedup is 4.330\n",
      "Finding the cheapest edge for every vertex took: 0.02305 seconds\n",
      "\n",
      "The speedup is with respect to the CPU is 6.691\n",
      "The speedup is with respect to the GPU is 1.545\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_75 -rdc=true -lcudadevrt GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/TESTING/mfTexture.cu -o mfTexture\n",
    "!./mfTexture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwhvV2EtcDXQ"
   },
   "source": [
    "## Segmented scan based fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmUCw0uScJsH"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"newFetch.cu\" --group \"TESTING\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <limits.h>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "/*****\n",
    "* Device function that gets the degree of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The node we are interested in\n",
    "*****/\n",
    "__device__ node d_deg (GraphStruct *str, node i) {\n",
    "    return str->cumDegs[i + 1] - str->cumDegs[i];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the weight of a certain edge\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ int d_getWeight (GraphStruct *str, node i, uint offset) {\n",
    "    return str->weights[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the neighbour of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
    "    return str->neighs[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "__device__ uint d_getPosition(GraphStruct *str, node i, uint offset) {\n",
    "    return str->cumDegs[i] + offset;\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void findMinimumForVertex(GraphStruct *str, uint *d_aux, uint *d_auxOffset, int smemSize, node vertex)\n",
    "{\n",
    "  printf(\"%d\\n\", vertex);\n",
    "  extern __shared__ int temp[];\n",
    "  int thid = threadIdx.x;\n",
    "  int offset = 1;\n",
    "  int idx = blockIdx.x * blockDim.x + thid;\n",
    "  int n = d_deg(str, vertex);\n",
    "\n",
    "  // Zero relative to the start of the array\n",
    "  int relativeZero = str->cumDegs[vertex];\n",
    "\n",
    "  // load input into shared memory\n",
    "  temp[2 * thid] = (2 * idx < n) ? (int) (2 * idx) : NO_VALUE;\n",
    "  temp[2 * thid + 1] = (2 * idx + 1 < n) ? (int) (2 * idx + 1) : NO_VALUE;\n",
    "\n",
    "\n",
    "  // build sum in place up the tree\n",
    "  for (int d = smemSize>>1; d > 0; d >>= 1)\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "          int aiWeight = (temp[ai] != NO_VALUE) ? str->weights[relativeZero + temp[ai]] : INT_MAX;\n",
    "          int biWeight = (temp[bi] != NO_VALUE) ? str->weights[relativeZero + temp[bi]] : INT_MAX;\n",
    "          temp[bi] = (aiWeight < biWeight) ? temp[ai] : temp[bi];\n",
    "      }\n",
    "    }\n",
    "    offset *= 2;\n",
    "  }\n",
    "\n",
    "  printf(\"%d\\n\", vertex);\n",
    "  if (vertex == 0) {\n",
    "      if (idx == 0) {\n",
    "          printf(\"%d\\n\", n);\n",
    "      }\n",
    "      printf(\"temp[2 * %d]: %d    temp[2 * %d + 1]: %d\\n\", thid, temp[2 * thid], thid, temp[2 * thid + 1]);\n",
    "  }\n",
    "\n",
    "  if (thid == 0)\n",
    "  {\n",
    "    d_aux[blockIdx.x + d_auxOffset[vertex]] = temp[smemSize - 1];\n",
    "  }\n",
    "}\n",
    "\n",
    "__global__ void findMinimum(GraphStruct *str, uint *d_aux, uint *d_auxOffset, uint *d_candidates) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    int min = INT_MAX;\n",
    "    for (uint i = 0; i < (d_deg(str, idx) + (2 * blockDim.x) - 1) / (2 * blockDim.x); i++) {\n",
    "        //printf(\"%d\\n\", d_aux[d_auxOffset[idx] + i]);\n",
    "        int weight = d_getWeight(str, idx, d_aux[d_auxOffset[idx] + i]);\n",
    "        if (weight < min) {\n",
    "            min = weight;\n",
    "            d_candidates[idx] = d_aux[d_auxOffset[idx] + i];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void findCheapestTexture (GraphStruct *str, uint *d_candidates, cudaTextureObject_t wtex, cudaTextureObject_t ntex) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // Initialize the minimum value\n",
    "    uint minimum = UINT_MAX;\n",
    "    int minimumWeight = INT_MAX;\n",
    "\n",
    "    // Find the cheapest edge in each adjacency list\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        uint pos = d_getPosition(str, idx, i);\n",
    "        int edgeWeight = tex1Dfetch<int>(wtex, pos);\n",
    "        if (edgeWeight < minimumWeight) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "        else {\n",
    "            uint neigh = tex1Dfetch<int>(ntex, pos);\n",
    "            pos = d_getPosition(str, idx, minimum);\n",
    "            uint miNeigh = (minimum == UINT_MAX) ?  UINT_MAX : tex1Dfetch<int>(ntex, pos);\n",
    "\n",
    "            if (edgeWeight == minimumWeight && neigh < miNeigh) {\n",
    "                minimumWeight = edgeWeight;\n",
    "                minimum = i;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Update the return vector\n",
    "    d_candidates[idx] = minimum;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Generation of a random graph\n",
    "    std::random_device rd;\n",
    "    std::default_random_engine eng(FIXED_SEED);\n",
    "    uint maxWeight = MAX_WEIGHT;\n",
    "    float prob = PROBABILITY;\n",
    "    bool GPUEnabled = 1;\n",
    "    Graph *graphPointer;\n",
    "    Graph graph(SIZE, GPUEnabled);\n",
    "    graphPointer = &graph;\n",
    "  \tgraphPointer->randGraph(prob, true, maxWeight, eng);\n",
    "    /**************************************************/\n",
    "\n",
    "\n",
    "    // Checking if the random graph is connected\n",
    "    if (!graphPointer->isConnected()) {\n",
    "        cout << \"The graph is not connected\" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "    /************/\n",
    "\n",
    "    // Initialization of the variables associated with the graph\n",
    "    GraphStruct *str = graphPointer->getStruct();\n",
    "    uint size = str->nodeSize;\n",
    "    uint edgeSize = str->edgeSize;\n",
    "    cout << \"Processing a graph of size: \" << size << \" with \" << edgeSize << \" edges.\\n\\n\";\n",
    "    uint *candidates = new uint[size];\n",
    "    uint *CPUCandidates = new uint[size];\n",
    "\n",
    "    // First setp of the algorithm\n",
    "    uint *d_candidates;\n",
    "    CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
    "    CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
    "\n",
    "    uint blockDim = BLOCK_SIZE;\n",
    "    uint gridDim = (size + blockDim - 1) / blockDim;\n",
    "\n",
    "    // Events to measure time\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    float milliseconds;\n",
    "    float cpuTime, gpuTime, gpuETime;\n",
    "\n",
    "    // create texture object\n",
    "    cudaResourceDesc weightsDesc;\n",
    "    memset(&weightsDesc, 0, sizeof(weightsDesc));\n",
    "    weightsDesc.resType = cudaResourceTypeLinear;\n",
    "    weightsDesc.res.linear.devPtr = str->weights;\n",
    "    weightsDesc.res.linear.desc.f = cudaChannelFormatKindSigned;\n",
    "    weightsDesc.res.linear.desc.x = 32; // bits per channel\n",
    "    weightsDesc.res.linear.sizeInBytes = edgeSize * sizeof(uint);\n",
    "\n",
    "    cudaResourceDesc neighDesc;\n",
    "    memset(&neighDesc, 0, sizeof(neighDesc));\n",
    "    neighDesc.resType = cudaResourceTypeLinear;\n",
    "    neighDesc.res.linear.devPtr = str->weights;\n",
    "    neighDesc.res.linear.desc.f = cudaChannelFormatKindUnsigned;\n",
    "    neighDesc.res.linear.desc.x = 32; // bits per channel\n",
    "    neighDesc.res.linear.sizeInBytes = edgeSize * sizeof(uint);\n",
    "\n",
    "    cudaTextureDesc weightsTexDesc, neighTexDesc;\n",
    "    memset(&weightsTexDesc, 0, sizeof(weightsTexDesc));\n",
    "    memset(&neighTexDesc, 0, sizeof(neighTexDesc));\n",
    "    weightsTexDesc.readMode = cudaReadModeElementType;\n",
    "    neighTexDesc.readMode = cudaReadModeElementType;\n",
    "\n",
    "    // create texture object: we only have to do this once!\n",
    "    cudaTextureObject_t weightsTex, neighsTex;\n",
    "    cudaCreateTextureObject(&weightsTex, &weightsDesc, &weightsTexDesc, NULL);\n",
    "    cudaCreateTextureObject(&neighsTex, &neighDesc, &neighTexDesc, NULL);\n",
    "\n",
    "    printf(\"CPU procedure...\\n\");\n",
    "\t  double go = seconds();\n",
    "    for (uint i = 0; i < size; i++) {\n",
    "        int min = INT_MAX;\n",
    "        uint minOffset = 0;\n",
    "        for (uint j = 0; j < str->deg(i); j++) {\n",
    "            if (str->getWeight(i, j) < min) {\n",
    "                min = str->getWeight(i, j);\n",
    "                minOffset = j;\n",
    "            }\n",
    "        }\n",
    "        CPUCandidates[i] = minOffset;\n",
    "    }\n",
    "    cpuTime = seconds() - go;\n",
    "    printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", cpuTime);\n",
    "\n",
    "        // Compute the ratio between the outdegree and the smem size\n",
    "        uint smemSize = 2 * blockDim;\n",
    "        uint auxSize = 0;\n",
    "\n",
    "        // Compute the ratio between the outdegree and the smem size\n",
    "\n",
    "        printf(\"smemSize: %d   blockDim: %d   size: %d   edgeSize: %d\\n\", smemSize, blockDim, size, edgeSize);\n",
    "\n",
    "        // Compute the size of the auxiliary array\n",
    "        for (uint i = 0; i < size; i++) {\n",
    "            uint outdegree = str->deg(i);\n",
    "            auxSize += (outdegree + smemSize - 1) / smemSize;\n",
    "        }\n",
    "        printf(\"auxSize: %d\\n\", auxSize);\n",
    "\n",
    "\n",
    "        // Allocating resources for the support arrays\n",
    "        uint *aux, *auxOffset, *d_auxOffset, *d_aux;\n",
    "        candidates = new uint[size];\n",
    "        aux = (uint *) malloc(auxSize * sizeof(uint));\n",
    "        auxOffset = (uint *) malloc(size * sizeof(uint));\n",
    "        CHECK(cudaMalloc((void **) &d_aux, auxSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_aux, INT_MAX, auxSize * sizeof(uint)));\n",
    "\n",
    "        // Copy the contents of auxOffset to device memory\n",
    "        CHECK(cudaMalloc((void **) &d_auxOffset, size * sizeof(uint)));\n",
    "        for (node i = 0; i < size; i++) {\n",
    "            auxOffset[i] = (i == 0) ? 0 : auxOffset[i - 1] + (str->deg(i - 1) + smemSize - 1) / smemSize;\n",
    "        }\n",
    "        CHECK(cudaMemcpy(d_auxOffset, auxOffset, size * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        for (node i = 0; i < size; i++) {\n",
    "            uint gridSize = (str->deg(i) + smemSize - 1) / smemSize;\n",
    "            int smem = smemSize * sizeof(uint);\n",
    "\n",
    "            printf(\"%d > str->cumDegs[i]: %d   auxOffset[i]: %d   str->deg(i): %d   gridSize: %d\\n\", i, str->cumDegs[i], auxOffset[i], str->deg(i), gridSize);\n",
    "\n",
    "            if (str->deg(i) >= blockDim) {\n",
    "                findMinimumForVertex <<< gridSize, blockDim, smem >>> (str, d_aux, d_auxOffset, smemSize, i);\n",
    "            }\n",
    "        }\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        gpuETime = milliseconds / 1000.0;\n",
    "        printf(\"Doing a preliminary minimum search took: %.5f seconds\\n\\n\", milliseconds / 1000.0);\n",
    "\n",
    "        CHECK(cudaMemcpy(aux, d_aux, auxSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        uint nanValues = 0;\n",
    "        for (uint i = 0; i < auxSize; i++) {\n",
    "            //printf(\"aux[%d]: %d\\n\", i, aux[i]);\n",
    "            if (aux[i] == UINT_MAX) {\n",
    "                nanValues++;\n",
    "            }\n",
    "        }\n",
    "        printf(\"There are %d NaN values out of %d\\n\", nanValues, auxSize);\n",
    "return 0;\n",
    "        // For every vertex pick the lightest edge\n",
    "        CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
    "        cudaEventRecord(start);\n",
    "        findMinimum <<< gridDim, blockDim >>> (str, d_aux, d_auxOffset, d_candidates);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        gpuETime += milliseconds / 1000.0;\n",
    "        printf(\"Picking the minimum for every vertex: %.5f seconds\\n\\n\", milliseconds / 1000.0);\n",
    "\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        printf(\"Using parallel scan took %.5f seconds\\n\\n\", gpuETime);\n",
    "\n",
    "    for (uint i = 0; i < size; i++) {\n",
    "        if (str->getWeight(i, CPUCandidates[i]) < str->getWeight(i, candidates[i])) {\n",
    "            printf(\"The two vectors are different at position %d\\n\", i);\n",
    "            printf(\"%d - %d\\n\", CPUCandidates[i], candidates[i]);\n",
    "            return -1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(start);\n",
    "    findCheapestTexture <<<gridDim, blockDim>>> (str, d_candidates, weightsTex, neighsTex);\n",
    "    cudaEventRecord(stop);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    CHECK(cudaEventSynchronize(stop));\n",
    "    CHECK(cudaMemcpy(candidates, d_candidates, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "    gpuTime = milliseconds / 1000.0;\n",
    "    printf(\"Using the textures to find the cheapest edge took: %.5f seconds\\n\\n\", gpuTime);\n",
    "\n",
    "    for (uint i = 0; i < size; i++) {\n",
    "        if (CPUCandidates[i] != candidates[i]) {\n",
    "            printf(\"The two vectors are different at position %d\\n\", i);\n",
    "            printf(\"%d - %d\\n\", CPUCandidates[i], candidates[i]);\n",
    "            return -1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"The speedup is with respect to the CPU is %.3f\\n\", cpuTime/gpuETime);\n",
    "    printf(\"The speedup is with respect to the GPU is %.3f\\n\", gpuTime/gpuETime);\n",
    "\n",
    "    // destroy texture object\n",
    "    //cudaDestroyTextureObject(tex);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAbc6t-QcPfp"
   },
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -rdc=true -lcudadevrt GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/TESTING/newFetch.cu -o newFetch\n",
    "!./newFetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwQlFQ0uR2nc"
   },
   "source": [
    "## Read graph from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eya8cgpKR8Pm"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"readGraph.cu\" --group \"TESTING\"\n",
    "\n",
    "#include <fstream>\n",
    "#include <string>\n",
    "#include <iostream>\n",
    "#include <sstream>\n",
    "\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "Graph *initializeGraph(string line) {\n",
    "    stringstream ss(line);\n",
    "    string element;\n",
    "    uint nodeSize;\n",
    "    uint edgeSize;\n",
    "\n",
    "    ss >> element;\n",
    "    nodeSize = stoi(element);\n",
    "    ss >> element;\n",
    "    edgeSize = stoi(element);\n",
    "\n",
    "    Graph *graph = new Graph(nodeSize, edgeSize, 1);\n",
    "    return graph;\n",
    "}\n",
    "\n",
    "void readEdge(string line, vector<uint> *edges, vector<int> *weights, GraphStruct *str) {\n",
    "    stringstream ss(line);\n",
    "    string element;\n",
    "    node source, destination;\n",
    "    int weight;\n",
    "\n",
    "    ss >> element;\n",
    "    source = stoi(element) - 1;\n",
    "    ss >> element;\n",
    "    destination = stoi(element) - 1;\n",
    "    ss >> element;\n",
    "    weight = stoi(element);\n",
    "\n",
    "    str->cumDegs[source + 1]++;\n",
    "\n",
    "    edges[source].push_back(destination);\n",
    "    weights[source].push_back(weight);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    ifstream inFile;\n",
    "    string path = \"/content/small.txt\";\n",
    "    string line;\n",
    "    Graph *graph;\n",
    "\n",
    "    inFile.open(path);\n",
    "\n",
    "    if (!inFile) {\n",
    "        cout << \"Unable to open file\";\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    getline(inFile, line);\n",
    "    graph = initializeGraph(line);\n",
    "    GraphStruct *str = graph->getStruct();\n",
    "    uint nodeSize = str->nodeSize;\n",
    "    uint edgeSize = str->edgeSize;\n",
    "    printf(\"%d\\t%d\\n\", nodeSize, edgeSize);\n",
    "    vector<uint> *edges = new vector<uint>[edgeSize];\n",
    "\t  vector<int> *weights = new vector<int>[edgeSize];\n",
    "\n",
    "    while (getline(inFile, line)) {\n",
    "        readEdge(line, edges, weights, str);\n",
    "    }\n",
    "\n",
    "    for (node i = 0; i < nodeSize; ++i) {\n",
    "        str->cumDegs[i + 1] += str->cumDegs[i];\n",
    "        str->outdegrees[i] = str->cumDegs[i + 1] - str->cumDegs[i];\n",
    "    }\n",
    "\n",
    "    for (node i = 0; i < nodeSize; ++i) {\n",
    "        memcpy((str->neighs + str->cumDegs[i]), edges[i].data(), sizeof(uint) * edges[i].size());\n",
    "\t\t    memcpy((str->weights + str->cumDegs[i]), weights[i].data(), sizeof(int) * weights[i].size());\n",
    "    }\n",
    "\n",
    "    graph->print(true);\n",
    "    print_d <<<1, 1>>> (str, 1);\n",
    "\n",
    "    inFile.close();\n",
    "\n",
    "    delete graph;\n",
    "    graph = NULL;\n",
    "    delete[] edges;\n",
    "    edges = NULL;\n",
    "    delete[] weights;\n",
    "    weights = NULL;\n",
    "\n",
    "    return graph;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0PbzkmpSFdc",
    "outputId": "256112b6-0d2f-4715-ef53-8475778e9c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01m\u001b[0m\u001b[01msrc/TESTING/readGraph.cu(61)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"i\"\u001b[0m was declared but never referenced\n",
      "      uint i = 0;\n",
      "           ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "11\t12\n",
      "** Graph (num node: 11, num edges: 12)\n",
      "         (min deg: 0, max deg: 0, mean deg: 0, connected: 1)\n",
      "   node(0)[1]-> 1(803) \n",
      "   node(1)[1]-> 0(803) \n",
      "   node(2)[1]-> 3(158) \n",
      "   node(3)[1]-> 2(158) \n",
      "   node(4)[1]-> 5(774) \n",
      "   node(5)[1]-> 4(774) \n",
      "   node(6)[1]-> 7(1531) \n",
      "   node(7)[1]-> 6(1531) \n",
      "   node(8)[2]-> 9(1673) 10(1400) \n",
      "   node(9)[1]-> 8(1673) \n",
      "   node(10)[0]-> \n",
      "\n",
      "** Graph (num node: 11, num edges: 12)\n",
      "  node(0)[1]-> 1(803) \n",
      "  node(1)[1]-> 0(803) \n",
      "  node(2)[1]-> 3(158) \n",
      "  node(3)[1]-> 2(158) \n",
      "  node(4)[1]-> 5(774) \n",
      "  node(5)[1]-> 4(774) \n",
      "  node(6)[1]-> 7(1531) \n",
      "  node(7)[1]-> 6(1531) \n",
      "  node(8)[2]-> 9(1673) 10(1400) \n",
      "  node(9)[1]-> 8(1673) \n",
      "  node(10)[0]-> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_75 -rdc=true -lcudadevrt GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/TESTING/readGraph.cu -o readGraph\n",
    "!./readGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scPfLP48iEId"
   },
   "source": [
    "## Other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqflBl-0MTW9"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"mst.h\" --group \"GPU\"\n",
    "#ifndef MST_H\n",
    "#define MST_H\n",
    "\n",
    "cudaResourceDesc generateCudaDescriptor(GraphStruct *str, uint field, uint size, size_t type, cudaChannelFormatKind chDesc) {\n",
    "    cudaResourceDesc descriptor;\n",
    "    memset(&descriptor, 0, sizeof(descriptor));\n",
    "    descriptor.resType = cudaResourceTypeLinear;\n",
    "    if (field == 0) {\n",
    "        descriptor.res.linear.devPtr = str->weights;\n",
    "    }\n",
    "    else if (field == 1) {\n",
    "        descriptor.res.linear.devPtr = str->outdegrees;\n",
    "    }\n",
    "    else if (field == 2) {\n",
    "        descriptor.res.linear.devPtr = str->cumDegs;\n",
    "    }\n",
    "    else {\n",
    "        descriptor.res.linear.devPtr = str->neighs;\n",
    "    }\n",
    "    descriptor.res.linear.desc.f = chDesc;\n",
    "    descriptor.res.linear.desc.x = 32; // bits per channel\n",
    "    descriptor.res.linear.sizeInBytes = size * type;\n",
    "\n",
    "    return descriptor;\n",
    "}\n",
    "\n",
    "cudaTextureDesc generateTextureDescriptor() {\n",
    "    cudaTextureDesc texDesc;\n",
    "    memset(&texDesc, 0, sizeof(texDesc));\n",
    "    texDesc.readMode = cudaReadModeElementType;\n",
    "\n",
    "    return texDesc;\n",
    "}\n",
    "\n",
    "__device__\n",
    "node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
    "    return str->neighs[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "#endif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuYh_aea_g4r"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"mst.cu\" --group \"GPU\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <limits.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "#include \"../COMMON/readGraph.h\"\n",
    "#include \"mst.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "cudaTextureObject_t wtex, otex, ntex, cdtex;\n",
    "\n",
    "void cpuScan(uint *array, int start, int end) {\n",
    "    if (end - start <= 1) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    int temp = array[start + 1];\n",
    "    array[start + 1] = array[start];\n",
    "    array[start] = 0;\n",
    "\n",
    "    for (uint i = start + 1; i < end - 1; i++) {\n",
    "        int sum = array[i] + temp;\n",
    "        temp = array[i + 1];\n",
    "        array[i + 1] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "uint getRoot (uint i, uint *svIds, uint *colors) {\n",
    "    return max(0, svIds[colors[i]]);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "__device__\n",
    "uint d_getRoot (uint i, uint *d_svIds, uint *d_colors) {\n",
    "    return max(0, d_svIds[d_colors[i]]);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__\n",
    "void findCheapest(GraphStruct *str, cudaTextureObject_t ntex, cudaTextureObject_t otex, cudaTextureObject_t wtex, cudaTextureObject_t cdtex, uint *d_candidates) {\n",
    "    // Initialize one thread per node\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "\n",
    "    // Check the boundary condition\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint medge = 0;\n",
    "    int wmin = INT_MAX;\n",
    "    uint nmin = 0;\n",
    "\n",
    "    uint edge = tex1Dfetch<uint>(cdtex, idx);\n",
    "    uint loopEnd = edge + tex1Dfetch<uint>(otex, idx);\n",
    "    while (edge < loopEnd) {\n",
    "        int weight = tex1Dfetch<int>(wtex, edge);\n",
    "        uint neigh = tex1Dfetch<uint>(ntex, edge);\n",
    "\n",
    "\n",
    "        if (weight < wmin) {\n",
    "            wmin = weight;\n",
    "            medge = edge;\n",
    "            nmin = neigh;\n",
    "        }\n",
    "        else if (weight == wmin && neigh < nmin) {\n",
    "            wmin = weight;\n",
    "            medge = edge;\n",
    "            nmin = neigh;\n",
    "        }\n",
    "\n",
    "        ++edge;\n",
    "    }\n",
    "\n",
    "    d_candidates[idx] = medge;\n",
    "}\n",
    "\n",
    "__global__\n",
    "void findCheapestUnified(GraphStruct *str, uint *d_candidates) {\n",
    "    // Initialize one thread per node\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "\n",
    "    // Check the boundary condition\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint medge = 0;\n",
    "    int wmin = INT_MAX;\n",
    "    uint nmin = 0;\n",
    "\n",
    "    uint edge = str->cumDegs[idx];\n",
    "    uint loopEnd = edge + str->outdegrees[idx];\n",
    "    while (edge < loopEnd) {\n",
    "        int weight = str->weights[edge];\n",
    "        node neigh = str->neighs[edge];\n",
    "\n",
    "        if (weight < wmin) {\n",
    "            wmin = weight;\n",
    "            medge = edge;\n",
    "            nmin = neigh;\n",
    "        }\n",
    "        else if (weight == wmin && neigh < nmin) {\n",
    "            wmin = weight;\n",
    "            medge = edge;\n",
    "            nmin = neigh;\n",
    "        }\n",
    "\n",
    "        ++edge;\n",
    "    }\n",
    "\n",
    "    d_candidates[idx] = medge;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__\n",
    "void removeMirroredEdges(GraphStruct *str, cudaTextureObject_t ntex, uint *d_candidates) {\n",
    "    // Initialize one thread per node\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (idx > str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint edge = d_candidates[idx];\n",
    "    node neigh = tex1Dfetch<node>(ntex, edge);\n",
    "    uint nedge = d_candidates[neigh];\n",
    "    node nneigh = tex1Dfetch<node>(ntex, nedge);\n",
    "\n",
    "    if (nneigh == idx && neigh > idx) {\n",
    "        d_candidates[idx] = UINT_MAX;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__\n",
    "void removeMirroredEdgesUnified (GraphStruct *str, uint *d_candidates, unsigned long long int *d_weight) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint dedge = d_candidates[idx];\n",
    "    node destination = str->neighs[dedge];\n",
    "    if (idx < destination) {\n",
    "        uint sedge = d_candidates[destination] == UINT_MAX;\n",
    "        if (sedge == UINT_MAX) {\n",
    "            return;\n",
    "        }\n",
    "        node destinationNeigh = str->neighs[sedge];\n",
    "\n",
    "        // The vertex cannot be a candidate anymore because it would create a cycle\n",
    "        if (destinationNeigh == idx) {\n",
    "            d_candidates[idx] = UINT_MAX;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    uint cedge = d_candidates[idx];\n",
    "    if (d_candidates[idx] != UINT_MAX) {\n",
    "        atomicAdd(d_weight, str->weights[cedge]);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__device__\n",
    "uint *d_recursiveColorationHelper (GraphStruct *str, uint *d_candidates, node i, uint *d_colors) {\n",
    "    uint color = UINT_MAX;\n",
    "    uint edge = d_candidates[i];\n",
    "    if (edge == UINT_MAX) {\n",
    "        color = i;\n",
    "    }\n",
    "    else {\n",
    "        node neigh = str->neighs[edge];\n",
    "        color = d_recursiveColorationHelper(str, d_candidates, neigh, d_colors)[neigh];\n",
    "    }\n",
    "\n",
    "\n",
    "    if (color != UINT_MAX) {\n",
    "        d_colors[i] = color;\n",
    "    }\n",
    "    return d_colors;\n",
    "}\n",
    "\n",
    "__global__\n",
    "void colorationProcess (GraphStruct *str, uint *d_candidates, uint *d_colors) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    d_recursiveColorationHelper(str, d_candidates, idx, d_colors);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__\n",
    "void svIdentification (GraphStruct *str, uint *d_colors, uint *d_candidates, uint *d_isSupervertex) {\n",
    "    // Initialize one thread per node\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    if (d_colors[idx] == idx && str->outdegrees[idx] > 0) {\n",
    "        d_isSupervertex[idx] = 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__\n",
    "void prescan(uint *g_odata, uint *g_idata, uint *aux, int n, int smemSize)\n",
    "{\n",
    "  extern __shared__ int temp[];// allocated on invocation\n",
    "  int thid = threadIdx.x;\n",
    "  int offset = 1;\n",
    "  int idx = blockIdx.x * blockDim.x + thid;\n",
    "\n",
    "  // load input into shared memory\n",
    "  temp[2 * thid] =  (2 * idx < n) ? g_idata[2 * idx] : 0;\n",
    "  temp[2 * thid + 1] = (2 * idx + 1 < n) ? g_idata[2 * idx + 1] : 0;\n",
    "  //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "      //printf(\"UPSWEEP\\n\");\n",
    "  //}\n",
    "\n",
    "  //printf(\"%d >> left: %d   right: %d\\n\", thid, temp[2 * thid], temp[2 * thid + 1]);\n",
    "\n",
    "  for (int d =smemSize>>1; d > 0; d >>= 1) // build sum in place up the tree\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        temp[bi] += temp[ai];\n",
    "      }\n",
    "    }\n",
    "    offset *= 2;\n",
    "  }\n",
    "\n",
    "  //printf(\"%d >> right: %d   left: %d\\n\", thid, temp[2 * thid], temp[2 * thid + 1]);\n",
    "\n",
    "  if (thid == 0)\n",
    "  {\n",
    "    aux[blockIdx.x] = temp[smemSize - 1];\n",
    "    temp[smemSize - 1] = 0;\n",
    "  }\n",
    "\n",
    "  //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "      //printf(\"DOWNSWEEP\\n\");\n",
    "  //}\n",
    "\n",
    "  for (int d = 1; d < smemSize; d *= 2) // traverse down tree & build scan\n",
    "  {\n",
    "      offset >>= 1;\n",
    "    __syncthreads();\n",
    "\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        //printf(\"%d >> ai: %d   bi: %d   temp[ai]: %d   temp[bi]: %d\\n\", thid, ai, bi, temp[ai], temp[bi]);\n",
    "        int t = temp[ai];\n",
    "        temp[ai] = temp[bi];\n",
    "        temp[bi] += t;\n",
    "      }\n",
    "    }\n",
    "    //if (2 * idx == n - 1) {\n",
    "        //printf(\"temp[n - 1]: %d\\n\", temp[2 * thid]);\n",
    "    //}\n",
    "    //if (2 * idx + 1 == n - 1) {\n",
    "        //printf(\"temp[n - 1]: %d\\n\", temp[2 * thid + 1]);\n",
    "    //}\n",
    "  }\n",
    "\n",
    "  //printf(\"%d >> right: %d   left: %d\\n\", thid, temp[2 * thid], temp[2 * thid + 1]);\n",
    "\n",
    "\n",
    "  __syncthreads();\n",
    "  if (idx <= (n / 2)) {\n",
    "      g_odata[2*idx] = temp[2*thid]; // write results to device memory\n",
    "      g_odata[2*idx+1] = temp[2*thid+1];\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "__global__\n",
    "void final_sum(uint *g_odata, uint *aux, uint n)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "  if (blockIdx.x == 0 || 2 * idx >= n) {\n",
    "      return;\n",
    "  }\n",
    "\n",
    "  //printf(\"%d: ls - %d  rs - %d  aux - %d\\n\", idx, g_odata[2 * idx], g_odata[2 * idx + 1], aux[blockIdx.x - 1]);\n",
    "\n",
    "  if (2 * idx == n - 1) {\n",
    "      g_odata[2 * idx] += aux[blockIdx.x];\n",
    "      return;\n",
    "  }\n",
    "  g_odata[2 * idx] += aux[blockIdx.x];\n",
    "  g_odata[2 * idx + 1] += aux[blockIdx.x];\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__\n",
    "void countNewEdges(GraphStruct *str, cudaTextureObject_t ntex, cudaTextureObject_t otex, cudaTextureObject_t cdtex, uint *d_colors, uint *d_svIds, uint *newOutdegrees) {\n",
    "    // Initialize one thread per node\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint edge = tex1Dfetch<uint>(cdtex, idx);\n",
    "    uint loopEnd = edge + tex1Dfetch<uint>(otex, idx);\n",
    "    uint newEdges = 0;\n",
    "    uint color = d_colors[idx];\n",
    "    while (edge < loopEnd) {\n",
    "        node neigh = tex1Dfetch<node>(ntex, edge);\n",
    "\n",
    "        if (d_colors[neigh] != color) {\n",
    "            ++newEdges;\n",
    "        }\n",
    "        ++edge;\n",
    "    }\n",
    "\n",
    "    node sv = d_getRoot(idx, d_svIds, d_colors);\n",
    "    atomicAdd(&newOutdegrees[sv], newEdges);\n",
    "}\n",
    "\n",
    "__global__\n",
    "void countNewEdgesUnified(GraphStruct *str, uint *d_colors, uint *d_svIds, uint *newOutdegrees) {\n",
    "    // Initialize one thread per node\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint edge = str->cumDegs[idx];\n",
    "    uint loopEnd = edge + str->outdegrees[idx];\n",
    "    uint newEdges = 0;\n",
    "    uint color = d_colors[idx];\n",
    "    while (edge < loopEnd) {\n",
    "        node neigh = str->neighs[edge];\n",
    "\n",
    "        if (d_colors[neigh] != color) {\n",
    "            ++newEdges;\n",
    "        }\n",
    "        ++edge;\n",
    "    }\n",
    "\n",
    "    node sv = d_getRoot(idx, d_svIds, d_colors);\n",
    "    atomicAdd(&newOutdegrees[sv], newEdges);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__\n",
    "void graphContraction(GraphStruct *str, cudaTextureObject_t ntex, cudaTextureObject_t otex, cudaTextureObject_t cdtex, cudaTextureObject_t wtex,\n",
    "                      uint *newNeighs, uint *newWeights, uint *d_colors, uint *d_newCumDegs, uint *d_svIds) {\n",
    "    // Initialize one thread per node\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint edge = tex1Dfetch<uint>(cdtex, idx);\n",
    "    uint loopEnd = edge + tex1Dfetch<uint>(otex, idx);\n",
    "    uint color = d_colors[idx];\n",
    "\n",
    "    while (edge < loopEnd) {\n",
    "        node neigh = tex1Dfetch<node>(ntex, edge);\n",
    "\n",
    "        if (d_colors[neigh] != color) {\n",
    "            node osv = d_getRoot(idx, d_svIds, d_colors);\n",
    "            node dsv = d_getRoot(neigh, d_svIds, d_colors);\n",
    "            uint position = atomicAdd(&(d_newCumDegs[osv]), 1);\n",
    "            newNeighs[position] = dsv;\n",
    "            newWeights[position] = tex1Dfetch<int>(wtex, edge);\n",
    "        }\n",
    "        ++edge;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__\n",
    "void graphContractionUnified(GraphStruct *str, uint *newNeighs, uint *newWeights, uint *d_colors, uint *d_newCumDegs, uint *d_svIds) {\n",
    "    // Initialize one thread per node\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint edge = str->cumDegs[idx];\n",
    "    uint loopEnd = edge + str->outdegrees[idx];\n",
    "    uint color = d_colors[idx];\n",
    "\n",
    "    while (edge < loopEnd) {\n",
    "        node neigh = str->neighs[edge];\n",
    "\n",
    "        if (d_colors[neigh] != color) {\n",
    "            node osv = d_getRoot(idx, d_svIds, d_colors);\n",
    "            node dsv = d_getRoot(neigh, d_svIds, d_colors);\n",
    "            uint position = atomicAdd(&(d_newCumDegs[osv]), 1);\n",
    "            newNeighs[position] = dsv;\n",
    "            newWeights[position] = str->weights[edge];\n",
    "        }\n",
    "        ++edge;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main() {\n",
    "    // Generation of a random graph\n",
    "    Graph *graph;\n",
    "\n",
    "    if (TESTING) {\n",
    "        string path(\"/content/ny.txt\");\n",
    "        printf(\"Generating graph from file\\n\");\n",
    "        graph = rgraph(path, true);\n",
    "    }\n",
    "    else {\n",
    "        std::random_device rd;\n",
    "        std::default_random_engine eng(FIXED_SEED);\n",
    "        uint maxWeight = MAX_WEIGHT;\n",
    "        float prob = PROBABILITY;\n",
    "        bool GPUEnabled = 1;\n",
    "        graph = new Graph(SIZE, GPUEnabled);\n",
    "        graph->randGraph(prob, true, maxWeight, eng);\n",
    "\n",
    "        if (!graph->isConnected()) {\n",
    "            cout << \"The graph is not connected\" << endl;\n",
    "            return -1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    uint iterations = 1;\n",
    "\n",
    "\n",
    "    // Events to measure time\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    uint tArraySize = TIME_ARRAY_SIZE;\n",
    "    float milliseconds;\n",
    "    float *timings = new float[tArraySize];\n",
    "    float *timingsUnified = new float[tArraySize];\n",
    "    for (uint i = 0; i < tArraySize; ++i) {\n",
    "        timings[i] = 0.0;\n",
    "        timingsUnified[i] = 0.0;\n",
    "    }\n",
    "\n",
    "\n",
    "    // Variables calculating the MST weight\n",
    "    unsigned long long int mstWeight = 0;\n",
    "    unsigned long long int *d_mstWeight;\n",
    "    CHECK(cudaMalloc((void**)&d_mstWeight, sizeof(unsigned long long int)));\n",
    "    CHECK(cudaMemset(d_mstWeight, 0, sizeof(unsigned long long int)));\n",
    "\n",
    "    // Initializing the variables associated with the graph\n",
    "    GraphStruct *str = graph->getStruct();\n",
    "    uint nodeSize = str->nodeSize;\n",
    "    uint edgeSize = str->edgeSize;\n",
    "    printf(\"Processing a graph containing %d nodes and %d edges\\n\\n\", nodeSize, edgeSize);\n",
    "\n",
    "    do {\n",
    "        // Initializing the variables associated with the kernel structure\n",
    "        uint blockDim = BLOCK_SIZE;\n",
    "        uint gridDim = (nodeSize + blockDim - 1) / blockDim;\n",
    "\n",
    "        // Initialize some of the variables for the first phase.\n",
    "        uint *candidates, *d_candidates, *offsetCandidates, *d_offsetCandidates;\n",
    "        candidates = new uint[nodeSize];\n",
    "        offsetCandidates = new uint[nodeSize];\n",
    "        CHECK(cudaMalloc((void**)&d_candidates, nodeSize * sizeof(uint)));\n",
    "        CHECK(cudaMalloc((void**)&d_offsetCandidates, nodeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_candidates, 0, nodeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_offsetCandidates, 0, nodeSize * sizeof(uint)));\n",
    "\n",
    "        // Generating resource descriptors\n",
    "        cudaResourceDesc weightDesc = generateCudaDescriptor(str, 0, edgeSize, sizeof(int), cudaChannelFormatKindSigned);\n",
    "        cudaResourceDesc outdegreeDesc = generateCudaDescriptor(str, 1, nodeSize, sizeof(uint), cudaChannelFormatKindUnsigned);\n",
    "        cudaResourceDesc cdDesc = generateCudaDescriptor(str, 2, nodeSize + 1, sizeof(uint), cudaChannelFormatKindUnsigned);\n",
    "        cudaResourceDesc neighDesc = generateCudaDescriptor(str, 3, edgeSize, sizeof(node), cudaChannelFormatKindUnsigned);\n",
    "\n",
    "        // Generating the texture objects\n",
    "        cudaTextureDesc wtexDesc = generateTextureDescriptor();\n",
    "        cudaTextureDesc otexDesc = generateTextureDescriptor();\n",
    "        cudaTextureDesc ntexDesc = generateTextureDescriptor();\n",
    "        cudaTextureDesc cdtexDesc = generateTextureDescriptor();\n",
    "\n",
    "        // Create the texture objects\n",
    "        cudaTextureObject_t wtex, otex, ntex, cdtex;\n",
    "        CHECK(cudaCreateTextureObject(&wtex, &weightDesc, &wtexDesc, NULL));\n",
    "        CHECK(cudaCreateTextureObject(&otex, &outdegreeDesc, &otexDesc, NULL));\n",
    "        CHECK(cudaCreateTextureObject(&ntex, &neighDesc, &ntexDesc, NULL));\n",
    "        CHECK(cudaCreateTextureObject(&cdtex, &cdDesc, &cdtexDesc, NULL));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        printf(\"Launching a kernel FIND CHEAPEST using %d blocks of %d threads\\n\", gridDim, blockDim);\n",
    "        cudaEventRecord(start);\n",
    "        findCheapest <<< gridDim, blockDim >>> (str, ntex, otex, wtex, cdtex, d_candidates);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaGetLastError();\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timings[0] = milliseconds / 1000.0;\n",
    "        printf(\"Finding the cheapest edge for every vertex took:   %.5f seconds\\n\\n\", timings[0]);\n",
    "\n",
    "        timings[tArraySize - 1] += timings[0];\n",
    "        timings[1] += timings[0];\n",
    "\n",
    "        printf(\"Launching the unfied version of the kernel using %d blocks of %d threads\\n\", gridDim, blockDim);\n",
    "        cudaEventRecord(start);\n",
    "        findCheapestUnified <<< gridDim, blockDim >>> (str, d_candidates);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaGetLastError();\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"Finding the cheapest edge using unified memory took for unified version: %.5f seconds\\n\", timingsUnified[0]);\n",
    "        printf(\"SPEEDUP:   %.5f\\n\", timings[0] / timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timingsUnified[1] += timingsUnified[0];\n",
    "\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, nodeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            for (node i = 0; i < nodeSize; ++i) {\n",
    "                node nmin = 0;\n",
    "                int wmin = INT_MAX;\n",
    "                uint medge = 0;\n",
    "                uint edge = str->cumDegs[i];\n",
    "                uint loopEnd = edge + str->outdegrees[i];\n",
    "\n",
    "                while (edge < loopEnd) {\n",
    "                    node neigh = str->neighs[edge];\n",
    "                    int weight = str->weights[edge];\n",
    "\n",
    "                    if (weight < wmin) {\n",
    "                        wmin = weight;\n",
    "                        medge = edge;\n",
    "                        nmin = neigh;\n",
    "                    }\n",
    "                    else if (weight == wmin && neigh < nmin) {\n",
    "                        wmin = weight;\n",
    "                        medge = edge;\n",
    "                        nmin = neigh;\n",
    "                    }\n",
    "\n",
    "                    ++edge;\n",
    "                }\n",
    "\n",
    "                if (medge != candidates[i]) {\n",
    "                    printf(\"The two arrays differ in position %d    CPU:%d(%d)    GPU:%d(%d)\\n\\n\\n\", i, medge, str->weights[medge], candidates[i], str->weights[candidates[i]]);\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            printf(\"The two arrays are identical\\n\\n\\n\");\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Launching a kernel to remove loops\n",
    "        printf(\"Launching a kernel MIRRORED EDGE REMOVAL using %d blocks of %d threads\\n\", gridDim, blockDim);\n",
    "        cudaEventRecord(start);\n",
    "        removeMirroredEdges <<< gridDim, blockDim >>> (str, ntex, d_candidates);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timings[0] = milliseconds / 1000.0;\n",
    "        printf(\"Removing loops took:   %.5f seconds\\n\\n\", timings[0]);\n",
    "\n",
    "        timings[tArraySize - 1] += timings[0];\n",
    "        timings[2] += timings[0];\n",
    "\n",
    "\n",
    "        CHECK(cudaMemcpy(d_candidates, candidates, nodeSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "        printf(\"Launching the unfied version of the kernel using %d blocks of %d threads\\n\", gridDim, blockDim);\n",
    "        cudaEventRecord(start);\n",
    "        removeMirroredEdgesUnified <<< gridDim, blockDim >>> (str, d_candidates, d_mstWeight);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"Removing loops in unified memory took:   %.5f seconds\\n\\n\", timingsUnified[0]);\n",
    "        printf(\"SPEEDUP: %.5f\\n\", timings[0] / timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timingsUnified[2] += timingsUnified[0];\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            uint *nanVertices = new uint[nodeSize];\n",
    "            uint j = 0;\n",
    "            for (node i = 0; i < nodeSize; ++i) {\n",
    "                uint edge = candidates[i];\n",
    "                node neigh = str->neighs[edge];\n",
    "\n",
    "                uint nedge = candidates[neigh];\n",
    "                node nneigh = str->neighs[nedge];\n",
    "\n",
    "                if (nneigh == i && neigh > i) {\n",
    "                    nanVertices[j] = i;\n",
    "                    ++j;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            printf(\"The array contains %d NaN values\\n\", j);\n",
    "\n",
    "            CHECK(cudaMemcpy(candidates, d_candidates, nodeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "            for (uint i = 0, j = 0; i < nodeSize; ++i) {\n",
    "                if (candidates[i] == UINT_MAX) {\n",
    "                    if (nanVertices[j] != i) {\n",
    "                        printf(\"The positions containing NaN do not match   CPU:%d    GPU:%d\\n\\n\\n\", nanVertices[j], candidates[j]);\n",
    "                        return -1;\n",
    "                    }\n",
    "                    ++j;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            printf(\"There are NaNs in every position necessary\\n\\n\\n\");\n",
    "            delete[] nanVertices;\n",
    "\n",
    "            /*\n",
    "            for (uint i = 0; i < nodeSize; ++i) {\n",
    "                if (candidates[i] == UINT_MAX) {\n",
    "                    continue;\n",
    "                }\n",
    "                printf(\"%d >> %d %d(%d)\\n\", i, candidates[i], str->neighs[candidates[i]], str->weights[candidates[i]]);\n",
    "            }\n",
    "            printf(\"\\n\\n\\n\");\n",
    "            */\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        // Initialization of the variables associated with the recursive\n",
    "        // coloration kernel\n",
    "        uint *colors, *d_colors;\n",
    "        colors = new uint[nodeSize];\n",
    "        CHECK(cudaMalloc((void**)&d_colors, nodeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_colors, UINT_MAX, nodeSize * sizeof(uint)));\n",
    "\n",
    "\n",
    "        ////////////////////////\n",
    "        // TODO -- FIX THE COLORATION PROCEDURE TO MAKE IT GO FASTER\n",
    "        ////////////////////////\n",
    "        // Launching a kernel to remove loops\n",
    "        printf(\"Launching a kernel COLORATION PROCESS using %d blocks of %d threads\\n\", gridDim, blockDim);\n",
    "        cudaEventRecord(start);\n",
    "        colorationProcess <<< gridDim, blockDim >>> (str, d_candidates, d_colors);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"The recursive coloration procedure took:   %.5f seconds\\n\\n\", timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timingsUnified[4] += timingsUnified[0];\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            CHECK(cudaMemcpy(colors, d_colors, nodeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "            uint rootNumber = 0;\n",
    "            for (uint i = 0; i < nodeSize; ++i) {\n",
    "                if (colors[i] == i) {\n",
    "                    ++rootNumber;\n",
    "                }\n",
    "\n",
    "                if (colors[i] == UINT_MAX) {\n",
    "                    printf(\"Unexpected value at position %d\\n\", i);\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "            printf(\"The number of roots is %d\\n\\n\\n\", rootNumber);\n",
    "        }\n",
    "\n",
    "\n",
    "        // Initialization of the variables for the flag array construction\n",
    "        uint *isSupervertex, *d_isSupervertex;\n",
    "        isSupervertex = new uint[nodeSize];\n",
    "        CHECK(cudaMalloc((void**)&d_isSupervertex, nodeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_isSupervertex, false, nodeSize * sizeof(uint)));\n",
    "\n",
    "        printf(\"Launching a kernel SUPERVERTEX IDENTIFICATION using %d blocks of %d threads\\n\", gridDim, blockDim);\n",
    "        cudaEventRecord(start);\n",
    "        svIdentification <<< gridDim, blockDim >>> (str, d_colors, d_candidates, d_isSupervertex);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"The supervertex identification procedure took: %.5f seconds\\n\\n\", timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timingsUnified[5] += timingsUnified[0];\n",
    "        timings[tArraySize - 1] += timingsUnified[0];\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            CHECK(cudaMemcpy(isSupervertex, d_isSupervertex, nodeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "            for (node i = 0; i < nodeSize; ++i) {\n",
    "                if (colors[i] == i && isSupervertex[i] != 1) {\n",
    "                    printf(\"The expected supervertex flag (1) is absent at position %d\\n\", i);\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Smem definition\n",
    "        uint smemSize = 2 * blockDim;\n",
    "        uint numSmemBlock = (nodeSize + smemSize - 1) / smemSize;\n",
    "\n",
    "        // Supervertex ids and aux vector definition\n",
    "        uint *svIds, *aux, *d_svIds, *d_aux;\n",
    "        svIds = new uint[nodeSize];\n",
    "        aux = new uint[numSmemBlock];\n",
    "        CHECK(cudaMalloc((void**)&d_svIds, nodeSize * sizeof(uint)));\n",
    "        CHECK(cudaMalloc((void**)&d_aux, numSmemBlock * sizeof(uint)));\n",
    "\n",
    "        // Prescan procedure on the vertex array\n",
    "        uint smem = smemSize * sizeof(uint);\n",
    "        printf(\"prescan procedure on the isSupervertex array of size: %d ...\\n\", nodeSize);\n",
    "        cudaEventRecord(start);\n",
    "        prescan <<<  numSmemBlock, blockDim, smem >>> (d_svIds, d_isSupervertex, d_aux, nodeSize, smemSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"The first prescan procedure took:   %.5f seconds\\n\", timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[6] += timingsUnified[0];\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timings[tArraySize - 1] += timingsUnified[0];\n",
    "\n",
    "        // Prescan procedure on the aux array to do the sum of the offsets for the various blocks\n",
    "        printf(\"prescan procedure on the aux array of size: %d ...\\n\", numSmemBlock + 1);\n",
    "        uint *d_aaux;\n",
    "        CHECK(cudaMalloc((void **) &d_aaux, sizeof(uint)));\n",
    "        cudaEventRecord(start);\n",
    "        prescan <<<  1, blockDim, smem >>> (d_aux, d_aux, d_aaux, numSmemBlock + 1, smemSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"The second prescan procedure took:   %.5f seconds\\n\", timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[7] += timingsUnified[0];\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timings[tArraySize - 1] += timingsUnified[0];\n",
    "\n",
    "        // Put everything together\n",
    "        printf(\"final summation procedure...\\n\");\n",
    "        cudaEventRecord(start);\n",
    "        final_sum <<< gridDim, blockDim >>> (d_svIds, d_aux, nodeSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"The final summation procedure took:   %.5f seconds\\n\\n\", timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[8] += timingsUnified[0];\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timings[tArraySize - 1] += timingsUnified[0];\n",
    "\n",
    "        CHECK(cudaMemcpy(svIds, d_svIds, nodeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            uint *checkSupervertexIds = new uint[nodeSize];\n",
    "            for (node i = 0; i < nodeSize; ++i) {\n",
    "                checkSupervertexIds[i] = isSupervertex[i];\n",
    "            }\n",
    "            cpuScan(checkSupervertexIds, 0, nodeSize);\n",
    "            for (node i = 0; i < nodeSize; ++i) {\n",
    "                if (svIds[i] != checkSupervertexIds[i]) {\n",
    "                    printf(\"The naming for the supervertices does not match at position %d   CPU: %d   GPU: %d\\n\\n\\n\", i, checkSupervertexIds[i], svIds[i]);\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "            printf(\"The two arrays are identical and the maximum vertex id is %d\\n\\n\\n\", svIds[nodeSize - 1]);\n",
    "            delete[] checkSupervertexIds;\n",
    "        }\n",
    "\n",
    "        // Freeing the auxiliary vectors for later reuse\n",
    "        CHECK(cudaFree(d_aux));\n",
    "        CHECK(cudaFree(d_aaux));\n",
    "        delete[] aux;\n",
    "\n",
    "\n",
    "\n",
    "        // Setting up the newOutdegrees array for the counting kernel\n",
    "        uint newNodeSize = svIds[nodeSize - 1];\n",
    "        uint *newOutdegrees, *d_newOutdegrees;\n",
    "        newOutdegrees = new uint[newNodeSize];\n",
    "        CHECK(cudaMalloc((void**)&d_newOutdegrees, newNodeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_newOutdegrees, 0, newNodeSize * sizeof(uint)));\n",
    "\n",
    "        // Launching a kernel to count outgoing edges in the new graph\n",
    "        printf(\"Launching a kernel COUNT NEW EDGES using %d blocks of %d threads\\n\", gridDim, blockDim);\n",
    "        cudaEventRecord(start);\n",
    "        countNewEdges <<< gridDim, blockDim >>> (str, ntex, otex, cdtex, d_colors, d_svIds, d_newOutdegrees);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timings[0] = milliseconds / 1000.0;\n",
    "        printf(\"Counting the number of edges crossing components took:   %.5f seconds\\n\\n\", timings[0]);\n",
    "\n",
    "        timings[tArraySize - 1] += timings[0];\n",
    "        timings[4] += timings[0];\n",
    "\n",
    "        // Resetting the newOutdegrees array\n",
    "        CHECK(cudaMemset(d_newOutdegrees, 0, newNodeSize * sizeof(uint)));\n",
    "\n",
    "        // Doing a relaunch with UMEM to check performance\n",
    "        printf(\"Launching the unified version of the kernel using %d blocks of %d threads\\n\", gridDim, blockDim);\n",
    "        cudaEventRecord(start);\n",
    "        countNewEdgesUnified <<< gridDim, blockDim >>> (str, d_colors, d_svIds, d_newOutdegrees);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"Counting the number of edges crossing components took:   %.5f seconds\\n\\n\", timingsUnified[0]);\n",
    "        printf(\"SPEEDUP: %.5f\\n\", timings[0] / timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timingsUnified[9] += timingsUnified[0];\n",
    "\n",
    "        CHECK(cudaMemcpy(newOutdegrees, d_newOutdegrees, newNodeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            uint *outDegreesCheck = new uint[newNodeSize];\n",
    "\n",
    "            for (uint i = 0; i < newNodeSize; ++i) {\n",
    "                outDegreesCheck[i] = 0;\n",
    "            }\n",
    "\n",
    "            for (node i = 0; i < nodeSize; ++i) {\n",
    "                uint numEdges = 0;\n",
    "                uint color = colors[i];\n",
    "                for (uint j = 0; j < str->outdegrees[i]; ++j) {\n",
    "                    node neigh = str->neighs[str->cumDegs[i] + j];\n",
    "                    if (color != colors[neigh]) {\n",
    "                        ++numEdges;\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                node sv = getRoot(i, svIds, colors);\n",
    "                outDegreesCheck[sv] += numEdges;\n",
    "            }\n",
    "\n",
    "            for (node i = 0; i < newNodeSize; ++i) {\n",
    "                if (newOutdegrees[i] != outDegreesCheck[i]) {\n",
    "                    printf(\"The number of edges crossing components does not match at position %d   CPU: %d   GPU: %d\\n\\n\\n\", i, outDegreesCheck[i], newOutdegrees[i]);\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "            printf(\"The two arrays are identical\\n\\n\\n\");\n",
    "            delete[] outDegreesCheck;\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Smem redefinition\n",
    "        numSmemBlock = (newNodeSize + smemSize) / smemSize;\n",
    "\n",
    "        // Supervertex ids and aux vector definition\n",
    "        uint *newCumDegs, *d_newCumDegs;\n",
    "        newCumDegs = new uint[newNodeSize + 1];\n",
    "        aux = new uint[numSmemBlock];\n",
    "        CHECK(cudaMalloc((void**)&d_newCumDegs, (newNodeSize + 1) * sizeof(uint)));\n",
    "        CHECK(cudaMalloc((void**)&d_aux, numSmemBlock * sizeof(uint)));\n",
    "\n",
    "        // Prescan procedure on the vertex array\n",
    "        smem = smemSize * sizeof(uint);\n",
    "        printf(\"prescan procedure on the newOutdegrees array of size: %d ...\\n\", nodeSize);\n",
    "        cudaEventRecord(start);\n",
    "        prescan <<<  numSmemBlock, blockDim, smem >>> (d_newCumDegs, d_newOutdegrees, d_aux, newNodeSize, smemSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"The first prescan procedure took:   %.5f seconds\\n\", timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[10] += timingsUnified[0];\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timings[tArraySize - 1] += timingsUnified[0];\n",
    "\n",
    "        // Prescan procedure on the aux array to do the sum of the offsets for the various blocks\n",
    "        printf(\"prescan procedure on the aux array of size: %d ...\\n\", numSmemBlock + 1);\n",
    "        CHECK(cudaMalloc((void **) &d_aaux, sizeof(uint)));\n",
    "        cudaEventRecord(start);\n",
    "        prescan <<<  1, blockDim, smem >>> (d_aux, d_aux, d_aaux, numSmemBlock + 1, smemSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"The second prescan procedure took:   %.5f seconds\\n\", timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[11] += timingsUnified[0];\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timings[tArraySize - 1] += timingsUnified[0];\n",
    "\n",
    "        // Put everything together\n",
    "        printf(\"final summation procedure...\\n\");\n",
    "        cudaEventRecord(start);\n",
    "        final_sum <<< gridDim, blockDim >>> (d_newCumDegs, d_aux, newNodeSize + 1);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"The final summation procedure took:   %.5f seconds\\n\\n\", timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[12] += timingsUnified[0];\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        timings[tArraySize - 1] += timingsUnified[0];\n",
    "\n",
    "        CHECK(cudaMemcpy(newCumDegs, d_newCumDegs, (newNodeSize + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            uint *checkCumDegs = new uint[newNodeSize + 1];\n",
    "            for (node i = 0; i < newNodeSize; ++i) {\n",
    "                checkCumDegs[i] = newOutdegrees[i];\n",
    "            }\n",
    "            printf(\"\\n\\n\\n\");\n",
    "            cpuScan(checkCumDegs, 0, newNodeSize);\n",
    "            for (node i = 0; i < newNodeSize; ++i) {\n",
    "                if (newCumDegs[i] != checkCumDegs[i]) {\n",
    "                    printf(\"The naming for the supervertices does not match at position %d   CPU: %d   GPU: %d\\n\\n\\n\", i, checkCumDegs[i], newCumDegs[i]);\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "            printf(\"The two arrays are identical\\n\\n\\n\");\n",
    "            delete[] checkCumDegs;\n",
    "        }\n",
    "\n",
    "        // Freeing the auxiliary vectors for later reuse\n",
    "        CHECK(cudaFree(d_aux));\n",
    "        CHECK(cudaFree(d_aaux));\n",
    "        delete[] aux;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Contraction step\n",
    "        // Generation of the new arrays\n",
    "        uint *newNeighs, *d_newNeighs, *newWeights, *d_newWeights;\n",
    "        uint newEdgeSize = newCumDegs[newNodeSize];\n",
    "        newNeighs = new uint[newEdgeSize];\n",
    "        newWeights = new uint[newEdgeSize];\n",
    "        CHECK(cudaMalloc((void**)&d_newNeighs, newEdgeSize * sizeof(uint)));\n",
    "        CHECK(cudaMalloc((void**)&d_newWeights, newEdgeSize * sizeof(uint)));\n",
    "\n",
    "        printf(\"Launching a kernel GRAPH CONTRACTION using %d blocks of %d threads\\n\", gridDim, blockDim);\n",
    "        cudaEventRecord(start);\n",
    "        graphContraction <<< gridDim, blockDim >>> (str, ntex, otex, cdtex, wtex, d_newNeighs, d_newWeights, d_colors, d_newCumDegs, d_svIds);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timings[0] = milliseconds / 1000.0;\n",
    "        printf(\"The final contraction step took:   %.5f seconds\\n\\n\", timings[0]);\n",
    "\n",
    "        timings[5] += timings[0];\n",
    "        timings[tArraySize - 1] += timings[0];\n",
    "\n",
    "        // Resetting the various arrays\n",
    "        CHECK(cudaMemset(d_newNeighs, 0, newEdgeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_newWeights, 0, newEdgeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemcpy(d_newCumDegs, newCumDegs, (newNodeSize + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "        printf(\"Launching the unified version of the kernel using %d blocks of %d threads\\n\", gridDim, blockDim);\n",
    "        cudaEventRecord(start);\n",
    "        graphContractionUnified <<< gridDim, blockDim >>> (str, d_newNeighs, d_newWeights, d_colors, d_newCumDegs, d_svIds);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        timingsUnified[0] = milliseconds / 1000.0;\n",
    "        printf(\"The final contraction step took:   %.5f seconds\\n\\n\", timingsUnified[0]);\n",
    "\n",
    "        timingsUnified[13] += timingsUnified[0];\n",
    "        timingsUnified[tArraySize - 1] += timingsUnified[0];\n",
    "        printf(\"SPEEDUP: %.5f\\n\", timings[0] / timingsUnified[0]);\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            CHECK(cudaMemcpy(newNeighs, d_newNeighs, newEdgeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "            CHECK(cudaMemcpy(newWeights, d_newWeights, newEdgeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "            uint *checkNeighs = new uint[newEdgeSize];\n",
    "            uint *checkWeights = new uint[newEdgeSize];\n",
    "            uint *checkCumDegs = new uint[newNodeSize + 1];\n",
    "            for (node i = 0; i < newNodeSize; ++i) {\n",
    "                checkCumDegs[i] = newCumDegs[i];\n",
    "            }\n",
    "\n",
    "            for (node i = 0; i < nodeSize; ++i) {\n",
    "                uint color = colors[i];\n",
    "                for (uint j = 0; j < str->outdegrees[i]; ++j) {\n",
    "                    node neigh = str->neighs[str->cumDegs[i] + j];\n",
    "                    if (color != colors[neigh]) {\n",
    "                        node osv = getRoot(i, svIds, colors);\n",
    "                        node dsv = getRoot(neigh, svIds, colors);\n",
    "                        uint position = checkCumDegs[osv];\n",
    "                        checkNeighs[position] = dsv;\n",
    "                        checkWeights[position] = str->weights[str->cumDegs[i] + j];\n",
    "                        ++checkCumDegs[osv];\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            for (node i = 0; i < newEdgeSize; ++i) {\n",
    "                if (newNeighs[i] != checkNeighs[i] || newWeights[i] != checkWeights[i]) {\n",
    "                    printf(\"The newNeighs array does not match at position %d   CPU: %d   GPU: %d\\n\\n\\n\", i, checkNeighs[i], newNeighs[i]);\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "            printf(\"The two vectors are the same\\n\");\n",
    "            delete[] checkNeighs;\n",
    "            delete[] checkWeights;\n",
    "            delete[] checkCumDegs;\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        nodeSize = 0;\n",
    "\n",
    "        // Free device memory\n",
    "        CHECK(cudaFree(d_candidates));\n",
    "        CHECK(cudaFree(d_colors));\n",
    "        CHECK(cudaFree(d_offsetCandidates));\n",
    "\n",
    "        // Free host memory\n",
    "        delete[] candidates;\n",
    "        delete[] offsetCandidates;\n",
    "        delete[] colors;\n",
    "\n",
    "    } while (nodeSize > 1);\n",
    "\n",
    "    printf(\"Total execution time:\\n\");\n",
    "    printf(\"    Total execution time for texture-based implementation:   %.5f seconds\\n\", timings[tArraySize - 1]);\n",
    "    printf(\"    \\tTime spent fetching the minimum:   %.5f seconds\\n\", timings[1]);\n",
    "    printf(\"    \\tTime spent removing loops:   %.5f seconds\\n\", timings[2]);\n",
    "    printf(\"    \\tTime spent finding connected components:   %.5f seconds\\n\", timings[3]);\n",
    "    printf(\"    \\tTime spent counting the new edges:   %.5f seconds\\n\", timings[4]);\n",
    "    printf(\"    \\tTime spent doing the contraction operation:   %.5f seconds\\n\", timings[5]);\n",
    "    printf(\"\\n\\n\\n\");\n",
    "    printf(\"    Total execution time for UMEM-based implementation:   %.5f seconds\\n\", timingsUnified[tArraySize - 1]);\n",
    "    printf(\"    \\tTime spent fetching the minimum:   %.5f seconds\\n\", timingsUnified[1]);\n",
    "    printf(\"    \\tTime spent removing loops:   %.5f seconds\\n\", timingsUnified[2]);\n",
    "    printf(\"    \\tTime spent finding connected components:   %.5f seconds\\n\", timingsUnified[4]);\n",
    "    printf(\"    \\tTime spent renaming the supervertices:   %.5f seconds\\n\", timingsUnified[5] + timingsUnified[6] + timingsUnified[7] + timingsUnified[8]);\n",
    "    printf(\"    \\t  Of which %.5f s spent finding the roots of the connected components\\n\", timingsUnified[5]);\n",
    "    printf(\"    \\t       And %.5f s spent doing a first prescan procedure on array isSupervertex\\n\", timingsUnified[6]);\n",
    "    printf(\"    \\t       And %.5f s spent doing a second prescan procedure on the auxiliary array\\n\", timingsUnified[7]);\n",
    "    printf(\"    \\t       And %.5f s spent doing a final sum on the isSupervertex array\\n\\n\", timingsUnified[8]);\n",
    "    printf(\"    \\tTime spent counting the new edges:   %.5f seconds\\n\", timingsUnified[9]);\n",
    "    printf(\"    \\tTime spent building a new cumDegs array:   %.5f seconds\\n\", timingsUnified[10] + timingsUnified[11] + timingsUnified[12]);\n",
    "    printf(\"    \\t  Of which %.5f s spent doing a first prescan procedure on array newOutdegrees\\n\", timingsUnified[10]);\n",
    "    printf(\"    \\t       And %.5f s spent doing a first prescan procedure on the auxiliary array\\n\", timingsUnified[11]);\n",
    "    printf(\"    \\t       And %.5f s spent doing a final sum on the newCumDegs array\\n\\n\", timingsUnified[12]);\n",
    "    printf(\"    \\tTime spent on the graph contraction:   %.5f seconds\\n\", timingsUnified[13]);\n",
    "    printf(\"\\n\\n\\n\");\n",
    "    printf(\"TOTAL SPEEDUP: %.5f%%\", 100 * (timings[tArraySize - 1] / timingsUnified[tArraySize - 1]));\n",
    "\n",
    "\n",
    "    // Destroy texture objects\n",
    "    CHECK(cudaDestroyTextureObject(wtex));\n",
    "    CHECK(cudaDestroyTextureObject(otex));\n",
    "    CHECK(cudaDestroyTextureObject(ntex));\n",
    "    CHECK(cudaDestroyTextureObject(cdtex));\n",
    "\n",
    "    // Destroy event listeners\n",
    "    CHECK(cudaEventDestroy(start));\n",
    "    CHECK(cudaEventDestroy(stop));\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "by0GWqS5bH8o"
   },
   "source": [
    "## GPU efficient new minimum-find kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swNiEEesbHkw"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"mstGPUEmfk.cu\" --group \"GPU\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <limits.h>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "/*****\n",
    "* Device function that gets the degree of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The node we are interested in\n",
    "*****/\n",
    "__device__ node d_deg (GraphStruct *str, node i) {\n",
    "    return str->cumDegs[i + 1] - str->cumDegs[i];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the weight of a certain edge\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ int d_getWeight (GraphStruct *str, node i, uint offset) {\n",
    "    return str->weights[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the neighbour of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
    "    return str->neighs[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "__device__ uint d_getRoot (uint i, uint *d_flag, uint *d_colors) {\n",
    "    return max(0, d_flag[d_colors[i]]);\n",
    "}\n",
    "\n",
    "uint getRoot (uint i, uint *flag, uint *colors) {\n",
    "    return max(0, flag[colors[i]]);\n",
    "}\n",
    "\n",
    "__device__ uint d_getPosition(GraphStruct *str, node i, uint offset) {\n",
    "    return str->cumDegs[i] + offset;\n",
    "}\n",
    "\n",
    "\n",
    "__device__ uint binarySearch (uint *d_cumDegs, uint neighPosition, uint cumDegSize) {\n",
    "    uint left = 0;\n",
    "    uint right = cumDegSize - 1;\n",
    "\n",
    "    if (d_cumDegs[right] <= neighPosition) {\n",
    "        return right;\n",
    "    }\n",
    "\n",
    "    while (left <= right) {\n",
    "        uint mid = (left + right) / 2;\n",
    "        if (d_cumDegs[mid] <= neighPosition) {\n",
    "            left = mid + 1;\n",
    "        }\n",
    "        else {\n",
    "            right = mid - 1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (left == right) {\n",
    "        return left;\n",
    "    }\n",
    "    return left - 1;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void findMinimumForVertex(GraphStruct *str, uint *d_aux, uint *d_auxOffset, int smemSize, node vertex)\n",
    "{\n",
    "  extern __shared__ int temp[];\n",
    "  int thid = threadIdx.x;\n",
    "  int offset = 1;\n",
    "  int idx = blockIdx.x * blockDim.x + thid;\n",
    "  int n = d_deg(str, vertex);\n",
    "\n",
    "  // Zero relative to the start of the array\n",
    "  int relativeZero = str->cumDegs[vertex];\n",
    "\n",
    "  // load input into shared memory\n",
    "  temp[2 * thid] = (2 * idx < n) ? (int) (2 * idx) : NO_VALUE;\n",
    "  temp[2 * thid + 1] = (2 * idx + 1 < n) ? (int) (2 * idx + 1) : NO_VALUE;\n",
    "\n",
    "\n",
    "  // build sum in place up the tree\n",
    "  for (int d = smemSize>>1; d > 0; d >>= 1)\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "          int aiWeight = (temp[ai] != NO_VALUE) ? str->weights[relativeZero + temp[ai]] : INT_MAX;\n",
    "          int biWeight = (temp[bi] != NO_VALUE) ? str->weights[relativeZero + temp[bi]] : INT_MAX;\n",
    "          temp[bi] = (aiWeight < biWeight) ? temp[ai] : temp[bi];\n",
    "      }\n",
    "    }\n",
    "    offset *= 2;\n",
    "  }\n",
    "\n",
    "\n",
    "  if (thid == 0)\n",
    "  {\n",
    "    d_aux[blockIdx.x + d_auxOffset[vertex]] = temp[smemSize - 1];\n",
    "  }\n",
    "}\n",
    "\n",
    "__global__ void findMinimum(GraphStruct *str, uint *d_aux, uint *d_auxOffset, uint *d_candidates) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    int min = INT_MAX;\n",
    "    for (uint i = 0; i < (d_deg(str, idx) + (2 * blockDim.x) - 1) / (2 * blockDim.x); i++) {\n",
    "        //printf(\"%d\\n\", d_aux[d_auxOffset[idx] + i]);\n",
    "        int weight = d_getWeight(str, idx, d_aux[d_auxOffset[idx] + i]);\n",
    "        if (weight < min) {\n",
    "            min = weight;\n",
    "            d_candidates[idx] = d_aux[d_auxOffset[idx] + i];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Kernel that finds the cheapest edge in the adjacency list of every node\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "*****/\n",
    "__global__ void findCheapest (GraphStruct *str, uint *d_candidates) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // Initialize the minimum value\n",
    "    uint minimum = UINT_MAX;\n",
    "    int minimumWeight = INT_MAX;\n",
    "\n",
    "    // Find the cheapest edge in each adjacency list\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        int edgeWeight = d_getWeight(str, idx, i);\n",
    "        if (edgeWeight < minimumWeight) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "        else if (edgeWeight == minimumWeight &&\n",
    "                 d_getNeigh(str, idx, i) < d_getNeigh(str, idx, minimum)) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Update the return vector\n",
    "    d_candidates[idx] = minimum;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that removes the mirrored edges from the graph. A mirrored edge is\n",
    "* simply an edge pointing from the source to the destination and vice versa in\n",
    "* an oriented graph, the removal logic is to cut the edge with the lowest source\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "*****/\n",
    "__global__ void mirroredEdgesRemoval (GraphStruct *str, uint *d_candidates, int *d_weight) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint destinationOffset = d_candidates[idx];\n",
    "    node destination = d_getNeigh(str, idx, destinationOffset);\n",
    "    if (idx < destination) {\n",
    "        uint sourceOffset = d_candidates[destination];\n",
    "        node destinationNeigh = d_getNeigh(str, destination, sourceOffset);\n",
    "\n",
    "        // The vertex cannot be a candidate anymore because it would create a cycle\n",
    "        if (destinationNeigh == idx) {\n",
    "            d_candidates[idx] = UINT_MAX;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (d_candidates[idx] != UINT_MAX) {\n",
    "        atomicAdd(d_weight, d_getWeight(str, idx, d_candidates[idx]));\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/*****\n",
    "* Helper device function that recursively colors the nodes of the graph\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "* @param i - The index of the node to be colored\n",
    "* @param d_colors - The device-level array of colors assigned to each vertex\n",
    "*****/\n",
    "__device__ uint *d_recursiveColorationHelper (GraphStruct *str, uint *d_candidates, node i, uint *d_colors) {\n",
    "    uint color = UINT_MAX;\n",
    "    if (d_candidates[i] == UINT_MAX) {\n",
    "        color = i;\n",
    "    }\n",
    "    else {\n",
    "        node neigh = d_getNeigh(str, i, d_candidates[i]);\n",
    "        color = d_recursiveColorationHelper(str, d_candidates, neigh, d_colors)[neigh];\n",
    "    }\n",
    "\n",
    "    if (color != UINT_MAX) {\n",
    "        d_colors[i] = color;\n",
    "    }\n",
    "    return d_colors;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that recognizes the connected components in the graph and colors them\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree\n",
    "* @param d_colors - The device-level array of colors assigned to each vertex\n",
    "*****/\n",
    "__global__ void colorationProcess(GraphStruct *str, uint *d_candidates, uint *d_colors) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    d_recursiveColorationHelper(str, d_candidates, idx, d_colors);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "//*** SCAN FUNCTIONS ***//\n",
    "\n",
    "__global__ void prescan(uint *g_odata, uint *g_idata, uint *aux, int n, int smemSize)\n",
    "{\n",
    "  extern __shared__ int temp[];// allocated on invocation\n",
    "  int thid = threadIdx.x;\n",
    "  int offset = 1;\n",
    "  int idx = blockIdx.x * blockDim.x + thid;\n",
    "\n",
    "  // load input into shared memory\n",
    "  temp[2 * thid] =  (2 * idx < n) ? g_idata[2 * idx] : 0;\n",
    "  temp[2 * thid + 1] = (2 * idx + 1 < n) ? g_idata[2 * idx + 1] : 0;\n",
    "  //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "      //printf(\"UPSWEEP\\n\");\n",
    "  //}\n",
    "\n",
    "  for (int d = n>>1; d > 0; d >>= 1) // build sum in place up the tree\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        temp[bi] += temp[ai];\n",
    "      }\n",
    "      //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "        //printf(\"temp[idx]: %d\\n\", temp[thid]);\n",
    "      //}\n",
    "    }\n",
    "    offset *= 2;\n",
    "  }\n",
    "\n",
    "  if (thid == 0)\n",
    "  {\n",
    "    aux[blockIdx.x] = temp[smemSize - 1];\n",
    "    temp[smemSize - 1] = 0;\n",
    "  } // clear the last element\n",
    "\n",
    "  //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "      //printf(\"DOWNSWEEP\\n\");\n",
    "  //}\n",
    "\n",
    "  for (int d = 1; d < n; d *= 2) // traverse down tree & build scan\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d && offset > 0)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        int t = temp[ai];\n",
    "        temp[ai] = temp[bi];\n",
    "        temp[bi] += t;\n",
    "      }\n",
    "    }\n",
    "    //if (2 * idx == n - 1) {\n",
    "        //printf(\"temp[n - 1]: %d\\n\", temp[2 * thid]);\n",
    "    //}\n",
    "    //if (2 * idx + 1 == n - 1) {\n",
    "        //printf(\"temp[n - 1]: %d\\n\", temp[2 * thid + 1]);\n",
    "    //}\n",
    "    offset >>= 1;\n",
    "  }\n",
    "\n",
    "\n",
    "  __syncthreads();\n",
    "  if (idx <= (n / 2)) {\n",
    "      g_odata[2*idx] = temp[2*thid]; // write results to device memory\n",
    "      g_odata[2*idx+1] = temp[2*thid+1];\n",
    "  }\n",
    "}\n",
    "\n",
    "void cpuScan(uint *array, int start, int end) {\n",
    "    if (end - start <= 1) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    int temp = array[start + 1];\n",
    "    array[start + 1] = array[start];\n",
    "    array[start] = 0;\n",
    "\n",
    "    for (uint i = start + 1; i < end - 1; i++) {\n",
    "        int sum = array[i] + temp;\n",
    "        temp = array[i + 1];\n",
    "        array[i + 1] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void final_sum(uint *g_odata, uint *aux, uint n)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "  if (blockIdx.x == 0 || 2 * idx >= n) {\n",
    "      return;\n",
    "  }\n",
    "\n",
    "  //printf(\"%d: ls - %d  rs - %d  aux - %d\\n\", idx, g_odata[2 * idx], g_odata[2 * idx + 1], aux[blockIdx.x - 1]);\n",
    "\n",
    "  if (2 * idx == n - 1) {\n",
    "      g_odata[2 * idx] += aux[blockIdx.x];\n",
    "      return;\n",
    "  }\n",
    "  g_odata[2 * idx] += aux[blockIdx.x];\n",
    "  g_odata[2 * idx + 1] += aux[blockIdx.x];\n",
    "}\n",
    "\n",
    "//****************//\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void cumulatedDegreeUpdate(GraphStruct *str, uint *d_cumDegs, uint *d_colors, uint *d_flag) {\n",
    "    // One thread per edge\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint color = d_colors[idx];\n",
    "    node svSuccessor = d_getRoot(idx, d_flag, d_colors);\n",
    "    uint sum = 0;\n",
    "\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        node neigh = d_getNeigh(str, idx, i);\n",
    "        uint neighColor = d_colors[neigh];\n",
    "\n",
    "        if (color != neighColor) {\n",
    "            sum++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    atomicAdd(&(d_cumDegs[svSuccessor]), sum);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void cumulatedDegreeUpdateCopy(GraphStruct *str, uint *d_cumDegs, uint *d_colors, uint *d_flag) {\n",
    "    // One thread per edge\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the thread is out of bounds returns immediately\n",
    "    if (idx >= str->edgeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // The thread is the destination of the considered edge\n",
    "    node destination = str->neighs[idx];\n",
    "    uint destColor = d_colors[destination];\n",
    "\n",
    "    // I look for the origin of the edge using the cumulated degrees array\n",
    "    uint origin = binarySearch(str->cumDegs, idx, str->nodeSize + 1);\n",
    "    uint originColor = d_colors[origin];\n",
    "\n",
    "    // Find the roots => the super-vertices\n",
    "    node oSuperVertex = d_getRoot(origin, d_flag, d_colors);\n",
    "\n",
    "    //printf(\"%d(%d)   destination: %d(%d)   origin: %d(%d)\\n\", idx, destination, destColor, origin, originColor);\n",
    "\n",
    "    // If the colors of the two vertices are different then they belong to different components\n",
    "    if (destColor != originColor) {\n",
    "        atomicAdd(&(d_cumDegs[oSuperVertex]), 1);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void graphContractionCopy(GraphStruct *str, uint *d_colors, uint *d_flag,\n",
    "                                 uint *d_cumDegs, node *d_newNeighs, uint *d_newWeights) {\n",
    "    // One index per edge\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->edgeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // The index is the destination of the considered edge\n",
    "    node destination = str->neighs[idx];\n",
    "    uint destColor = d_colors[destination];\n",
    "\n",
    "    // I look for the origin of the edge using the cumulated degrees array\n",
    "    uint origin = binarySearch(str->cumDegs, idx, str->nodeSize + 1);\n",
    "    uint originColor = d_colors[origin];\n",
    "\n",
    "    // Find the roots => the super-vertices\n",
    "    node oSuperVertex = d_getRoot(origin, d_flag, d_colors);\n",
    "    node dSuperVertex = d_getRoot(destination, d_flag, d_colors);\n",
    "\n",
    "    //printf(\"%d(%d)   destination: %d(%d)   origin: %d(%d)\\n\", idx, destination, destColor, origin, originColor);\n",
    "\n",
    "    // If the colors of the two vertices are different then they belong to different components\n",
    "    if (destColor != originColor) {\n",
    "        // I take the weight\n",
    "        int weight = str->weights[idx];\n",
    "\n",
    "        // Compute the comulatedDegrees increment\n",
    "        uint position = atomicAdd(&(d_cumDegs[oSuperVertex]), 1);\n",
    "\n",
    "        // Update the vectors\n",
    "        d_newNeighs[position] = dSuperVertex;\n",
    "        d_newWeights[position] = weight;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main () {\n",
    "    // Generation of a random graph\n",
    "    std::random_device rd;\n",
    "    std::default_random_engine eng(FIXED_SEED);\n",
    "    uint maxWeight = MAX_WEIGHT;\n",
    "    float prob = PROBABILITY;\n",
    "    bool GPUEnabled = 1;\n",
    "    Graph *graphPointer;\n",
    "    Graph graph(SIZE, GPUEnabled);\n",
    "    graphPointer = &graph;\n",
    "  \tgraphPointer->randGraph(prob, true, maxWeight, eng);\n",
    "    /**************************************************/\n",
    "\n",
    "\n",
    "    // Checking if the random graph is connected\n",
    "    if (!graphPointer->isConnected()) {\n",
    "        cout << \"The graph is not connected\" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "    /************/\n",
    "\n",
    "\n",
    "    uint iterations = 0;\n",
    "    uint blockDim = BLOCK_SIZE;\n",
    "\n",
    "\n",
    "    // Events to measure time\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    float milliseconds;\n",
    "    float spliTime = 0;\n",
    "    float totalTime = 0;\n",
    "    float firstPhase = 0;\n",
    "    float secondPhase = 0;\n",
    "    float thirdPhase = 0;\n",
    "    float fourthPhase = 0;\n",
    "    float fifthPhase = 0;\n",
    "    /******************/\n",
    "\n",
    "\n",
    "    // Variables calculating the MST weight\n",
    "    int mstWeight = 0;\n",
    "    int *d_mstWeight;\n",
    "    CHECK(cudaMalloc((void **)&d_mstWeight, sizeof(int)));\n",
    "    CHECK(cudaMemcpy(d_mstWeight, &mstWeight, sizeof(int), cudaMemcpyHostToDevice));\n",
    "    /******************************************************************************/\n",
    "\n",
    "\n",
    "    // Main block of the algorithm\n",
    "    while (graphPointer->getStruct()->nodeSize > 1) {\n",
    "        // Initialization of the variables associated with the graph\n",
    "        GraphStruct *str = graphPointer->getStruct();\n",
    "        uint size = str->nodeSize;\n",
    "        uint edgeSize = str->edgeSize;\n",
    "        cout << \"Processing a graph of size: \" << size << \" with \" << edgeSize << \" edges.\\n\\n\";\n",
    "\n",
    "        uint gridDim = (size + blockDim - 1) / blockDim;\n",
    "        uint searchGrid = (edgeSize + blockDim - 1) / blockDim;\n",
    "\n",
    "        if (DEBUGGING && size < 15 && str->edgeSize < 100) {\n",
    "            graphPointer->print(true);\n",
    "            print_d<<<1, 1>>>(str, 1);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "        }\n",
    "        /******************************/\n",
    "\n",
    "\n",
    "\n",
    "        // Compute the ratio between the outdegree and the smem size\n",
    "        uint smemSize = 2 * blockDim;\n",
    "        uint auxSize = 0;\n",
    "\n",
    "        // Compute the ratio between the outdegree and the smem size\n",
    "\n",
    "        printf(\"smemSize: %d   blockDim: %d   size: %d   edgeSize: %d\\n\", smemSize, blockDim, size, edgeSize);\n",
    "\n",
    "        // Compute the size of the auxiliary array\n",
    "        for (uint i = 0; i < size; i++) {\n",
    "            uint outdegree = str->deg(i);\n",
    "            auxSize += (outdegree + smemSize - 1) / smemSize;\n",
    "        }\n",
    "        printf(\"auxSize: %d\\n\", auxSize);\n",
    "\n",
    "\n",
    "\n",
    "        // Allocating resources for the support arrays\n",
    "        uint *aux, *auxOffset, *candidates, *d_auxOffset, *d_aux, *d_candidates;\n",
    "        candidates = new uint[size];\n",
    "        aux = (uint *) malloc(auxSize * sizeof(uint));\n",
    "        auxOffset = (uint *) malloc(size * sizeof(uint));\n",
    "        CHECK(cudaMalloc((void **) &d_aux, auxSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_aux, INT_MAX, auxSize * sizeof(uint)));\n",
    "\n",
    "        // Copy the contents of auxOffset to device memory\n",
    "        CHECK(cudaMalloc((void **) &d_auxOffset, size * sizeof(uint)));\n",
    "        for (node i = 0; i < size; i++) {\n",
    "            auxOffset[i] = (i == 0) ? 0 : auxOffset[i - 1] + (str->deg(i - 1) + smemSize - 1) / smemSize;\n",
    "        }\n",
    "        CHECK(cudaMemcpy(d_auxOffset, auxOffset, size * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        for (node i = 0; i < size; i++) {\n",
    "            uint gridSize = (str->deg(i) + smemSize - 1) / smemSize;\n",
    "            int smem = smemSize * sizeof(uint);\n",
    "\n",
    "            //printf(\"%d > str->cumDegs[i]: %d   auxOffset[i]: %d   str->deg(i): %d   gridSize: %d\\n\", i, str->cumDegs[i], auxOffset[i], str->deg(i), gridSize);\n",
    "\n",
    "            findMinimumForVertex <<< gridSize, blockDim, smem >>> (str, d_aux, d_auxOffset, smemSize, i);\n",
    "        }\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Doing a preliminary minimum search took: %.5f seconds\\n\\n\", milliseconds / 1000.0);\n",
    "\n",
    "        CHECK(cudaMemcpy(aux, d_aux, auxSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        uint nanValues = 0;\n",
    "        for (uint i = 0; i < auxSize; i++) {\n",
    "            //printf(\"aux[%d]: %d\\n\", i, aux[i]);\n",
    "            if (aux[i] == UINT_MAX) {\n",
    "                nanValues++;\n",
    "            }\n",
    "        }\n",
    "        printf(\"There are %d NaN values out of %d\\n\", nanValues, auxSize);\n",
    "\n",
    "\n",
    "        // For every vertex pick the lightest edge\n",
    "        CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
    "        cudaEventRecord(start);\n",
    "        findMinimum<<< gridDim, blockDim >>>(str, d_aux, d_auxOffset, d_candidates);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime += milliseconds / 1000.0;\n",
    "        printf(\"Picking the minimum for every vertex: %.5f seconds\\n\\n\", milliseconds / 1000.0);\n",
    "\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        printf(\"The procedure took in total %.5f seconds\\n\\n\", spliTime);\n",
    "\n",
    "\n",
    "\n",
    "/*\n",
    "        // First setp of the algorithm\n",
    "        uint *d_candidates, *candidates;\n",
    "        candidates = new uint[size];\n",
    "        CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
    "\n",
    "        cout << \"Launching kernel FIND CHEAPEST -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        findCheapest<<<gridDim, blockDim>>>(str, d_candidates);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", spliTime);\n",
    "\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "*/\n",
    "\n",
    "        totalTime += spliTime;\n",
    "        firstPhase += spliTime;\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            for (node i = 0; i < size; i++) {\n",
    "                int min =  INT_MAX;\n",
    "                uint mindex = 0;\n",
    "                for (uint j = 0; j < str->deg(i); j++) {\n",
    "                    if (str->getWeight(i, j) < min) {\n",
    "                        mindex = j;\n",
    "                        min = str->getWeight(i, j);\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if (str->getWeight(i, mindex) < str->getWeight(i, candidates[i])) {\n",
    "                    printf(\"The GPU sequence is picking worse weights %d   CPU: %d(%d)    GPU: %d(%d)\\n\", i, mindex, str->getWeight(i, mindex), candidates[i], str->getWeight(i, candidates[i]));\n",
    "                    return -1;\n",
    "                }\n",
    "\n",
    "                //printf(\"%d >> CPU: %d    GPU: %d\\n\", i, mindex, candidates[i]);\n",
    "                //printf(\"%d >> CPU: %d(%d)   GPU: %d(%d)\\n\", i, str->getNeigh(i, mindex), str->getWeight(i, mindex), str->getNeigh(i, candidates[i]), str->getWeight(i, candidates[i]));\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        free(aux);\n",
    "        free(auxOffset);\n",
    "        CHECK(cudaFree(d_aux));\n",
    "        CHECK(cudaFree(d_auxOffset));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // ~Debugging~ print the cheapest edge for every vertex\n",
    "        if (DEBUGGING && size < 15) {\n",
    "            cout << \"The cheapest edge for every vertex\" << endl;\n",
    "            CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"node (\" << i << \") -> \" << str->getNeigh(i, candidates[i]) << \"(\"\n",
    "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
    "            }\n",
    "            cout << \"\\n\\n\\n\";\n",
    "        }\n",
    "        /*******************/\n",
    "\n",
    "\n",
    "\n",
    "        // Second step of the algorithm\n",
    "        cout << \"Launching kernel MIRRORED EDGES REMOVAL -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        mirroredEdgesRemoval<<<gridDim, blockDim>>>(str, d_candidates, d_mstWeight);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        CHECK(cudaMemcpy(&mstWeight, d_mstWeight, sizeof(int), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "        secondPhase += spliTime;\n",
    "        /********************/\n",
    "\n",
    "        // ~Debugging~ print the cheapest edge for every vertex update\n",
    "        if (DEBUGGING && size < 15) {\n",
    "            cout << \"Update of the cheapest edge for every vertex\" << endl;\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"node (\" << i << \") -> \";\n",
    "                if (candidates[i] != UINT_MAX) {\n",
    "                    cout << str->getNeigh(i, candidates[i]) << \"(\"\n",
    "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
    "                }\n",
    "                else {\n",
    "                    cout << \"NULL\" << endl;\n",
    "                }\n",
    "            }\n",
    "            printf (\"%d\\n\", mstWeight);\n",
    "        }\n",
    "        /*****************************/\n",
    "\n",
    "        cout << \"The MST weight at the end of iteration \" << iterations + 1 << \" is: \" << mstWeight << endl;\n",
    "\n",
    "\n",
    "\n",
    "        // Third step of the algorithm\n",
    "        cout << \"Launching kernel COLORATION PROCESS -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "\n",
    "        // Initialize the color array\n",
    "        uint *colors = new uint[size];\n",
    "        uint *d_colors;\n",
    "        CHECK(cudaMalloc((void**)&d_colors, size * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_colors, UINT_MAX, size * sizeof(uint)));\n",
    "        /**************************************************/\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        colorationProcess<<<gridDim, blockDim>>>(str, d_candidates, d_colors);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(colors, d_colors, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "        thirdPhase += spliTime;\n",
    "\n",
    "        // Print the coloring\n",
    "        if (DEBUGGING) {\n",
    "            uint *checkColoring = new uint[size];\n",
    "\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                checkColoring[i] = 0;\n",
    "            }\n",
    "\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                checkColoring[colors[i]]++;\n",
    "            }\n",
    "\n",
    "            uint nonZeroColors = 0;\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                if (checkColoring[i] != 0) {\n",
    "                    nonZeroColors++;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            cout << \"There is a total of \" << nonZeroColors << \" colors\" << endl;\n",
    "\n",
    "            cout << \"\\n\\n\\n\";\n",
    "        }\n",
    "        /*******************/\n",
    "\n",
    "        /**\n",
    "         * If the coloring coming out of the last kernel contains only one color\n",
    "         * then it means that the edge added in the last step was the one needed\n",
    "         * to merge the partial trees\n",
    "         **/\n",
    "        uint color = colors[0];\n",
    "        bool uniqueColor = true;\n",
    "        for (uint i = 1; i < size; i++) {\n",
    "            if (colors[i] != color) {\n",
    "                uniqueColor = false;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "        if (uniqueColor) {\n",
    "            cout << \"THE CALCULATION OF THE MST IS COMPLETE\\n\";\n",
    "            cout << \"THE MST WEIGHT IS: \" << mstWeight << endl;\n",
    "            printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
    "            printf(\"The time distribution is the following:\\n\\tFirst phase: %.5f\\n\\tSecond phase: %.5f\\n\\tThird phase: %.5f\\n\\tFourth phase: %.5f\\n\\tFifth phase: %.5f\\n\", firstPhase, secondPhase, thirdPhase, fourthPhase, fifthPhase);\n",
    "\n",
    "            // Cuda memory deallocation\n",
    "            CHECK(cudaEventDestroy(start));\n",
    "            CHECK(cudaEventDestroy(stop));\n",
    "            CHECK(cudaFree(d_candidates));\n",
    "            CHECK(cudaFree(d_colors));\n",
    "\n",
    "            // Host memory deallocation\n",
    "            delete[] candidates;\n",
    "            delete[] colors;\n",
    "\n",
    "            return 0;\n",
    "        }\n",
    "        /***********/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Fourth step of the algorithm\n",
    "        cout << \"Doing a round of scan on the flag vector, size: \" << size << endl;\n",
    "        uint *flag = new uint[size];\n",
    "        uint *cFlag = new uint[size];\n",
    "        for (uint i = 0; i < size; i++) {\n",
    "            flag[i] = (colors[i] == i) ? 1 : 0;\n",
    "            cFlag[i] = flag[i];\n",
    "        }\n",
    "        uint *d_flag;\n",
    "\n",
    "        CHECK(cudaMalloc((void**)&d_flag, (size) * sizeof(uint)));\n",
    "\n",
    "        if (size < smemSize) {\n",
    "            cout << \"Resorting to a round of CPU scan\" << endl;\n",
    "            cudaEventRecord(start);\n",
    "            cpuScan(flag, 0, size);\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            float milliseconds;\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime = milliseconds / 1000.0;\n",
    "            printf(\"Time required for a round of CPU scan on the flag array:   %.5f (sec)\\n\", spliTime);\n",
    "            totalTime += spliTime;\n",
    "            fourthPhase += spliTime;\n",
    "            CHECK(cudaMemcpy(d_flag, flag, (size) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "        }\n",
    "        else {\n",
    "            uint *d_aux, *aux, *d_ogFlag;\n",
    "\n",
    "            uint numSmemBlock = (size + smemSize - 1) / smemSize;\n",
    "            uint numBlock = (size + blockDim - 1) / blockDim;\n",
    "\n",
    "            aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
    "\n",
    "            CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
    "            CHECK(cudaMalloc((void **) &d_ogFlag, size * sizeof(uint)));\n",
    "\n",
    "            CHECK(cudaMemcpy(d_ogFlag, flag, (size) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "            CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
    "            CHECK(cudaMemset(d_flag, 0, (size) * sizeof(uint)));\n",
    "\n",
    "            // Copy the contents of gpuArray in the Device memory\n",
    "            CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
    "            CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
    "\n",
    "            printf(\"\\n  block scan...\\n\");\n",
    "\n",
    "            size_t smem = smemSize * sizeof(uint);\n",
    "            printf(\"\\n  prescan procedure on: %d elements...\\n\", size);\n",
    "            cudaEventRecord(start);\n",
    "            prescan<<<  numSmemBlock, blockDim, smem >>>(d_flag, d_ogFlag, d_aux, size, smemSize);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime = milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "            CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "            printf(\"\\n  CPU scan procedure of the aux array: %d elements...\\n\", numSmemBlock + 1);\n",
    "            cudaEventRecord(start);\n",
    "            cpuScan(aux, 0, numSmemBlock + 1);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime += milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "            CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "            printf(\"\\n  final summation procedure...\\n\");\n",
    "            cudaEventRecord(start);\n",
    "            final_sum<<< numBlock, blockDim >>>(d_flag, d_aux, size);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime += milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
    "            printf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", spliTime);\n",
    "\n",
    "            totalTime += spliTime;\n",
    "            fourthPhase += spliTime;\n",
    "            CHECK(cudaMemcpy(flag, d_flag, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "            free(aux);\n",
    "            CHECK(cudaFree(d_aux));\n",
    "            CHECK(cudaFree(d_ogFlag));\n",
    "        }\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            for (uint i = 1; i < size; i++) {\n",
    "                cFlag[i] += cFlag[i - 1];\n",
    "            }\n",
    "\n",
    "            for (uint i = 0; i < size - 1; i++) {\n",
    "                if (cFlag[i] != flag[i + 1]) {\n",
    "                    cout << \"I due array sono diversi in posizione \" << i << endl;\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        delete[] cFlag;\n",
    "        cout << \"The contracted graph will contain \" << flag[size - 1] << \" supervertices\\n\\n\" << endl;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Fifth step of the algorithm\n",
    "\n",
    "        // Allocating resources for the new cumulated degrees array\n",
    "        uint newNodeSize = flag[size - 1];\n",
    "        uint cumDegSize = newNodeSize + 1;\n",
    "        uint *cumDegs = new uint[cumDegSize];\n",
    "        uint *d_cumDegs;\n",
    "        CHECK(cudaMalloc((void**)&d_cumDegs, (cumDegSize) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
    "        /***********************************/\n",
    "\n",
    "        cout << \"Launching kernel CUMULATED DEGREE UPDATE -- (\" << blockDim << \", 1, 1) -- (\" << searchGrid << \", 1, 1)\" << endl;\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        cumulatedDegreeUpdateCopy<<< searchGrid, blockDim >>>(str, d_cumDegs, d_colors, d_flag);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Doing the computation of the cumulated degrees took: %.5f seconds\\n\\n\", spliTime);\n",
    "        CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        // ~Debugging~ looking for errors in the cumulated degrees array\n",
    "        if (DEBUGGING) {\n",
    "            uint *checkDegs = new uint[cumDegSize];\n",
    "            for (uint i = 0; i < cumDegSize; i++) {\n",
    "                checkDegs[i] = 0;\n",
    "            }\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                uint color = colors[i];\n",
    "                node svSuccessor = getRoot(i, flag, colors);\n",
    "                uint sum = 0;\n",
    "\n",
    "                for (uint j = 0; j < str->deg(i); j++) {\n",
    "                    node neigh = str->getNeigh(i, j);\n",
    "                    uint neighColor = colors[neigh];\n",
    "\n",
    "                    if (color != neighColor) {\n",
    "                        sum++;\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                checkDegs[svSuccessor] += sum;\n",
    "            }\n",
    "            for (uint i = 0; i < cumDegSize; i++) {\n",
    "                if (cumDegs[i] != checkDegs[i]) {\n",
    "                    cout << i << \": cumDegs - \" << cumDegs[i + 1] << \"\\tcheckDegs - \" << checkDegs[i] << endl;\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "            cout << \"The CPU check vector and the GPU computed one are the same\\n\\n\" << endl;\n",
    "            delete[] checkDegs;\n",
    "        }\n",
    "        /********************/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Perform another prefix sum on the cumDegrees array\n",
    "        cout << \"Doing a round of scan on the cumDegs vector, size: \" << cumDegSize << endl;\n",
    "\n",
    "        uint *cCumDegs = new uint[cumDegSize];\n",
    "        for (uint i = 0; i < cumDegSize; i++) {\n",
    "            cCumDegs[i] = cumDegs[i];\n",
    "        }\n",
    "\n",
    "        if (cumDegSize < smemSize) {\n",
    "            cout << \"Resorting to a round of CPU scan\" << endl;\n",
    "            cpuScan(cumDegs, 0, cumDegSize);\n",
    "            CHECK(cudaMemcpy(d_cumDegs, cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "        }\n",
    "        else {\n",
    "            uint *d_aux, *aux, *d_ogCumDegs;\n",
    "\n",
    "            uint numSmemBlock = (cumDegSize + smemSize - 1) / smemSize;\n",
    "            uint numBlock = (cumDegSize + blockDim - 1) / blockDim;\n",
    "            uint gpuScanSize = numSmemBlock * smemSize;\n",
    "            uint residualSize = cumDegSize - gpuScanSize;\n",
    "\n",
    "            aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
    "\n",
    "            CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
    "            CHECK(cudaMalloc((void **) &d_ogCumDegs, cumDegSize * sizeof(uint)));\n",
    "\n",
    "            CHECK(cudaMemcpy(d_ogCumDegs, cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "            CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
    "            CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
    "\n",
    "            printf(\"\\n  block scan...\\n\");\n",
    "\n",
    "            uint smem = smemSize * sizeof(uint);\n",
    "            printf(\"\\n  first prescan procedure on the Device: %d elements...\\n\", cumDegSize);\n",
    "            cudaEventRecord(start);\n",
    "            prescan<<<  numSmemBlock, blockDim, smem >>>(d_cumDegs, d_ogCumDegs, d_aux, cumDegSize, smemSize);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            float milliseconds;\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime = milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "            // Copy the contents of the aux array into Host memory and perform another scan\n",
    "            printf(\"\\n  CPU scan procedure of the aux array: %d elements...\\n\", numSmemBlock);\n",
    "            CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "            cudaEventRecord(start);\n",
    "            cpuScan(aux, 0, numSmemBlock + 1);\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime += milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "            // Copy the portions of the array computed on the Host to Device memory\n",
    "            CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "            printf(\"\\n  final summation procedure...\\n\");\n",
    "            cudaEventRecord(start);\n",
    "            final_sum<<< numBlock, blockDim >>>(d_cumDegs, d_aux, cumDegSize);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime += milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
    "\n",
    "            printf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", spliTime);\n",
    "\n",
    "            totalTime += spliTime;\n",
    "            CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "            free(aux);\n",
    "            CHECK(cudaFree(d_aux));\n",
    "            CHECK(cudaFree(d_ogCumDegs));\n",
    "        }\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            for (uint i = 1; i < cumDegSize; i++) {\n",
    "                cCumDegs[i] += cCumDegs[i - 1];\n",
    "            }\n",
    "\n",
    "            for (uint i = 0; i < cumDegSize - 1; i++) {\n",
    "                if (cCumDegs[i] != cumDegs[i + 1]) {\n",
    "                    cout << \"I due array sono diversi in posizione \" << i << endl;\n",
    "                    cout << cCumDegs[i] << \"   \" << cumDegs[i + 1];\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        cout << \"The contracted graph will contain \" << cumDegs[cumDegSize - 1] << \" edges\" << endl;\n",
    "        cout << \"The old graph structure contained \" << str->edgeSize << \" edges\\n\\n\" << endl;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Allocating space for the arrays in the newly contracted graph\n",
    "        uint newEdgeSize = cumDegs[cumDegSize - 1];\n",
    "        node *newNeighs = new node[newEdgeSize];\n",
    "        uint *newWeights = new uint[newEdgeSize];\n",
    "\n",
    "        uint *d_newNeighs, *d_newWeights;\n",
    "        CHECK(cudaMalloc((void **)&d_newNeighs, newEdgeSize * sizeof(node)));\n",
    "        CHECK(cudaMalloc((void **)&d_newWeights, newEdgeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_newNeighs, 0, newEdgeSize * sizeof(node)));\n",
    "        CHECK(cudaMemset(d_newWeights, 0, newEdgeSize * sizeof(uint)));\n",
    "\n",
    "        cout << \"Launching kernel GRAPH CONSTRUCTION -- (\" << blockDim << \", 1, 1) -- (\" << searchGrid << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        graphContractionCopy<<<searchGrid, blockDim>>>(str, d_colors, d_flag, d_cumDegs, d_newNeighs, d_newWeights);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        printf(\"The construction of the new neighbour and weight arrays took: %.5f seconds\\n\\n\", milliseconds/1000);\n",
    "        spliTime += milliseconds / 1000.0;\n",
    "        CHECK(cudaMemcpy(newNeighs, d_newNeighs, newEdgeSize * sizeof(node), cudaMemcpyDeviceToHost));\n",
    "        CHECK(cudaMemcpy(newWeights, d_newWeights, newEdgeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "\n",
    "\n",
    "        // Reconstructing the graph\n",
    "        graphPointer->copyConstructor(newNodeSize, newEdgeSize, newNeighs, newWeights, cumDegs);\n",
    "\n",
    "        //graphPointer->print(true);\n",
    "\n",
    "        printf(\"----------------------------------\\n\\n\");\n",
    "        /***********************************************/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Updating the iteration information\n",
    "        totalTime += spliTime;\n",
    "        fifthPhase += spliTime;\n",
    "        iterations++;\n",
    "        /*****************************************/\n",
    "\n",
    "\n",
    "        // Cuda memory deallocation\n",
    "        CHECK(cudaFree(d_candidates));\n",
    "        CHECK(cudaFree(d_colors));\n",
    "        CHECK(cudaFree(d_flag));\n",
    "        CHECK(cudaFree(d_cumDegs));\n",
    "        CHECK(cudaFree(d_newNeighs));\n",
    "        CHECK(cudaFree(d_newWeights));\n",
    "        /****************************/\n",
    "\n",
    "        // Host memory deallocation\n",
    "        delete[] candidates;\n",
    "        delete[] colors;\n",
    "        delete[] flag;\n",
    "        delete[] cumDegs;\n",
    "        delete[] newNeighs;\n",
    "        delete[] newWeights;\n",
    "        /******************/\n",
    "    }\n",
    "\n",
    "    printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
    "    printf(\"The calculation of the MST took %d iterations\\n\\n\", iterations);\n",
    "    printf(\"The total weight of the tree is %d\\n\", mstWeight);\n",
    "\n",
    "\n",
    "    CHECK(cudaEventDestroy(start));\n",
    "    CHECK(cudaEventDestroy(stop));\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9c-9aGqbHiD",
    "outputId": "4bac55d9-5bca-49eb-d849-c7e48ce9ded5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01m\u001b[Ksrc/GPU/mstGPUEmfk.cu:16:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[K../COMMON/sharedMacros.h: No such file or directory\n",
      "   16 | #include \u001b[01;31m\u001b[K\"../COMMON/sharedMacros.h\"\u001b[m\u001b[K\n",
      "      |          \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "compilation terminated.\n",
      "/bin/bash: line 1: ./mstGPUEmfk: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Compilazione ed esecuzione\n",
    "\n",
    "!nvcc -arch=sm_75 GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/GPU/mstGPUEmfk.cu -o mstGPUEmfk\n",
    "!./mstGPUEmfk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KqoBgM--a13"
   },
   "source": [
    "## Hybrid approach\n",
    "\n",
    "The code below uses an hybrid approach where a part of the code is working with the GPU and a part of the code is using the CPU, namely:\n",
    "\n",
    "- Finding the cheapest edge for every node is implemented using a GPU kernel\n",
    "- The scan operation is implemented with a CPU procedure because it's more efficient than the naive GPU counterpart\n",
    "- The removal of mirrored edges is implemented using a GPU kernel\n",
    "- Finding the connected components is done through a recursive GPU kernel\n",
    "- Calculating the outdegrees for the supervertices is done with a GPU kernel\n",
    "- The new graph allocation is done through a CPU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CkG5s5Ph76C"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"mstHBD.cu\" --group \"GPU\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <limits.h>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "/*****\n",
    "* Device function that gets the degree of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The node we are interested in\n",
    "*****/\n",
    "__device__ node d_deg (GraphStruct *str, node i) {\n",
    "    return str->cumDegs[i + 1] - str->cumDegs[i];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the weight of a certain edge\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ int d_getWeight (GraphStruct *str, node i, uint offset) {\n",
    "    return str->weights[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the neighbour of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
    "    return str->neighs[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "__device__ uint d_getRoot (uint i, uint *d_flag, uint *d_colors) {\n",
    "    return max(0, d_flag[d_colors[i]] - 1);\n",
    "}\n",
    "\n",
    "uint getRoot (uint i, uint *flag, uint *colors) {\n",
    "    return max(0, flag[colors[i]] - 1);\n",
    "}\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that finds the cheapest edge in the adjacency list of every node\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "*****/\n",
    "__global__ void findCheapest (GraphStruct *str, uint *d_candidates) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // Initialize the minimum value\n",
    "    uint minimum = UINT_MAX;\n",
    "    int minimumWeight = INT_MAX;\n",
    "\n",
    "    // Find the cheapest edge in each adjacency list\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        int edgeWeight = d_getWeight(str, idx, i);\n",
    "        if (edgeWeight < minimumWeight) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "        else if (edgeWeight == minimumWeight &&\n",
    "                 d_getNeigh(str, idx, i) < d_getNeigh(str, idx, minimum)) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Update the return vector\n",
    "    d_candidates[idx] = minimum;\n",
    "}\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that removes the mirrored edges from the graph. A mirrored edge is\n",
    "* simply an edge pointing from the source to the destination and vice versa in\n",
    "* an oriented graph, the removal logic is to cut the edge with the lowest source\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "*****/\n",
    "__global__ void mirroredEdgesRemoval (GraphStruct *str, uint *d_candidates, int *d_weight) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint destinationOffset = d_candidates[idx];\n",
    "    node destination = d_getNeigh(str, idx, destinationOffset);\n",
    "    if (idx < destination) {\n",
    "        uint sourceOffset = d_candidates[destination];\n",
    "        node destinationNeigh = d_getNeigh(str, destination, sourceOffset);\n",
    "\n",
    "        // The vertex cannot be a candidate anymore because it would create a cycle\n",
    "        if (destinationNeigh == idx) {\n",
    "            d_candidates[idx] = UINT_MAX;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (d_candidates[idx] != UINT_MAX) {\n",
    "        atomicAdd(d_weight, d_getWeight(str, idx, d_candidates[idx]));\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "/*****\n",
    "* Helper device function that recursively colors the nodes of the graph\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "* @param i - The index of the node to be colored\n",
    "* @param d_colors - The device-level array of colors assigned to each vertex\n",
    "*****/\n",
    "__device__ uint *d_recursiveColorationHelper (GraphStruct *str, uint *d_candidates, node i, uint *d_colors) {\n",
    "    uint color = UINT_MAX;\n",
    "    if (d_candidates[i] == UINT_MAX) {\n",
    "        color = i;\n",
    "    }\n",
    "    else {\n",
    "        node neigh = d_getNeigh(str, i, d_candidates[i]);\n",
    "        color = d_recursiveColorationHelper(str, d_candidates, neigh, d_colors)[neigh];\n",
    "    }\n",
    "\n",
    "    if (color != UINT_MAX) {\n",
    "        d_colors[i] = color;\n",
    "    }\n",
    "    return d_colors;\n",
    "}\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that recognizes the connected components in the graph and colors them\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree\n",
    "* @param d_colors - The device-level array of colors assigned to each vertex\n",
    "*****/\n",
    "__global__ void colorationProcess(GraphStruct *str, uint *d_candidates, uint *d_colors) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    d_recursiveColorationHelper(str, d_candidates, idx, d_colors);\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void cumulatedDegreeUpdate(GraphStruct *str, uint *d_cumDegs, uint *d_colors, uint *d_flag) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint color = d_colors[idx];\n",
    "    node svSuccessor = d_getRoot(idx, d_flag, d_colors) + 1;\n",
    "    uint sum = 0;\n",
    "\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        node neigh = d_getNeigh(str, idx, i);\n",
    "        uint neighColor = d_colors[neigh];\n",
    "\n",
    "        if (color != neighColor) {\n",
    "            sum++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    atomicAdd(&(d_cumDegs[svSuccessor]), sum);\n",
    "}\n",
    "\n",
    "\n",
    "uint *CPUScan(uint *input, uint size) {\n",
    "    for (uint i = 1; i < size; i++) {\n",
    "        input[i] = input[i - 1] + input[i];\n",
    "    }\n",
    "    return input;\n",
    "}\n",
    "\n",
    "\n",
    "int main () {\n",
    "    // Generation of a random graph\n",
    "    std::random_device rd;\n",
    "    std::default_random_engine eng(FIXED_SEED);\n",
    "    uint maxWeight = MAX_WEIGHT;\n",
    "    float prob = .5;\n",
    "    bool GPUEnabled = 1;\n",
    "    Graph *graphPointer;\n",
    "    Graph graph(SIZE, GPUEnabled);\n",
    "    graphPointer = &graph;\n",
    "  \tgraphPointer->randGraph(prob, true, maxWeight, eng);\n",
    "    /**************************************************/\n",
    "\n",
    "\n",
    "    // Checking if the random graph is connected\n",
    "    if (!graphPointer->isConnected()) {\n",
    "        cout << \"The graph is not connected\" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "    /************/\n",
    "\n",
    "\n",
    "    uint iterations = 0;\n",
    "\n",
    "\n",
    "    // Configuration of the GPU kernel\n",
    "    uint blockDim = BLOCK_SIZE;\n",
    "    uint *candidates;\n",
    "    /***************/\n",
    "\n",
    "\n",
    "    // Events to measure time\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    float milliseconds;\n",
    "    float spliTime = 0;\n",
    "    float totalTime = 0;\n",
    "    /******************/\n",
    "\n",
    "\n",
    "    // Variables calculating the MST weight\n",
    "    int mstWeight = 0;\n",
    "    int *d_mstWeight;\n",
    "    CHECK(cudaMalloc((void **)&d_mstWeight, sizeof(int)));\n",
    "    CHECK(cudaMemcpy(d_mstWeight, &mstWeight, sizeof(int), cudaMemcpyHostToDevice));\n",
    "    /******************************************************************************/\n",
    "\n",
    "\n",
    "    // Main block of the algorithm\n",
    "    while (graphPointer->getStruct()->nodeSize > 1) {\n",
    "        // Initialization of the variables associated with the graph\n",
    "        GraphStruct *str = graphPointer->getStruct();\n",
    "        uint size = str->nodeSize;\n",
    "        uint edgeSize = str->edgeSize;\n",
    "        cout << \"Processing a graph of size: \" << size << \" with \" << edgeSize << \" edges.\\n\\n\";\n",
    "        uint gridDim = (size + blockDim - 1) / blockDim;\n",
    "        if (DEBUGGING && size < 15 && str->edgeSize < 100) {\n",
    "            graphPointer->print(true);\n",
    "            print_d<<<1, 1>>>(str, 1);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "        }\n",
    "        candidates = new uint[size];\n",
    "        /**************************/\n",
    "\n",
    "        // First setp of the algorithm\n",
    "        uint *d_candidates;\n",
    "        CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
    "        cout << \"Launching kernel FIND CHEAPEST -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        findCheapest<<<gridDim, blockDim>>>(str, d_candidates);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "        /********************/\n",
    "\n",
    "        // ~Debugging~ print the cheapest edge for every vertex\n",
    "        if (DEBUGGING && size < 15) {\n",
    "            cout << \"The cheapest edge for every vertex\" << endl;\n",
    "            CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"node (\" << i << \") -> \" << str->getNeigh(i, candidates[i]) << \"(\"\n",
    "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
    "            }\n",
    "            cout << \"\\n\\n\\n\";\n",
    "        }\n",
    "        /*******************/\n",
    "\n",
    "\n",
    "\n",
    "        // Second step of the algorithm\n",
    "        cout << \"Launching kernel MIRRORED EDGES REMOVAL -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        mirroredEdgesRemoval<<<gridDim, blockDim>>>(str, d_candidates, d_mstWeight);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        CHECK(cudaMemcpy(&mstWeight, d_mstWeight, sizeof(int), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "        /********************/\n",
    "\n",
    "        // ~Debugging~ print the cheapest edge for every vertex update\n",
    "        if (DEBUGGING && size < 15) {\n",
    "            cout << \"Update of the cheapest edge for every vertex\" << endl;\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"node (\" << i << \") -> \";\n",
    "                if (candidates[i] != UINT_MAX) {\n",
    "                    cout << str->getNeigh(i, candidates[i]) << \"(\"\n",
    "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
    "                }\n",
    "                else {\n",
    "                    cout << \"NULL\" << endl;\n",
    "                }\n",
    "            }\n",
    "            printf (\"%d\\n\", mstWeight);\n",
    "        }\n",
    "        /*****************************/\n",
    "        printf (\"%d\\n\", mstWeight);\n",
    "\n",
    "\n",
    "\n",
    "        // Third step of the algorithm\n",
    "        cout << \"Launching kernel COLORATION PROCESS -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "\n",
    "        // Initialize the color array\n",
    "        uint *colors = new uint[size];\n",
    "        uint *d_colors;\n",
    "        CHECK(cudaMalloc((void**)&d_colors, size * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_colors, UINT_MAX, size * sizeof(uint)));\n",
    "        /*********************************************************/\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        colorationProcess<<<gridDim, blockDim>>>(str, d_candidates, d_colors);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(colors, d_colors, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        // Print the coloring\n",
    "        if (DEBUGGING) {\n",
    "            uint *checkColoring = new uint[size];\n",
    "\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                checkColoring[i] = 0;\n",
    "            }\n",
    "\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                checkColoring[colors[i]]++;\n",
    "            }\n",
    "\n",
    "            uint nonZeroColors = 0;\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                if (checkColoring[i] != 0) {\n",
    "                    cout << \"color \" << i << \"\\t\" << checkColoring[i] << endl;\n",
    "                    nonZeroColors++;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            cout << \"There is a total of \" << nonZeroColors << \" colors\" << endl;\n",
    "\n",
    "            cout << \"\\n\\n\\n\";\n",
    "        }\n",
    "        /*******************/\n",
    "\n",
    "        /**\n",
    "         * If the coloring coming out of the last kernel contains only one color\n",
    "         * then it means that the edge added in the last step was the one needed\n",
    "         * to merge the partial trees\n",
    "         **/\n",
    "        uint color = colors[0];\n",
    "        bool uniqueColor = true;\n",
    "        for (uint i = 1; i < size; i++) {\n",
    "            if (colors[i] != color) {\n",
    "                uniqueColor = false;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "        if (uniqueColor) {\n",
    "            cout << \"THE CALCULATION OF THE MST IS COMPLETE\\n\";\n",
    "            cout << \"THE MST WEIGHT IS: \" << mstWeight << endl;\n",
    "            printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
    "\n",
    "            // Cuda memory deallocation\n",
    "            CHECK(cudaEventDestroy(start));\n",
    "            CHECK(cudaEventDestroy(stop));\n",
    "            CHECK(cudaFree(d_candidates));\n",
    "            CHECK(cudaFree(d_colors));\n",
    "\n",
    "            // Host memory deallocation\n",
    "            delete[] candidates;\n",
    "            delete[] colors;\n",
    "\n",
    "            return 0;\n",
    "        }\n",
    "        /***********/\n",
    "\n",
    "\n",
    "\n",
    "        // Fourth step of the algorithm\n",
    "        cout << \"Launching a round of CPU scan\\n\\n\" << endl;\n",
    "        uint *flag = new uint[size];\n",
    "        for (uint i = 0; i < size; i++) {\n",
    "            flag[i] = (colors[i] == i) ? 1 : 0;\n",
    "        }\n",
    "        cudaEventRecord(start);\n",
    "        flag = CPUScan(flag, size);\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Doing the prefix sum of the auxiliary flag array took: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "        if (DEBUGGING) {\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                if (colors[i] == i) {\n",
    "                    cout << \"Mapping color \" << i << \" to \" << getRoot(i, flag, colors) << endl;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        uint *d_flag;\n",
    "\n",
    "        CHECK(cudaMalloc((void**)&d_flag, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemcpy(d_flag, flag, (size) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "        /*****************************************************************************/\n",
    "\n",
    "\n",
    "\n",
    "        // Fifth step of the algorithm\n",
    "\n",
    "        // Allocating resources for the new cumulated degrees array\n",
    "        uint newNodeSize = flag[size - 1];\n",
    "        uint cumDegSize = newNodeSize + 1;\n",
    "        uint *cumDegs = new uint[cumDegSize];\n",
    "        uint *d_cumDegs;\n",
    "        CHECK(cudaMalloc((void**)&d_cumDegs, (cumDegSize) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
    "        /***********************************************************/\n",
    "\n",
    "        cout << \"Launching kernel CUMULATED DEGREE UPDATE -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        cumulatedDegreeUpdate<<<gridDim, blockDim>>>(str, d_cumDegs, d_colors, d_flag);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Doing the computation of the cumulated degrees took: %.5f seconds\\n\\n\", spliTime);\n",
    "        CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        // ~Debugging~ looking for errors in the cumulated degrees array\n",
    "        if (DEBUGGING) {\n",
    "            uint *checkDegs = new uint[cumDegSize];\n",
    "            for (uint i = 0; i < cumDegSize; i++) {\n",
    "                checkDegs[i] = 0;\n",
    "            }\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                uint color = colors[i];\n",
    "                node svSuccessor = getRoot(i, flag, colors) + 1;\n",
    "                uint sum = 0;\n",
    "\n",
    "                for (uint j = 0; j < str->deg(i); j++) {\n",
    "                    node neigh = str->getNeigh(i, j);\n",
    "                    uint neighColor = colors[neigh];\n",
    "\n",
    "                    if (color != neighColor) {\n",
    "                        sum++;\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                checkDegs[svSuccessor] += sum;\n",
    "            }\n",
    "            for (uint i = 0; i < cumDegSize; i++) {\n",
    "                if (checkDegs[i] != cumDegs[i]) {\n",
    "                    cout << i << \" \" << checkDegs[i] << \" \" << cumDegs[i] << endl;\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "            cout << \"The CPU check vector and the GPU computed one are the same\" << endl;\n",
    "            delete[] checkDegs;\n",
    "        }\n",
    "        /*********************/\n",
    "\n",
    "\n",
    "        // Perform another prefix sum on the cumDegrees array\n",
    "        cout << \"Launching a round of CPU scan\\n\\n\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        cumDegs = CPUScan(cumDegs, cumDegSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        printf(\"Doing the scan of the new cumDegs array took: %.5f seconds\\n\\n\", milliseconds/1000);\n",
    "        spliTime += milliseconds / 1000.0;\n",
    "\n",
    "        // ~Debugging~ print the results of the scan operation on the cum degrees array\n",
    "        if (DEBUGGING) {\n",
    "            uint j = 0;\n",
    "            for (uint i = 0; i < cumDegSize; i++) {\n",
    "                cout << cumDegs[i] << \"   \";\n",
    "                j++;\n",
    "                if (j == 10) {\n",
    "                    cout << endl;\n",
    "                    j = 0;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        /****************/\n",
    "\n",
    "\n",
    "        // Allocating space for the arrays in the newly contracted graph\n",
    "        uint newEdgeSize = cumDegs[cumDegSize - 1];\n",
    "        node *newNeighs = new node[newEdgeSize];\n",
    "        uint *newWeights = new uint[newEdgeSize];\n",
    "        /***************************************/\n",
    "\n",
    "        // Copy the contents of cumDegs into a new array\n",
    "        uint *cCumDegs = new uint[cumDegSize];\n",
    "        for (uint i = 0; i < cumDegSize; i++) {\n",
    "            cCumDegs[i] = cumDegs[i];\n",
    "        }\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        for (uint i = 0; i < size; i++) {\n",
    "            uint color = colors[i];\n",
    "            node superVertex = getRoot(i, flag, colors);\n",
    "\n",
    "            for (uint j = 0; j < str->deg(i); j++) {\n",
    "                node neigh = str->getNeigh(i, j);\n",
    "                uint neighColor = colors[neigh];\n",
    "\n",
    "                if (color != neighColor) {\n",
    "                    int weight = str->getWeight(i, j);\n",
    "                    uint position = cCumDegs[superVertex];\n",
    "                    newNeighs[position] = getRoot(neigh, flag, colors);\n",
    "                    newWeights[position] = weight;\n",
    "                    cCumDegs[superVertex]++;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        printf(\"The construction of the new neighbour and weight arrays took: %.5f seconds\\n\\n\", milliseconds/1000);\n",
    "        spliTime += milliseconds / 1000.0;\n",
    "\n",
    "\n",
    "\n",
    "        // Reconstructing the graph\n",
    "        graphPointer->copyConstructor(newNodeSize, newEdgeSize, newNeighs, newWeights, cumDegs);\n",
    "        printf(\"----------------------------------\\n\\n\");\n",
    "        /***********************************************/\n",
    "\n",
    "\n",
    "\n",
    "        // Updating the iteration information\n",
    "        totalTime += spliTime;\n",
    "        iterations++;\n",
    "        /***********/\n",
    "\n",
    "\n",
    "        // Cuda memory deallocation\n",
    "        CHECK(cudaFree(d_candidates));\n",
    "        CHECK(cudaFree(d_colors));\n",
    "        CHECK(cudaFree(d_flag));\n",
    "        CHECK(cudaFree(d_cumDegs));\n",
    "        /*************************/\n",
    "\n",
    "        // Host memory deallocation\n",
    "        delete[] candidates;\n",
    "        delete[] colors;\n",
    "        delete[] flag;\n",
    "        delete[] cumDegs;\n",
    "        delete[] newNeighs;\n",
    "        delete[] newWeights;\n",
    "        delete[] cCumDegs;\n",
    "        /****************/\n",
    "    }\n",
    "\n",
    "    printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
    "    printf(\"The calculation of the MST took %d iterations\\n\\n\", iterations);\n",
    "    printf(\"The total weight of the tree is %d\\n\", mstWeight);\n",
    "\n",
    "\n",
    "    CHECK(cudaEventDestroy(start));\n",
    "    CHECK(cudaEventDestroy(stop));\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WL9T_IxiZvuv",
    "outputId": "8bf56abf-158b-45b5-db7e-03b68be8e3f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compilation terminated.\n",
      "nvcc error   : 'cudafe++' died due to signal 2 \n",
      "/bin/bash: line 1: ./mstHBD: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Compilazione ed esecuzione\n",
    "\n",
    "!nvcc -arch=sm_75 GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/GPU/mstHBD.cu -o mstHBD\n",
    "!./mstHBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OhoBGXoHMZ1"
   },
   "source": [
    "## GPU with textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKLfNXkXHQAV"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"mstGPUETex.cu\" --group \"GPU\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <limits.h>\n",
    "#include <fstream>\n",
    "#include <string>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "#include \"../COMMON/readGraph.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "/*****\n",
    "* Device function that gets the degree of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The node we are interested in\n",
    "*****/\n",
    "__device__ node d_deg (GraphStruct *str, node i) {\n",
    "    return str->cumDegs[i + 1] - str->cumDegs[i];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the weight of a certain edge\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ int d_getWeight (GraphStruct *str, node i, uint offset) {\n",
    "    return str->weights[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the neighbour of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
    "    return str->neighs[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "__device__ uint d_getRoot (uint i, uint *d_flag, uint *d_colors) {\n",
    "    return max(0, d_flag[d_colors[i]]);\n",
    "}\n",
    "\n",
    "__device__ uint d_getPosition(GraphStruct *str, node i, uint offset) {\n",
    "    return str->cumDegs[i] + offset;\n",
    "}\n",
    "\n",
    "uint getRoot (uint i, uint *flag, uint *colors) {\n",
    "    return max(0, flag[colors[i]]);\n",
    "}\n",
    "\n",
    "\n",
    "__device__ uint binarySearch (uint *d_cumDegs, uint neighPosition, uint cumDegSize) {\n",
    "    uint left = 0;\n",
    "    uint right = cumDegSize - 1;\n",
    "\n",
    "    if (d_cumDegs[right] <= neighPosition) {\n",
    "        return right;\n",
    "    }\n",
    "\n",
    "    while (left <= right) {\n",
    "        uint mid = (left + right) / 2;\n",
    "        if (d_cumDegs[mid] <= neighPosition) {\n",
    "            left = mid + 1;\n",
    "        }\n",
    "        else {\n",
    "            right = mid - 1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (left == right) {\n",
    "        return left;\n",
    "    }\n",
    "    return left - 1;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void findCheapestTexture (GraphStruct *str, uint *d_candidates, cudaTextureObject_t wtex, cudaTextureObject_t ntex) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // Initialize the minimum value\n",
    "    uint minimum = UINT_MAX;\n",
    "    int minimumWeight = INT_MAX;\n",
    "\n",
    "    uint loopEnd = d_getPosition(str, idx, d_deg(str, idx));\n",
    "\n",
    "    // Find the cheapest edge in each adjacency list\n",
    "    for (uint i = d_getPosition(str, idx, 0); i < loopEnd; i++) {\n",
    "        int edgeWeight = tex1Dfetch<int>(wtex, i);\n",
    "        if (edgeWeight < minimumWeight) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "        else {\n",
    "            uint neigh = tex1Dfetch<int>(ntex, i);\n",
    "            uint miNeigh = (minimum == UINT_MAX) ?  UINT_MAX : tex1Dfetch<int>(ntex, minimum);\n",
    "\n",
    "            if (edgeWeight == minimumWeight && neigh < miNeigh) {\n",
    "                minimumWeight = edgeWeight;\n",
    "                minimum = i;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Update the return vector\n",
    "    d_candidates[idx] = minimum - str->cumDegs[idx];\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that removes the mirrored edges from the graph. A mirrored edge is\n",
    "* simply an edge pointing from the source to the destination and vice versa in\n",
    "* an oriented graph, the removal logic is to cut the edge with the lowest source\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "*****/\n",
    "__global__ void mirroredEdgesRemoval (GraphStruct *str, uint *d_candidates, unsigned long long int *d_weight) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint destinationOffset = d_candidates[idx];\n",
    "    node destination = d_getNeigh(str, idx, destinationOffset);\n",
    "    if (idx < destination) {\n",
    "        uint sourceOffset = d_candidates[destination];\n",
    "        node destinationNeigh = d_getNeigh(str, destination, sourceOffset);\n",
    "\n",
    "        // The vertex cannot be a candidate anymore because it would create a cycle\n",
    "        if (destinationNeigh == idx) {\n",
    "            d_candidates[idx] = UINT_MAX;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (d_candidates[idx] != UINT_MAX) {\n",
    "        atomicAdd(d_weight, d_getWeight(str, idx, d_candidates[idx]));\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/*****\n",
    "* Helper device function that recursively colors the nodes of the graph\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "* @param i - The index of the node to be colored\n",
    "* @param d_colors - The device-level array of colors assigned to each vertex\n",
    "*****/\n",
    "__device__ uint *d_recursiveColorationHelper (GraphStruct *str, uint *d_candidates, node i, uint *d_colors) {\n",
    "    uint color = UINT_MAX;\n",
    "    if (d_candidates[i] == UINT_MAX) {\n",
    "        color = i;\n",
    "    }\n",
    "    else {\n",
    "        node neigh = d_getNeigh(str, i, d_candidates[i]);\n",
    "        color = d_recursiveColorationHelper(str, d_candidates, neigh, d_colors)[neigh];\n",
    "    }\n",
    "\n",
    "    if (color != UINT_MAX) {\n",
    "        d_colors[i] = color;\n",
    "    }\n",
    "    return d_colors;\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Kernel that recognizes the connected components in the graph and colors them\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree\n",
    "* @param d_colors - The device-level array of colors assigned to each vertex\n",
    "*****/\n",
    "__global__ void colorationProcess(GraphStruct *str, uint *d_candidates, uint *d_colors) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    d_recursiveColorationHelper(str, d_candidates, idx, d_colors);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "//*** SCAN FUNCTIONS ***//\n",
    "\n",
    "__global__ void prescan(uint *g_odata, uint *g_idata, uint *aux, int n, int smemSize)\n",
    "{\n",
    "  extern __shared__ int temp[];// allocated on invocation\n",
    "  int thid = threadIdx.x;\n",
    "  int offset = 1;\n",
    "  int idx = blockIdx.x * blockDim.x + thid;\n",
    "\n",
    "  // load input into shared memory\n",
    "  temp[2 * thid] =  (2 * idx < n) ? g_idata[2 * idx] : 0;\n",
    "  temp[2 * thid + 1] = (2 * idx + 1 < n) ? g_idata[2 * idx + 1] : 0;\n",
    "  //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "      //printf(\"UPSWEEP\\n\");\n",
    "  //}\n",
    "\n",
    "  for (int d = n>>1; d > 0; d >>= 1) // build sum in place up the tree\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        temp[bi] += temp[ai];\n",
    "      }\n",
    "      //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "        //printf(\"temp[idx]: %d\\n\", temp[thid]);\n",
    "      //}\n",
    "    }\n",
    "    offset *= 2;\n",
    "  }\n",
    "\n",
    "  if (thid == 0)\n",
    "  {\n",
    "    aux[blockIdx.x] = temp[smemSize - 1];\n",
    "    temp[smemSize - 1] = 0;\n",
    "  } // clear the last element\n",
    "\n",
    "  //if (2 * idx == n - 1 || 2 * idx + 1 == n - 1) {\n",
    "      //printf(\"DOWNSWEEP\\n\");\n",
    "  //}\n",
    "\n",
    "  for (int d = 1; d < n; d *= 2) // traverse down tree & build scan\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d && offset > 0)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        int t = temp[ai];\n",
    "        temp[ai] = temp[bi];\n",
    "        temp[bi] += t;\n",
    "      }\n",
    "    }\n",
    "    //if (2 * idx == n - 1) {\n",
    "        //printf(\"temp[n - 1]: %d\\n\", temp[2 * thid]);\n",
    "    //}\n",
    "    //if (2 * idx + 1 == n - 1) {\n",
    "        //printf(\"temp[n - 1]: %d\\n\", temp[2 * thid + 1]);\n",
    "    //}\n",
    "    offset >>= 1;\n",
    "  }\n",
    "\n",
    "\n",
    "  __syncthreads();\n",
    "  if (idx <= (n / 2)) {\n",
    "      g_odata[2*idx] = temp[2*thid]; // write results to device memory\n",
    "      g_odata[2*idx+1] = temp[2*thid+1];\n",
    "  }\n",
    "}\n",
    "\n",
    "void cpuScan(uint *array, int start, int end) {\n",
    "    if (end - start <= 1) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    int temp = array[start + 1];\n",
    "    array[start + 1] = array[start];\n",
    "    array[start] = 0;\n",
    "\n",
    "    for (uint i = start + 1; i < end - 1; i++) {\n",
    "        int sum = array[i] + temp;\n",
    "        temp = array[i + 1];\n",
    "        array[i + 1] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void final_sum(uint *g_odata, uint *aux, uint n)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "  if (blockIdx.x == 0 || 2 * idx >= n) {\n",
    "      return;\n",
    "  }\n",
    "\n",
    "  //printf(\"%d: ls - %d  rs - %d  aux - %d\\n\", idx, g_odata[2 * idx], g_odata[2 * idx + 1], aux[blockIdx.x - 1]);\n",
    "\n",
    "  if (2 * idx == n - 1) {\n",
    "      g_odata[2 * idx] += aux[blockIdx.x];\n",
    "      return;\n",
    "  }\n",
    "  g_odata[2 * idx] += aux[blockIdx.x];\n",
    "  g_odata[2 * idx + 1] += aux[blockIdx.x];\n",
    "}\n",
    "\n",
    "//****************//\n",
    "\n",
    "\n",
    "__global__ void cumulatedDegreeUpdateTexture(GraphStruct *str, uint *d_cumDegs, uint *d_colors, uint *d_flag, cudaTextureObject_t ntex) {\n",
    "    // One thread per vertex\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint color = d_colors[idx];\n",
    "    node svSuccessor = d_getRoot(idx, d_flag, d_colors);\n",
    "    uint sum = 0;\n",
    "\n",
    "    uint loopEnd = d_getPosition(str, idx, d_deg(str, idx));\n",
    "    for (uint i = d_getPosition(str, idx, 0); i < loopEnd; ++i) {\n",
    "        node neigh = tex1Dfetch<int>(ntex, i);\n",
    "        uint neighColor = d_colors[neigh];\n",
    "\n",
    "        if (color != neighColor) {\n",
    "            ++sum;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    atomicAdd(&(d_cumDegs[svSuccessor]), sum);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void graphContractionTexture(GraphStruct *str, uint *d_colors, uint *d_flag,\n",
    "                                 uint *d_cumDegs, node *d_newNeighs, uint *d_newWeights,\n",
    "                                 cudaTextureObject_t wtex, cudaTextureObject_t ntex) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint color = d_colors[idx];\n",
    "    node superVertex = d_getRoot(idx, d_flag, d_colors);\n",
    "\n",
    "    uint loopEnd = d_getPosition(str, idx, d_deg(str, idx));\n",
    "    for (uint i = d_getPosition(str, idx, 0); i < loopEnd; i++) {\n",
    "        node neigh = tex1Dfetch<uint>(ntex, i);\n",
    "        uint neighColor = d_colors[neigh];\n",
    "\n",
    "        if (color != neighColor) {\n",
    "            node weight = tex1Dfetch<int>(wtex, i);\n",
    "            uint position = atomicAdd(&(d_cumDegs[superVertex]), 1);\n",
    "            d_newNeighs[position] = d_getRoot(neigh, d_flag, d_colors);\n",
    "            d_newWeights[position] = weight;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main () {\n",
    "    // Generation of a random graph\n",
    "    std::random_device rd;\n",
    "    std::default_random_engine eng(FIXED_SEED);\n",
    "    uint maxWeight = MAX_WEIGHT;\n",
    "    float prob = PROBABILITY;\n",
    "    bool GPUEnabled = 1;\n",
    "    Graph *graphPointer;\n",
    "    if (TESTING) {\n",
    "        string path(TEST);\n",
    "        printf(\"Generating graph from file\\n\");\n",
    "        graphPointer = rgraph(path, true);\n",
    "    }\n",
    "    else {\n",
    "        graphPointer = new Graph(SIZE, GPUEnabled);\n",
    "        graphPointer->randGraph(prob, true, maxWeight, eng);\n",
    "\n",
    "        if (!graphPointer->isConnected()) {\n",
    "            cout << \"The graph is not connected\" << endl;\n",
    "            return -1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    uint iterations = 0;\n",
    "    uint blockDim = BLOCK_SIZE;\n",
    "    uint smemSize = 2 * blockDim;\n",
    "\n",
    "\n",
    "    // Events to measure time\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    float milliseconds;\n",
    "    float spliTime = 0;\n",
    "    float totalTime = 0;\n",
    "    float firstPhase = 0;\n",
    "    float secondPhase = 0;\n",
    "    float thirdPhase = 0;\n",
    "    float fourthPhase = 0;\n",
    "    float fifthPhase = 0;\n",
    "    /******************/\n",
    "\n",
    "\n",
    "    // Variables calculating the MST weight\n",
    "    unsigned long long int mstWeight = 0;\n",
    "    unsigned long long int *d_mstWeight;\n",
    "    CHECK(cudaMalloc((void **)&d_mstWeight, sizeof(unsigned long long int)));\n",
    "    CHECK(cudaMemcpy(d_mstWeight, &mstWeight, sizeof(unsigned long long int), cudaMemcpyHostToDevice));\n",
    "    /******************************************************************************/\n",
    "\n",
    "\n",
    "    // Main block of the algorithm\n",
    "    while (graphPointer->getStruct()->nodeSize > 1) {\n",
    "        // Initialization of the variables associated with the graph\n",
    "        GraphStruct *str = graphPointer->getStruct();\n",
    "        uint size = str->nodeSize;\n",
    "        uint edgeSize = str->edgeSize;\n",
    "        cout << \"Processing a graph of size: \" << size << \" with \" << edgeSize << \" edges.\\n\\n\";\n",
    "\n",
    "        if (DEBUGGING && size < 15 && str->edgeSize < 100) {\n",
    "            graphPointer->print(true);\n",
    "            print_d<<<1, 1>>>(str, 1);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "        }\n",
    "        /******************************/\n",
    "\n",
    "        uint gridDim = (size + blockDim - 1) / blockDim;\n",
    "        uint searchGrid = (edgeSize + blockDim - 1) / blockDim;\n",
    "\n",
    "        // create texture object\n",
    "        cudaResourceDesc weightsDesc;\n",
    "        memset(&weightsDesc, 0, sizeof(weightsDesc));\n",
    "        weightsDesc.resType = cudaResourceTypeLinear;\n",
    "        weightsDesc.res.linear.devPtr = str->weights;\n",
    "        weightsDesc.res.linear.desc.f = cudaChannelFormatKindSigned;\n",
    "        weightsDesc.res.linear.desc.x = 32; // bits per channel\n",
    "        weightsDesc.res.linear.sizeInBytes = edgeSize * sizeof(uint);\n",
    "\n",
    "        cudaResourceDesc neighDesc;\n",
    "        memset(&neighDesc, 0, sizeof(neighDesc));\n",
    "        neighDesc.resType = cudaResourceTypeLinear;\n",
    "        neighDesc.res.linear.devPtr = str->neighs;\n",
    "        neighDesc.res.linear.desc.f = cudaChannelFormatKindUnsigned;\n",
    "        neighDesc.res.linear.desc.x = 32; // bits per channel\n",
    "        neighDesc.res.linear.sizeInBytes = edgeSize * sizeof(uint);\n",
    "\n",
    "        cudaTextureDesc weightsTexDesc, neighTexDesc;\n",
    "        memset(&weightsTexDesc, 0, sizeof(weightsTexDesc));\n",
    "        memset(&neighTexDesc, 0, sizeof(neighTexDesc));\n",
    "        weightsTexDesc.readMode = cudaReadModeElementType;\n",
    "        neighTexDesc.readMode = cudaReadModeElementType;\n",
    "\n",
    "        // create texture object: we only have to do this once!\n",
    "        cudaTextureObject_t weightsTex, neighsTex;\n",
    "        cudaCreateTextureObject(&weightsTex, &weightsDesc, &weightsTexDesc, NULL);\n",
    "        cudaCreateTextureObject(&neighsTex, &neighDesc, &neighTexDesc, NULL);\n",
    "\n",
    "        uint *candidates, *d_candidates;\n",
    "        candidates = new uint[size];\n",
    "        CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
    "\n",
    "        cout << \"Launching kernel FIND CHEAPEST TEXTURE -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        findCheapestTexture <<<gridDim, blockDim>>> (str, d_candidates, weightsTex, neighsTex);\n",
    "        cudaEventRecord(stop);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", spliTime);\n",
    "\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        printf(\"The procedure took in total %.5f seconds\\n\\n\", spliTime);\n",
    "\n",
    "        totalTime += spliTime;\n",
    "        firstPhase += spliTime;\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            for (node i = 0; i < size; i++) {\n",
    "                int min =  INT_MAX;\n",
    "                uint mindex = 0;\n",
    "                for (uint j = 0; j < str->deg(i); j++) {\n",
    "                    if (str->getWeight(i, j) < min) {\n",
    "                        mindex = j;\n",
    "                        min = str->getWeight(i, j);\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if (str->getWeight(i, mindex) < str->getWeight(i, candidates[i])) {\n",
    "                    printf(\"The GPU sequence is picking worse weights %d   CPU: %d(%d)    GPU: %d(%d)\\n\", i, mindex, str->getWeight(i, mindex), candidates[i], str->getWeight(i, candidates[i]));\n",
    "                    return -1;\n",
    "                }\n",
    "\n",
    "                //printf(\"%d >> CPU: %d    GPU: %d\\n\", i, mindex, candidates[i]);\n",
    "                //printf(\"%d >> CPU: %d(%d)   GPU: %d(%d)\\n\", i, str->getNeigh(i, mindex), str->getWeight(i, mindex), str->getNeigh(i, candidates[i]), str->getWeight(i, candidates[i]));\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // ~Debugging~ print the cheapest edge for every vertex\n",
    "        if (DEBUGGING && size < 15) {\n",
    "            cout << \"The cheapest edge for every vertex\" << endl;\n",
    "            CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"node (\" << i << \") -> \" << str->getNeigh(i, candidates[i]) << \"(\"\n",
    "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
    "            }\n",
    "            cout << \"\\n\\n\\n\";\n",
    "        }\n",
    "        /*******************/\n",
    "\n",
    "\n",
    "\n",
    "        // Second step of the algorithm\n",
    "        cout << \"Launching kernel MIRRORED EDGES REMOVAL -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        mirroredEdgesRemoval<<<gridDim, blockDim>>>(str, d_candidates, d_mstWeight);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        CHECK(cudaMemcpy(&mstWeight, d_mstWeight, sizeof(int), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "        secondPhase += spliTime;\n",
    "        /********************/\n",
    "\n",
    "        // ~Debugging~ print the cheapest edge for every vertex update\n",
    "        if (DEBUGGING && size < 15) {\n",
    "            cout << \"Update of the cheapest edge for every vertex\" << endl;\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"node (\" << i << \") -> \";\n",
    "                if (candidates[i] != UINT_MAX) {\n",
    "                    cout << str->getNeigh(i, candidates[i]) << \"(\"\n",
    "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
    "                }\n",
    "                else {\n",
    "                    cout << \"NULL\" << endl;\n",
    "                }\n",
    "            }\n",
    "            printf (\"%llu\\n\", mstWeight);\n",
    "        }\n",
    "        /*****************************/\n",
    "\n",
    "        cout << \"The MST weight at the end of iteration \" << iterations + 1 << \" is: \" << mstWeight << endl;\n",
    "\n",
    "\n",
    "        // Third step of the algorithm\n",
    "        cout << \"Launching kernel COLORATION PROCESS -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "\n",
    "        // Initialize the color array\n",
    "        uint *colors = new uint[size];\n",
    "        uint *d_colors;\n",
    "        CHECK(cudaMalloc((void**)&d_colors, size * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_colors, UINT_MAX, size * sizeof(uint)));\n",
    "        /**************************************************/\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        colorationProcess<<<gridDim, blockDim>>>(str, d_candidates, d_colors);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(colors, d_colors, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "        thirdPhase += spliTime;\n",
    "\n",
    "        // Print the coloring\n",
    "        if (DEBUGGING) {\n",
    "            uint *checkColoring = new uint[size];\n",
    "\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                checkColoring[i] = 0;\n",
    "            }\n",
    "\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                checkColoring[colors[i]]++;\n",
    "            }\n",
    "\n",
    "            uint nonZeroColors = 0;\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                if (checkColoring[i] != 0) {\n",
    "                    nonZeroColors++;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            cout << \"There is a total of \" << nonZeroColors << \" colors\" << endl;\n",
    "\n",
    "            cout << \"\\n\\n\\n\";\n",
    "        }\n",
    "        /*******************/\n",
    "\n",
    "        /**\n",
    "         * If the coloring coming out of the last kernel contains only one color\n",
    "         * then it means that the edge added in the last step was the one needed\n",
    "         * to merge the partial trees\n",
    "         **/\n",
    "        uint color = colors[0];\n",
    "        bool uniqueColor = true;\n",
    "        for (uint i = 1; i < size; i++) {\n",
    "            if (colors[i] != color) {\n",
    "                uniqueColor = false;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "        if (uniqueColor) {\n",
    "            cout << \"THE CALCULATION OF THE MST IS COMPLETE\\n\";\n",
    "            cout << \"THE MST WEIGHT IS: \" << mstWeight << endl;\n",
    "            printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
    "            printf(\"The time distribution is the following:\\n\\tFirst phase: %.5f\\n\\tSecond phase: %.5f\\n\\tThird phase: %.5f\\n\\tFourth phase: %.5f\\n\\tFifth phase: %.5f\\n\", firstPhase, secondPhase, thirdPhase, fourthPhase, fifthPhase);\n",
    "\n",
    "            // Cuda memory deallocation\n",
    "            CHECK(cudaEventDestroy(start));\n",
    "            CHECK(cudaEventDestroy(stop));\n",
    "            CHECK(cudaFree(d_candidates));\n",
    "            CHECK(cudaFree(d_colors));\n",
    "\n",
    "            // Host memory deallocation\n",
    "            delete[] candidates;\n",
    "            delete[] colors;\n",
    "\n",
    "            string path(LOGPATH + string(\"gpuT\"));\n",
    "\n",
    "            ofstream logfile(path);\n",
    "\n",
    "            if (logfile.is_open()){\n",
    "                logfile << TEST << \"\\n\" << mstWeight << \"\\n\" << totalTime;\n",
    "                logfile.close();\n",
    "            }\n",
    "            else {\n",
    "                cout << \"Unable to open file\";\n",
    "            }\n",
    "\n",
    "            // Cuda event destruction\n",
    "            CHECK(cudaEventDestroy(start));\n",
    "            CHECK(cudaEventDestroy(stop));\n",
    "\n",
    "            return 0;\n",
    "        }\n",
    "        /***********/\n",
    "\n",
    "\n",
    "\n",
    "        // Fourth step of the algorithm\n",
    "        cout << \"Doing a round of scan on the flag vector, size: \" << size << endl;\n",
    "        uint *flag = new uint[size];\n",
    "        uint *cFlag = new uint[size];\n",
    "        for (uint i = 0; i < size; i++) {\n",
    "            flag[i] = (colors[i] == i) ? 1 : 0;\n",
    "            cFlag[i] = flag[i];\n",
    "        }\n",
    "        uint *d_flag;\n",
    "\n",
    "        CHECK(cudaMalloc((void**)&d_flag, (size) * sizeof(uint)));\n",
    "\n",
    "        if (size < smemSize) {\n",
    "            cout << \"Resorting to a round of CPU scan\" << endl;\n",
    "            cudaEventRecord(start);\n",
    "            cpuScan(flag, 0, size);\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            float milliseconds;\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime = milliseconds / 1000.0;\n",
    "            printf(\"Time required for a round of CPU scan on the flag array:   %.5f (sec)\\n\", spliTime);\n",
    "            totalTime += spliTime;\n",
    "            fourthPhase += spliTime;\n",
    "            CHECK(cudaMemcpy(d_flag, flag, (size) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "        }\n",
    "        else {\n",
    "            uint *d_aux, *aux, *d_ogFlag;\n",
    "\n",
    "            uint numSmemBlock = (size + smemSize - 1) / smemSize;\n",
    "            uint numBlock = (size + blockDim - 1) / blockDim;\n",
    "\n",
    "            aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
    "\n",
    "            CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
    "            CHECK(cudaMalloc((void **) &d_ogFlag, size * sizeof(uint)));\n",
    "\n",
    "            CHECK(cudaMemcpy(d_ogFlag, flag, (size) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "            CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
    "            CHECK(cudaMemset(d_flag, 0, (size) * sizeof(uint)));\n",
    "\n",
    "            // Copy the contents of gpuArray in the Device memory\n",
    "            CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
    "            CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
    "\n",
    "            printf(\"\\n  block scan...\\n\");\n",
    "\n",
    "            size_t smem = smemSize * sizeof(uint);\n",
    "            printf(\"\\n  prescan procedure on: %d elements...\\n\", size);\n",
    "            cudaEventRecord(start);\n",
    "            prescan<<<  numSmemBlock, blockDim, smem >>>(d_flag, d_ogFlag, d_aux, size, smemSize);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime = milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "            CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "            printf(\"\\n  CPU scan procedure of the aux array: %d elements...\\n\", numSmemBlock + 1);\n",
    "            cudaEventRecord(start);\n",
    "            cpuScan(aux, 0, numSmemBlock + 1);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime += milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "            CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "            printf(\"\\n  final summation procedure...\\n\");\n",
    "            cudaEventRecord(start);\n",
    "            final_sum<<< numBlock, blockDim >>>(d_flag, d_aux, size);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime += milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
    "            printf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", spliTime);\n",
    "\n",
    "            totalTime += spliTime;\n",
    "            fourthPhase += spliTime;\n",
    "            CHECK(cudaMemcpy(flag, d_flag, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "            free(aux);\n",
    "            CHECK(cudaFree(d_aux));\n",
    "            CHECK(cudaFree(d_ogFlag));\n",
    "        }\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            for (uint i = 1; i < size; i++) {\n",
    "                cFlag[i] += cFlag[i - 1];\n",
    "            }\n",
    "\n",
    "            for (uint i = 0; i < size - 1; i++) {\n",
    "                if (cFlag[i] != flag[i + 1]) {\n",
    "                    cout << \"I due array sono diversi in posizione \" << i << endl;\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        delete[] cFlag;\n",
    "        cout << \"The contracted graph will contain \" << flag[size - 1] << \" supervertices\\n\\n\" << endl;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Fifth step of the algorithm\n",
    "\n",
    "        // Allocating resources for the new cumulated degrees array\n",
    "        uint newNodeSize = flag[size - 1];\n",
    "        uint cumDegSize = newNodeSize + 1;\n",
    "        uint *cumDegs = new uint[cumDegSize];\n",
    "        uint *d_cumDegs;\n",
    "        CHECK(cudaMalloc((void**)&d_cumDegs, (cumDegSize) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
    "        /***********************************/\n",
    "\n",
    "        cout << \"Launching kernel CUMULATED DEGREE UPDATE -- (\" << blockDim << \", 1, 1) -- (\" << searchGrid << \", 1, 1)\" << endl;\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        cumulatedDegreeUpdateTexture <<< gridDim, blockDim >>> (str, d_cumDegs, d_colors, d_flag, neighsTex);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Doing the computation of the cumulated degrees took: %.5f seconds\\n\\n\", spliTime);\n",
    "        CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Perform another prefix sum on the cumDegrees array\n",
    "        cout << \"Doing a round of scan on the cumDegs vector, size: \" << cumDegSize << endl;\n",
    "\n",
    "        uint *cCumDegs = new uint[cumDegSize];\n",
    "        for (uint i = 0; i < cumDegSize; i++) {\n",
    "            cCumDegs[i] = cumDegs[i];\n",
    "        }\n",
    "\n",
    "        if (cumDegSize < smemSize) {\n",
    "            cout << \"Resorting to a round of CPU scan\" << endl;\n",
    "            cpuScan(cumDegs, 0, cumDegSize);\n",
    "            CHECK(cudaMemcpy(d_cumDegs, cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "        }\n",
    "        else {\n",
    "            uint *d_aux, *aux, *d_ogCumDegs;\n",
    "\n",
    "            uint numSmemBlock = (cumDegSize + smemSize - 1) / smemSize;\n",
    "            uint numBlock = (cumDegSize + blockDim - 1) / blockDim;\n",
    "            uint gpuScanSize = numSmemBlock * smemSize;\n",
    "            uint residualSize = cumDegSize - gpuScanSize;\n",
    "\n",
    "            aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
    "\n",
    "            CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
    "            CHECK(cudaMalloc((void **) &d_ogCumDegs, cumDegSize * sizeof(uint)));\n",
    "\n",
    "            CHECK(cudaMemcpy(d_ogCumDegs, cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "            CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
    "            CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
    "\n",
    "            printf(\"\\n  block scan...\\n\");\n",
    "\n",
    "            uint smem = smemSize * sizeof(uint);\n",
    "            printf(\"\\n  first prescan procedure on the Device: %d elements...\\n\", cumDegSize);\n",
    "            cudaEventRecord(start);\n",
    "            prescan<<<  numSmemBlock, blockDim, smem >>>(d_cumDegs, d_ogCumDegs, d_aux, cumDegSize, smemSize);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            float milliseconds;\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime = milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "            // Copy the contents of the aux array into Host memory and perform another scan\n",
    "            printf(\"\\n  CPU scan procedure of the aux array: %d elements...\\n\", numSmemBlock);\n",
    "            CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "            cudaEventRecord(start);\n",
    "            cpuScan(aux, 0, numSmemBlock + 1);\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime += milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
    "\n",
    "            // Copy the portions of the array computed on the Host to Device memory\n",
    "            CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "            printf(\"\\n  final summation procedure...\\n\");\n",
    "            cudaEventRecord(start);\n",
    "            final_sum<<< numBlock, blockDim >>>(d_cumDegs, d_aux, cumDegSize);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "            CHECK(cudaEventRecord(stop));\n",
    "            CHECK(cudaEventSynchronize(stop));\n",
    "            CHECK(cudaGetLastError());\n",
    "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "            spliTime += milliseconds / 1000.0;\n",
    "            printf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
    "\n",
    "            printf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", spliTime);\n",
    "\n",
    "            totalTime += spliTime;\n",
    "            CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "            free(aux);\n",
    "            CHECK(cudaFree(d_aux));\n",
    "            CHECK(cudaFree(d_ogCumDegs));\n",
    "        }\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            for (uint i = 1; i < cumDegSize; i++) {\n",
    "                cCumDegs[i] += cCumDegs[i - 1];\n",
    "            }\n",
    "\n",
    "            for (uint i = 0; i < cumDegSize - 1; i++) {\n",
    "                if (cCumDegs[i] != cumDegs[i + 1]) {\n",
    "                    cout << \"I due array sono diversi in posizione \" << i << endl;\n",
    "                    cout << cCumDegs[i] << \"   \" << cumDegs[i + 1];\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        cout << \"The contracted graph will contain \" << cumDegs[cumDegSize - 1] << \" edges\" << endl;\n",
    "        cout << \"The old graph structure contained \" << str->edgeSize << \" edges\\n\\n\" << endl;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Allocating space for the arrays in the newly contracted graph\n",
    "        uint newEdgeSize = cumDegs[cumDegSize - 1];\n",
    "        node *newNeighs = new node[newEdgeSize];\n",
    "        uint *newWeights = new uint[newEdgeSize];\n",
    "\n",
    "        uint *d_newNeighs, *d_newWeights;\n",
    "        CHECK(cudaMalloc((void **)&d_newNeighs, newEdgeSize * sizeof(node)));\n",
    "        CHECK(cudaMalloc((void **)&d_newWeights, newEdgeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_newNeighs, 0, newEdgeSize * sizeof(node)));\n",
    "        CHECK(cudaMemset(d_newWeights, 0, newEdgeSize * sizeof(uint)));\n",
    "\n",
    "        cout << \"Launching kernel GRAPH CONSTRUCTION -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        graphContractionTexture <<<gridDim, blockDim>>> (str, d_colors, d_flag, d_cumDegs, d_newNeighs, d_newWeights,  weightsTex, neighsTex);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        printf(\"The construction of the new neighbour and weight arrays took: %.5f seconds\\n\\n\", milliseconds/1000);\n",
    "        spliTime += milliseconds / 1000.0;\n",
    "        CHECK(cudaMemcpy(newNeighs, d_newNeighs, newEdgeSize * sizeof(node), cudaMemcpyDeviceToHost));\n",
    "        CHECK(cudaMemcpy(newWeights, d_newWeights, newEdgeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "\n",
    "\n",
    "        // Reconstructing the graph\n",
    "        graphPointer->copyConstructor(newNodeSize, newEdgeSize, newNeighs, newWeights, cumDegs);\n",
    "\n",
    "        //graphPointer->print(true);\n",
    "\n",
    "        printf(\"----------------------------------\\n\\n\");\n",
    "        /***********************************************/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Updating the iteration information\n",
    "        totalTime += spliTime;\n",
    "        fifthPhase += spliTime;\n",
    "        iterations++;\n",
    "        /*****************************************/\n",
    "\n",
    "\n",
    "        // Cuda memory deallocation\n",
    "        CHECK(cudaFree(d_candidates));\n",
    "        CHECK(cudaFree(d_colors));\n",
    "        CHECK(cudaFree(d_flag));\n",
    "        CHECK(cudaFree(d_cumDegs));\n",
    "        CHECK(cudaFree(d_newNeighs));\n",
    "        CHECK(cudaFree(d_newWeights));\n",
    "        /****************************/\n",
    "\n",
    "        // Host memory deallocation\n",
    "        delete[] candidates;\n",
    "        delete[] colors;\n",
    "        delete[] flag;\n",
    "        delete[] cumDegs;\n",
    "        delete[] newNeighs;\n",
    "        delete[] newWeights;\n",
    "        /******************/\n",
    "    }\n",
    "\n",
    "    printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
    "    printf(\"The calculation of the MST took %d iterations\\n\\n\", iterations);\n",
    "    printf(\"The total weight of the tree is %llu\\n\", mstWeight);\n",
    "\n",
    "\n",
    "    CHECK(cudaEventDestroy(start));\n",
    "    CHECK(cudaEventDestroy(stop));\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpAFfMIsJtvQ",
    "outputId": "11764b5d-afbc-4afe-91f9-55336c7e8a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01m\u001b[0m\u001b[01msrc/GPU/mstGPUETex.cu(851)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"residualSize\"\u001b[0m was declared but never referenced\n",
      "              uint residualSize = cumDegSize - gpuScanSize;\n",
      "                   ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "ptxas warning : Stack size for entry function '_Z17colorationProcessP11GraphStructPjS1_' cannot be statically determined\n",
      "Generating graph from file\n",
      "1070376\t2712798\n",
      "Closing the file and freeing memory\n",
      "Processing a graph of size: 1070376 with 2712798 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (1046, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00704 seconds\n",
      "\n",
      "The procedure took in total 0.00704 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1046, 1, 1)\n",
      "Removing the mirrored edges required: 0.00119 seconds\n",
      "\n",
      "The MST weight at the end of iteration 1 is: 1041112695\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1046, 1, 1)\n",
      "Removing the mirrored edges required: 0.00121 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 1070376\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  prescan procedure on: 1070376 elements...\n",
      "   elapsed time:   0.00044 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 524 elements...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00007 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00052 (sec)\n",
      "The contracted graph will contain 316322 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (2650, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00028 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 316323\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  first prescan procedure on the Device: 316323 elements...\n",
      "   elapsed time:   0.00012 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 155 elements...\n",
      "   elapsed time:   0.00000 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00003 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00015 (sec)\n",
      "The contracted graph will contain 1165914 edges\n",
      "The old graph structure contained 2712798 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1046, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00065 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 316322 with 1165914 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (309, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00315 seconds\n",
      "\n",
      "The procedure took in total 0.00315 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (309, 1, 1)\n",
      "Removing the mirrored edges required: 0.00037 seconds\n",
      "\n",
      "The MST weight at the end of iteration 2 is: 1518063446\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (309, 1, 1)\n",
      "Removing the mirrored edges required: 0.00040 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 316322\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  prescan procedure on: 316322 elements...\n",
      "   elapsed time:   0.00013 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 156 elements...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00003 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00016 (sec)\n",
      "The contracted graph will contain 90984 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1139, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00011 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 90985\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  first prescan procedure on the Device: 90985 elements...\n",
      "   elapsed time:   0.00006 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 45 elements...\n",
      "   elapsed time:   0.00000 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00002 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00008 (sec)\n",
      "The contracted graph will contain 573228 edges\n",
      "The old graph structure contained 1165914 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (309, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00042 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 90984 with 573228 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (89, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00147 seconds\n",
      "\n",
      "The procedure took in total 0.00147 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (89, 1, 1)\n",
      "Removing the mirrored edges required: 0.00013 seconds\n",
      "\n",
      "The MST weight at the end of iteration 3 is: 1710606056\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (89, 1, 1)\n",
      "Removing the mirrored edges required: 0.00015 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 90984\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  prescan procedure on: 90984 elements...\n",
      "   elapsed time:   0.00006 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 46 elements...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00002 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00008 (sec)\n",
      "The contracted graph will contain 24624 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (560, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00006 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 24625\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  first prescan procedure on the Device: 24625 elements...\n",
      "   elapsed time:   0.00003 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 13 elements...\n",
      "   elapsed time:   0.00000 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00005 (sec)\n",
      "The contracted graph will contain 261344 edges\n",
      "The old graph structure contained 573228 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (89, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00028 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 24624 with 261344 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (25, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00079 seconds\n",
      "\n",
      "The procedure took in total 0.00079 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (25, 1, 1)\n",
      "Removing the mirrored edges required: 0.00005 seconds\n",
      "\n",
      "The MST weight at the end of iteration 4 is: 1777355667\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (25, 1, 1)\n",
      "Removing the mirrored edges required: 0.00005 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 24624\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  prescan procedure on: 24624 elements...\n",
      "   elapsed time:   0.00003 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 14 elements...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00005 (sec)\n",
      "The contracted graph will contain 6258 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (256, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00005 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 6259\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  first prescan procedure on the Device: 6259 elements...\n",
      "   elapsed time:   0.00003 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 4 elements...\n",
      "   elapsed time:   0.00000 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00004 (sec)\n",
      "The contracted graph will contain 106290 edges\n",
      "The old graph structure contained 261344 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (25, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00026 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 6258 with 106290 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (7, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00051 seconds\n",
      "\n",
      "The procedure took in total 0.00051 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (7, 1, 1)\n",
      "Removing the mirrored edges required: 0.00003 seconds\n",
      "\n",
      "The MST weight at the end of iteration 5 is: 1798542635\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (7, 1, 1)\n",
      "Removing the mirrored edges required: 0.00004 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 6258\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  prescan procedure on: 6258 elements...\n",
      "   elapsed time:   0.00003 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 5 elements...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.00005 (sec)\n",
      "The contracted graph will contain 1474 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (104, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00006 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 1475\n",
      "Resorting to a round of CPU scan\n",
      "The contracted graph will contain 39736 edges\n",
      "The old graph structure contained 106290 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (7, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00028 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 1474 with 39736 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (2, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00044 seconds\n",
      "\n",
      "The procedure took in total 0.00044 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (2, 1, 1)\n",
      "Removing the mirrored edges required: 0.00003 seconds\n",
      "\n",
      "The MST weight at the end of iteration 6 is: 1804583482\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (2, 1, 1)\n",
      "Removing the mirrored edges required: 0.00004 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 1474\n",
      "Resorting to a round of CPU scan\n",
      "Time required for a round of CPU scan on the flag array:   0.00001 (sec)\n",
      "The contracted graph will contain 327 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (39, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00007 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 328\n",
      "Resorting to a round of CPU scan\n",
      "The contracted graph will contain 13052 edges\n",
      "The old graph structure contained 39736 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (2, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00035 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 327 with 13052 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00163 seconds\n",
      "\n",
      "The procedure took in total 0.00163 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 7 is: 1806066168\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 327\n",
      "Resorting to a round of CPU scan\n",
      "Time required for a round of CPU scan on the flag array:   0.00000 (sec)\n",
      "The contracted graph will contain 83 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (13, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00005 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 84\n",
      "Resorting to a round of CPU scan\n",
      "The contracted graph will contain 4106 edges\n",
      "The old graph structure contained 13052 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00024 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 83 with 4106 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00023 seconds\n",
      "\n",
      "The procedure took in total 0.00023 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 8 is: 1806644192\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 83\n",
      "Resorting to a round of CPU scan\n",
      "Time required for a round of CPU scan on the flag array:   0.00000 (sec)\n",
      "The contracted graph will contain 19 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (5, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00005 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 20\n",
      "Resorting to a round of CPU scan\n",
      "The contracted graph will contain 1268 edges\n",
      "The old graph structure contained 4106 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00019 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 19 with 1268 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00018 seconds\n",
      "\n",
      "The procedure took in total 0.00018 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 9 is: 1806743748\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 19\n",
      "Resorting to a round of CPU scan\n",
      "Time required for a round of CPU scan on the flag array:   0.00000 (sec)\n",
      "The contracted graph will contain 7 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (2, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00003 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 8\n",
      "Resorting to a round of CPU scan\n",
      "The contracted graph will contain 544 edges\n",
      "The old graph structure contained 1268 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1, 1, 1)\n",
      "The construction of the new neighbour and weight arrays took: 0.00017 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 7 with 544 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00017 seconds\n",
      "\n",
      "The procedure took in total 0.00017 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 10 is: 1806814846\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00003 seconds\n",
      "\n",
      "THE CALCULATION OF THE MST IS COMPLETE\n",
      "THE MST WEIGHT IS: 1806814846\n",
      "Total elapsed time: 0.02409 seconds\n",
      "\n",
      "The time distribution is the following:\n",
      "\tFirst phase: 0.01561\n",
      "\tSecond phase: 0.00187\n",
      "\tThird phase: 0.00197\n",
      "\tFourth phase: 0.00088\n",
      "\tFifth phase: 0.00344\n"
     ]
    }
   ],
   "source": [
    "# Compilazione ed esecuzione\n",
    "# GPU-t\n",
    "!nvcc -arch=sm_75 GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/COMMON/readGraph.cu src/GPU/mstGPUETex.cu -o mstGPUETex\n",
    "!./mstGPUETex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0TlIxcfCcwDp",
    "outputId": "89294c68-96b9-48b5-8cb4-4e8ab03b7fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "==PROF== Profiling \"cumulatedDegreeUpdateTexture\" - 32: 0%....50%....100% - 9 passes\n",
      "Doing the computation of the cumulated degrees took: 0.22664 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 20194\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  first prescan procedure on the Device: 20194 elements...\n",
      "==PROF== Profiling \"prescan\" - 33: 0%....50%....100% - 9 passes\n",
      "   elapsed time:   0.26866 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 10 elements...\n",
      "   elapsed time:   0.00000 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "==PROF== Profiling \"final_sum\" - 34: 0%....50%....100% - 9 passes\n",
      "   elapsed time:   0.29211 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.56077 (sec)\n",
      "The contracted graph will contain 337714 edges\n",
      "The old graph structure contained 780550 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (80, 1, 1)\n",
      "==PROF== Profiling \"graphContractionTexture\" - 35: 0%....50%....100% - 9 passes\n",
      "The construction of the new neighbour and weight arrays took: 0.28058 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 20193 with 337714 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (20, 1, 1)\n",
      "==PROF== Profiling \"findCheapestTexture\" - 36: 0%....50%....100% - 9 passes\n",
      "Finding the cheapest edge for every vertex took: 0.30346 seconds\n",
      "\n",
      "The procedure took in total 0.30346 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (20, 1, 1)\n",
      "==PROF== Profiling \"mirroredEdgesRemoval\" - 37: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.27525 seconds\n",
      "\n",
      "The MST weight at the end of iteration 5 is: 2169556313\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (20, 1, 1)\n",
      "==PROF== Profiling \"colorationProcess\" - 38: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.22945 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 20193\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  prescan procedure on: 20193 elements...\n",
      "==PROF== Profiling \"prescan\" - 39: 0%....50%....100% - 9 passes\n",
      "   elapsed time:   0.25185 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 11 elements...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "==PROF== Profiling \"final_sum\" - 40: 0%....50%....100% - 9 passes\n",
      "   elapsed time:   0.26116 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.51302 (sec)\n",
      "The contracted graph will contain 4695 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (330, 1, 1)\n",
      "==PROF== Profiling \"cumulatedDegreeUpdateTexture\" - 41: 0%....50%....100% - 9 passes\n",
      "Doing the computation of the cumulated degrees took: 0.28286 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 4696\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  first prescan procedure on the Device: 4696 elements...\n",
      "==PROF== Profiling \"prescan\" - 42: 0%....50%....100% - 9 passes\n",
      "   elapsed time:   0.20197 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 3 elements...\n",
      "   elapsed time:   0.00000 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "==PROF== Profiling \"final_sum\" - 43: 0%....50%....100% - 9 passes\n",
      "   elapsed time:   0.22938 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.43135 (sec)\n",
      "The contracted graph will contain 140182 edges\n",
      "The old graph structure contained 337714 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (20, 1, 1)\n",
      "==PROF== Profiling \"graphContractionTexture\" - 44: 0%....50%....100% - 9 passes\n",
      "The construction of the new neighbour and weight arrays took: 0.21480 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 4695 with 140182 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (5, 1, 1)\n",
      "==PROF== Profiling \"findCheapestTexture\" - 45: 0%....50%....100% - 9 passes\n",
      "Finding the cheapest edge for every vertex took: 0.19566 seconds\n",
      "\n",
      "The procedure took in total 0.19566 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (5, 1, 1)\n",
      "==PROF== Profiling \"mirroredEdgesRemoval\" - 46: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.14048 seconds\n",
      "\n",
      "The MST weight at the end of iteration 6 is: 2190134279\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (5, 1, 1)\n",
      "==PROF== Profiling \"colorationProcess\" - 47: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.13522 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 4695\n",
      "\n",
      "  block scan...\n",
      "\n",
      "  prescan procedure on: 4695 elements...\n",
      "==PROF== Profiling \"prescan\" - 48: 0%....50%....100% - 9 passes\n",
      "   elapsed time:   0.13845 (sec)\n",
      "\n",
      "  CPU scan procedure of the aux array: 4 elements...\n",
      "   elapsed time:   0.00001 (sec)\n",
      "\n",
      "  final summation procedure...\n",
      "==PROF== Profiling \"final_sum\" - 49: 0%....50%....100% - 9 passes\n",
      "   elapsed time:   0.13668 (sec)\n",
      "\n",
      "\n",
      "Total elapsed time:   0.27514 (sec)\n",
      "The contracted graph will contain 1070 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (137, 1, 1)\n",
      "==PROF== Profiling \"cumulatedDegreeUpdateTexture\" - 50: 0%....50%....100% - 9 passes\n",
      "Doing the computation of the cumulated degrees took: 0.14015 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 1071\n",
      "Resorting to a round of CPU scan\n",
      "The contracted graph will contain 57826 edges\n",
      "The old graph structure contained 140182 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (5, 1, 1)\n",
      "==PROF== Profiling \"graphContractionTexture\" - 51: 0%....50%....100% - 9 passes\n",
      "The construction of the new neighbour and weight arrays took: 0.13963 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 1070 with 57826 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (2, 1, 1)\n",
      "==PROF== Profiling \"findCheapestTexture\" - 52: 0%....50%....100% - 9 passes\n",
      "Finding the cheapest edge for every vertex took: 0.13651 seconds\n",
      "\n",
      "The procedure took in total 0.13651 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (2, 1, 1)\n",
      "==PROF== Profiling \"mirroredEdgesRemoval\" - 53: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.14146 seconds\n",
      "\n",
      "The MST weight at the end of iteration 7 is: 2195567673\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (2, 1, 1)\n",
      "==PROF== Profiling \"colorationProcess\" - 54: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.13592 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 1070\n",
      "Resorting to a round of CPU scan\n",
      "Time required for a round of CPU scan on the flag array:   0.00001 (sec)\n",
      "The contracted graph will contain 226 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (57, 1, 1)\n",
      "==PROF== Profiling \"cumulatedDegreeUpdateTexture\" - 55: 0%....50%....100% - 9 passes\n",
      "Doing the computation of the cumulated degrees took: 0.13944 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 227\n",
      "Resorting to a round of CPU scan\n",
      "The contracted graph will contain 23814 edges\n",
      "The old graph structure contained 57826 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (2, 1, 1)\n",
      "==PROF== Profiling \"graphContractionTexture\" - 56: 0%....50%....100% - 9 passes\n",
      "The construction of the new neighbour and weight arrays took: 0.13947 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 226 with 23814 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"findCheapestTexture\" - 57: 0%....50%....100% - 9 passes\n",
      "Finding the cheapest edge for every vertex took: 0.15846 seconds\n",
      "\n",
      "The procedure took in total 0.15846 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"mirroredEdgesRemoval\" - 58: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.15725 seconds\n",
      "\n",
      "The MST weight at the end of iteration 8 is: 2196833767\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"colorationProcess\" - 59: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.13868 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 226\n",
      "Resorting to a round of CPU scan\n",
      "Time required for a round of CPU scan on the flag array:   0.00001 (sec)\n",
      "The contracted graph will contain 42 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (24, 1, 1)\n",
      "==PROF== Profiling \"cumulatedDegreeUpdateTexture\" - 60: 0%....50%....100% - 9 passes\n",
      "Doing the computation of the cumulated degrees took: 0.15199 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 43\n",
      "Resorting to a round of CPU scan\n",
      "The contracted graph will contain 7840 edges\n",
      "The old graph structure contained 23814 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"graphContractionTexture\" - 61: 0%....50%....100% - 9 passes\n",
      "The construction of the new neighbour and weight arrays took: 0.14307 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 42 with 7840 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"findCheapestTexture\" - 62: 0%....50%....100% - 9 passes\n",
      "Finding the cheapest edge for every vertex took: 0.13513 seconds\n",
      "\n",
      "The procedure took in total 0.13513 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"mirroredEdgesRemoval\" - 63: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.13227 seconds\n",
      "\n",
      "The MST weight at the end of iteration 9 is: 2197088435\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"colorationProcess\" - 64: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.13748 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 42\n",
      "Resorting to a round of CPU scan\n",
      "Time required for a round of CPU scan on the flag array:   0.00001 (sec)\n",
      "The contracted graph will contain 9 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (8, 1, 1)\n",
      "==PROF== Profiling \"cumulatedDegreeUpdateTexture\" - 65: 0%....50%....100% - 9 passes\n",
      "Doing the computation of the cumulated degrees took: 0.14243 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 10\n",
      "Resorting to a round of CPU scan\n",
      "The contracted graph will contain 3054 edges\n",
      "The old graph structure contained 7840 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"graphContractionTexture\" - 66: 0%....50%....100% - 9 passes\n",
      "The construction of the new neighbour and weight arrays took: 0.13764 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 9 with 3054 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"findCheapestTexture\" - 67: 0%....50%....100% - 9 passes\n",
      "Finding the cheapest edge for every vertex took: 0.14196 seconds\n",
      "\n",
      "The procedure took in total 0.14196 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"mirroredEdgesRemoval\" - 68: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.13569 seconds\n",
      "\n",
      "The MST weight at the end of iteration 10 is: 2197144458\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"colorationProcess\" - 69: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.13487 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 9\n",
      "Resorting to a round of CPU scan\n",
      "Time required for a round of CPU scan on the flag array:   0.00000 (sec)\n",
      "The contracted graph will contain 2 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (3, 1, 1)\n",
      "==PROF== Profiling \"cumulatedDegreeUpdateTexture\" - 70: 0%....50%....100% - 9 passes\n",
      "Doing the computation of the cumulated degrees took: 0.13213 seconds\n",
      "\n",
      "Doing a round of scan on the cumDegs vector, size: 3\n",
      "Resorting to a round of CPU scan\n",
      "The contracted graph will contain 104 edges\n",
      "The old graph structure contained 3054 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"graphContractionTexture\" - 71: 0%....50%....100% - 9 passes\n",
      "The construction of the new neighbour and weight arrays took: 0.14017 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 2 with 104 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST TEXTURE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"findCheapestTexture\" - 72: 0%....50%....100% - 9 passes\n",
      "Finding the cheapest edge for every vertex took: 0.14369 seconds\n",
      "\n",
      "The procedure took in total 0.14369 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"mirroredEdgesRemoval\" - 73: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.13799 seconds\n",
      "\n",
      "The MST weight at the end of iteration 11 is: 2197153745\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "==PROF== Profiling \"colorationProcess\" - 74: 0%....50%....100% - 9 passes\n",
      "Removing the mirrored edges required: 0.14134 seconds\n",
      "\n",
      "THE CALCULATION OF THE MST IS COMPLETE\n",
      "THE MST WEIGHT IS: 2197153745\n",
      "Total elapsed time: 15.48542 seconds\n",
      "\n",
      "The time distribution is the following:\n",
      "\tFirst phase: 2.27571\n",
      "\tSecond phase: 2.02855\n",
      "\tThird phase: 1.92144\n",
      "\tFourth phase: 2.40617\n",
      "\tFifth phase: 4.71815\n",
      "Error: src/GPU/mstGPUETex.cu:682, code: 709, reason: context is destroyed\n",
      "Error: src/GPU/mstGPUETex.cu:683, code: 709, reason: context is destroyed\n",
      "==PROF== Disconnected from process 79426\n",
      "[79426] mstGPUETex@127.0.0.1\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (3515, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.97\n",
      "    SM Frequency            cycle/usecond       582.01\n",
      "    Elapsed Cycles                  cycle      522,012\n",
      "    Memory Throughput                   %        49.29\n",
      "    DRAM Throughput                     %        49.29\n",
      "    Duration                      usecond       896.90\n",
      "    L1/TEX Cache Throughput             %        37.07\n",
      "    L2 Cache Throughput                 %        12.82\n",
      "    SM Active Cycles                cycle   504,416.10\n",
      "    Compute (SM) Throughput             %        20.13\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  3,515\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       3,599,360\n",
      "    Waves Per SM                                               87.88\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        87.06\n",
      "    Achieved Active Warps Per SM           warp        27.86\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 12.94%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (87.1%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (3515, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.00\n",
      "    SM Frequency            cycle/usecond       585.38\n",
      "    Elapsed Cycles                  cycle    2,282,934\n",
      "    Memory Throughput                   %        17.38\n",
      "    DRAM Throughput                     %        17.38\n",
      "    Duration                      msecond         3.90\n",
      "    L1/TEX Cache Throughput             %        13.79\n",
      "    L2 Cache Throughput                 %         8.05\n",
      "    SM Active Cycles                cycle 2,258,144.55\n",
      "    Compute (SM) Throughput             %         3.91\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  3,515\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       3,599,360\n",
      "    Waves Per SM                                               87.88\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        66.65\n",
      "    Achieved Active Warps Per SM           warp        21.33\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 33.35%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (66.6%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (3515, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.99\n",
      "    SM Frequency            cycle/usecond       584.49\n",
      "    Elapsed Cycles                  cycle    2,762,355\n",
      "    Memory Throughput                   %        79.51\n",
      "    DRAM Throughput                     %        79.51\n",
      "    Duration                      msecond         4.73\n",
      "    L1/TEX Cache Throughput             %        43.66\n",
      "    L2 Cache Throughput                 %        24.17\n",
      "    SM Active Cycles                cycle 2,736,574.85\n",
      "    Compute (SM) Throughput             %        17.73\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
      "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
      "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
      "          whether there are values you can (re)compute.                                                                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  3,515\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       3,599,360\n",
      "    Waves Per SM                                               87.88\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        79.07\n",
      "    Achieved Active Warps Per SM           warp        25.30\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 20.93%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (79.1%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (1758, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.00\n",
      "    SM Frequency            cycle/usecond       585.11\n",
      "    Elapsed Cycles                  cycle      827,045\n",
      "    Memory Throughput                   %        39.20\n",
      "    DRAM Throughput                     %         8.46\n",
      "    Duration                      msecond         1.41\n",
      "    L1/TEX Cache Throughput             %        69.76\n",
      "    L2 Cache Throughput                 %         2.83\n",
      "    SM Active Cycles                cycle   812,604.38\n",
      "    Compute (SM) Throughput             %        39.20\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,758\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       1,800,192\n",
      "    Waves Per SM                                               43.95\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        99.05\n",
      "    Achieved Active Warps Per SM           warp        31.70\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (3515, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.94\n",
      "    SM Frequency            cycle/usecond       578.74\n",
      "    Elapsed Cycles                  cycle       82,403\n",
      "    Memory Throughput                   %        66.87\n",
      "    DRAM Throughput                     %        66.87\n",
      "    Duration                      usecond       142.37\n",
      "    L1/TEX Cache Throughput             %        69.56\n",
      "    L2 Cache Throughput                 %        35.01\n",
      "    SM Active Cycles                cycle    67,588.45\n",
      "    Compute (SM) Throughput             %        27.29\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
      "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
      "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
      "          whether there are values you can (re)compute.                                                                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  3,515\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       3,599,360\n",
      "    Waves Per SM                                               87.88\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        81.46\n",
      "    Achieved Active Warps Per SM           warp        26.07\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 18.54%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (81.5%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  cumulatedDegreeUpdateTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned long long) (3515, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.94\n",
      "    SM Frequency            cycle/usecond       577.93\n",
      "    Elapsed Cycles                  cycle      532,519\n",
      "    Memory Throughput                   %        66.84\n",
      "    DRAM Throughput                     %        66.84\n",
      "    Duration                      usecond       921.41\n",
      "    L1/TEX Cache Throughput             %        48.92\n",
      "    L2 Cache Throughput                 %        27.88\n",
      "    SM Active Cycles                cycle   531,171.45\n",
      "    Compute (SM) Throughput             %        15.63\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
      "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
      "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
      "          whether there are values you can (re)compute.                                                                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  3,515\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       3,599,360\n",
      "    Waves Per SM                                               87.88\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        87.19\n",
      "    Achieved Active Warps Per SM           warp        27.90\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 12.81%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (87.2%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (519, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.98\n",
      "    SM Frequency            cycle/usecond       583.01\n",
      "    Elapsed Cycles                  cycle      235,447\n",
      "    Memory Throughput                   %        37.13\n",
      "    DRAM Throughput                     %         7.46\n",
      "    Duration                      usecond       403.84\n",
      "    L1/TEX Cache Throughput             %        68.76\n",
      "    L2 Cache Throughput                 %         2.93\n",
      "    SM Active Cycles                cycle   230,713.30\n",
      "    Compute (SM) Throughput             %        37.13\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    519\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         531,456\n",
      "    Waves Per SM                                               12.97\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        99.00\n",
      "    Achieved Active Warps Per SM           warp        31.68\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (1038, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.82\n",
      "    SM Frequency            cycle/usecond       564.76\n",
      "    Elapsed Cycles                  cycle       25,327\n",
      "    Memory Throughput                   %        54.80\n",
      "    DRAM Throughput                     %        54.80\n",
      "    Duration                      usecond        44.83\n",
      "    L1/TEX Cache Throughput             %        66.83\n",
      "    L2 Cache Throughput                 %        33.92\n",
      "    SM Active Cycles                cycle    19,990.20\n",
      "    Compute (SM) Throughput             %        26.19\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,038\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       1,062,912\n",
      "    Waves Per SM                                               25.95\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        79.86\n",
      "    Achieved Active Warps Per SM           warp        25.56\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 20.14%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (79.9%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  graphContractionTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned long long, unsigned long long) (3515, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.98\n",
      "    SM Frequency            cycle/usecond       583.67\n",
      "    Elapsed Cycles                  cycle    1,319,296\n",
      "    Memory Throughput                   %        65.96\n",
      "    DRAM Throughput                     %        65.96\n",
      "    Duration                      msecond         2.26\n",
      "    L1/TEX Cache Throughput             %        70.36\n",
      "    L2 Cache Throughput                 %        31.59\n",
      "    SM Active Cycles                cycle 1,299,820.70\n",
      "    Compute (SM) Throughput             %        17.34\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
      "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
      "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
      "          whether there are values you can (re)compute.                                                                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  3,515\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       3,599,360\n",
      "    Waves Per SM                                               87.88\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        84.24\n",
      "    Achieved Active Warps Per SM           warp        26.96\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 15.76%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (84.2%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (1038, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.96\n",
      "    SM Frequency            cycle/usecond       580.42\n",
      "    Elapsed Cycles                  cycle      224,806\n",
      "    Memory Throughput                   %        41.12\n",
      "    DRAM Throughput                     %        40.66\n",
      "    Duration                      usecond       387.30\n",
      "    L1/TEX Cache Throughput             %        42.94\n",
      "    L2 Cache Throughput                 %        11.28\n",
      "    SM Active Cycles                cycle   215,276.77\n",
      "    Compute (SM) Throughput             %        18.62\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,038\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       1,062,912\n",
      "    Waves Per SM                                               25.95\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        81.94\n",
      "    Achieved Active Warps Per SM           warp        26.22\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 18.06%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (81.9%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (1038, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.98\n",
      "    SM Frequency            cycle/usecond       583.68\n",
      "    Elapsed Cycles                  cycle      682,756\n",
      "    Memory Throughput                   %        16.95\n",
      "    DRAM Throughput                     %        16.95\n",
      "    Duration                      msecond         1.17\n",
      "    L1/TEX Cache Throughput             %        14.17\n",
      "    L2 Cache Throughput                 %         8.07\n",
      "    SM Active Cycles                cycle   669,742.72\n",
      "    Compute (SM) Throughput             %         3.87\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,038\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       1,062,912\n",
      "    Waves Per SM                                               25.95\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        66.60\n",
      "    Achieved Active Warps Per SM           warp        21.31\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 33.4%                                                                                      \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (66.6%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (1038, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.02\n",
      "    SM Frequency            cycle/usecond       587.47\n",
      "    Elapsed Cycles                  cycle      832,481\n",
      "    Memory Throughput                   %        77.49\n",
      "    DRAM Throughput                     %        77.49\n",
      "    Duration                      msecond         1.42\n",
      "    L1/TEX Cache Throughput             %        43.26\n",
      "    L2 Cache Throughput                 %        24.22\n",
      "    SM Active Cycles                cycle   813,036.10\n",
      "    Compute (SM) Throughput             %        18.14\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
      "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
      "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
      "          whether there are values you can (re)compute.                                                                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,038\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       1,062,912\n",
      "    Waves Per SM                                               25.95\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        78.42\n",
      "    Achieved Active Warps Per SM           warp        25.10\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 21.58%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (78.4%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (519, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.97\n",
      "    SM Frequency            cycle/usecond       581.76\n",
      "    Elapsed Cycles                  cycle      235,972\n",
      "    Memory Throughput                   %        37.05\n",
      "    DRAM Throughput                     %         7.45\n",
      "    Duration                      usecond       405.60\n",
      "    L1/TEX Cache Throughput             %        68.61\n",
      "    L2 Cache Throughput                 %         2.92\n",
      "    SM Active Cycles                cycle   230,291.73\n",
      "    Compute (SM) Throughput             %        37.05\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    519\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         531,456\n",
      "    Waves Per SM                                               12.97\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        99.00\n",
      "    Achieved Active Warps Per SM           warp        31.68\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (1038, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.93\n",
      "    SM Frequency            cycle/usecond       577.49\n",
      "    Elapsed Cycles                  cycle       25,672\n",
      "    Memory Throughput                   %        53.80\n",
      "    DRAM Throughput                     %        53.80\n",
      "    Duration                      usecond        44.45\n",
      "    L1/TEX Cache Throughput             %        65.65\n",
      "    L2 Cache Throughput                 %        33.43\n",
      "    SM Active Cycles                cycle    20,074.72\n",
      "    Compute (SM) Throughput             %        25.83\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,038\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       1,062,912\n",
      "    Waves Per SM                                               25.95\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        80.21\n",
      "    Achieved Active Warps Per SM           warp        25.67\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 19.79%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (80.2%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  cumulatedDegreeUpdateTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned long long) (1038, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.00\n",
      "    SM Frequency            cycle/usecond       586.10\n",
      "    Elapsed Cycles                  cycle      173,004\n",
      "    Memory Throughput                   %        60.97\n",
      "    DRAM Throughput                     %        60.97\n",
      "    Duration                      usecond       295.17\n",
      "    L1/TEX Cache Throughput             %        43.53\n",
      "    L2 Cache Throughput                 %        25.16\n",
      "    SM Active Cycles                cycle   164,145.75\n",
      "    Compute (SM) Throughput             %        18.41\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
      "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
      "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
      "          whether there are values you can (re)compute.                                                                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,038\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       1,062,912\n",
      "    Waves Per SM                                               25.95\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        85.36\n",
      "    Achieved Active Warps Per SM           warp        27.32\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 14.64%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (85.4%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (150, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.98\n",
      "    SM Frequency            cycle/usecond       583.02\n",
      "    Elapsed Cycles                  cycle       68,106\n",
      "    Memory Throughput                   %        31.63\n",
      "    DRAM Throughput                     %         5.28\n",
      "    Duration                      usecond       116.80\n",
      "    L1/TEX Cache Throughput             %        63.10\n",
      "    L2 Cache Throughput                 %         2.91\n",
      "    SM Active Cycles                cycle    61,349.12\n",
      "    Compute (SM) Throughput             %        31.63\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    150\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         153,600\n",
      "    Waves Per SM                                                3.75\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        98.91\n",
      "    Achieved Active Warps Per SM           warp        31.65\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (299, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.82\n",
      "    SM Frequency            cycle/usecond       563.49\n",
      "    Elapsed Cycles                  cycle        8,895\n",
      "    Memory Throughput                   %        28.85\n",
      "    DRAM Throughput                     %        28.85\n",
      "    Duration                      usecond        15.78\n",
      "    L1/TEX Cache Throughput             %        55.11\n",
      "    L2 Cache Throughput                 %        28.13\n",
      "    SM Active Cycles                cycle     6,554.18\n",
      "    Compute (SM) Throughput             %        21.42\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    299\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         306,176\n",
      "    Waves Per SM                                                7.47\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        78.62\n",
      "    Achieved Active Warps Per SM           warp        25.16\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 21.38%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (78.6%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  graphContractionTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned long long, unsigned long long) (1038, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.95\n",
      "    SM Frequency            cycle/usecond       579.51\n",
      "    Elapsed Cycles                  cycle      617,530\n",
      "    Memory Throughput                   %        50.65\n",
      "    DRAM Throughput                     %        50.65\n",
      "    Duration                      msecond         1.07\n",
      "    L1/TEX Cache Throughput             %        71.82\n",
      "    L2 Cache Throughput                 %        32.37\n",
      "    SM Active Cycles                cycle   600,479.38\n",
      "    Compute (SM) Throughput             %        20.68\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,038\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread       1,062,912\n",
      "    Waves Per SM                                               25.95\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        80.83\n",
      "    Achieved Active Warps Per SM           warp        25.87\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 19.17%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (80.8%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (299, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.97\n",
      "    SM Frequency            cycle/usecond       582.51\n",
      "    Elapsed Cycles                  cycle      124,766\n",
      "    Memory Throughput                   %        39.06\n",
      "    DRAM Throughput                     %        30.14\n",
      "    Duration                      usecond       214.18\n",
      "    L1/TEX Cache Throughput             %        43.31\n",
      "    L2 Cache Throughput                 %        11.81\n",
      "    SM Active Cycles                cycle   112,508.12\n",
      "    Compute (SM) Throughput             %        17.10\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    299\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         306,176\n",
      "    Waves Per SM                                                7.47\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        74.01\n",
      "    Achieved Active Warps Per SM           warp        23.68\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 25.99%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (74.0%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (299, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.96\n",
      "    SM Frequency            cycle/usecond       580.61\n",
      "    Elapsed Cycles                  cycle      206,634\n",
      "    Memory Throughput                   %        18.79\n",
      "    DRAM Throughput                     %        18.79\n",
      "    Duration                      usecond       355.87\n",
      "    L1/TEX Cache Throughput             %        13.89\n",
      "    L2 Cache Throughput                 %         8.31\n",
      "    SM Active Cycles                cycle   195,859.90\n",
      "    Compute (SM) Throughput             %         3.68\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    299\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         306,176\n",
      "    Waves Per SM                                                7.47\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        64.31\n",
      "    Achieved Active Warps Per SM           warp        20.58\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 35.69%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (64.3%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (299, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.02\n",
      "    SM Frequency            cycle/usecond       588.21\n",
      "    Elapsed Cycles                  cycle      255,053\n",
      "    Memory Throughput                   %        73.22\n",
      "    DRAM Throughput                     %        73.22\n",
      "    Duration                      usecond       433.60\n",
      "    L1/TEX Cache Throughput             %        41.02\n",
      "    L2 Cache Throughput                 %        23.55\n",
      "    SM Active Cycles                cycle   236,737.77\n",
      "    Compute (SM) Throughput             %        18.02\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
      "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
      "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
      "          whether there are values you can (re)compute.                                                                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    299\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         306,176\n",
      "    Waves Per SM                                                7.47\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        80.85\n",
      "    Achieved Active Warps Per SM           warp        25.87\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 19.15%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (80.8%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (150, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.96\n",
      "    SM Frequency            cycle/usecond       580.74\n",
      "    Elapsed Cycles                  cycle       68,278\n",
      "    Memory Throughput                   %        31.54\n",
      "    DRAM Throughput                     %         5.32\n",
      "    Duration                      usecond       117.57\n",
      "    L1/TEX Cache Throughput             %        62.93\n",
      "    L2 Cache Throughput                 %         2.90\n",
      "    SM Active Cycles                cycle    61,349.43\n",
      "    Compute (SM) Throughput             %        31.54\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    150\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         153,600\n",
      "    Waves Per SM                                                3.75\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        98.90\n",
      "    Achieved Active Warps Per SM           warp        31.65\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (299, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.78\n",
      "    SM Frequency            cycle/usecond       560.19\n",
      "    Elapsed Cycles                  cycle        8,789\n",
      "    Memory Throughput                   %        29.18\n",
      "    DRAM Throughput                     %        29.18\n",
      "    Duration                      usecond        15.68\n",
      "    L1/TEX Cache Throughput             %        55.05\n",
      "    L2 Cache Throughput                 %        28.51\n",
      "    SM Active Cycles                cycle     6,527.77\n",
      "    Compute (SM) Throughput             %        21.68\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    299\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         306,176\n",
      "    Waves Per SM                                                7.47\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        78.69\n",
      "    Achieved Active Warps Per SM           warp        25.18\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 21.31%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (78.7%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  cumulatedDegreeUpdateTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned long long) (299, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.94\n",
      "    SM Frequency            cycle/usecond       578.39\n",
      "    Elapsed Cycles                  cycle       72,468\n",
      "    Memory Throughput                   %        43.78\n",
      "    DRAM Throughput                     %        43.78\n",
      "    Duration                      usecond       125.28\n",
      "    L1/TEX Cache Throughput             %        34.14\n",
      "    L2 Cache Throughput                 %        17.89\n",
      "    SM Active Cycles                cycle    63,445.05\n",
      "    Compute (SM) Throughput             %        18.65\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    299\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         306,176\n",
      "    Waves Per SM                                                7.47\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        82.99\n",
      "    Achieved Active Warps Per SM           warp        26.56\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 17.01%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (83.0%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (40, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.94\n",
      "    SM Frequency            cycle/usecond       577.71\n",
      "    Elapsed Cycles                  cycle       17,200\n",
      "    Memory Throughput                   %        30.30\n",
      "    DRAM Throughput                     %         5.46\n",
      "    Duration                      usecond        29.76\n",
      "    L1/TEX Cache Throughput             %        60.59\n",
      "    L2 Cache Throughput                 %         3.20\n",
      "    SM Active Cycles                cycle    15,528.90\n",
      "    Compute (SM) Throughput             %        27.49\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     40\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          40,960\n",
      "    Waves Per SM                                                   1\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the \n",
      "          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   \n",
      "          hardware busy.                                                                                                \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        98.83\n",
      "    Achieved Active Warps Per SM           warp        31.63\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (80, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.81\n",
      "    SM Frequency            cycle/usecond       560.50\n",
      "    Elapsed Cycles                  cycle        3,647\n",
      "    Memory Throughput                   %        18.23\n",
      "    DRAM Throughput                     %        17.48\n",
      "    Duration                      usecond         6.50\n",
      "    L1/TEX Cache Throughput             %        34.54\n",
      "    L2 Cache Throughput                 %        18.23\n",
      "    SM Active Cycles                cycle     2,099.65\n",
      "    Compute (SM) Throughput             %        13.79\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     80\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          81,920\n",
      "    Waves Per SM                                                   2\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        80.13\n",
      "    Achieved Active Warps Per SM           warp        25.64\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 19.87%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (80.1%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  graphContractionTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned long long, unsigned long long) (299, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.78\n",
      "    SM Frequency            cycle/usecond       559.75\n",
      "    Elapsed Cycles                  cycle      278,176\n",
      "    Memory Throughput                   %        39.95\n",
      "    DRAM Throughput                     %        39.95\n",
      "    Duration                      usecond       496.96\n",
      "    L1/TEX Cache Throughput             %        71.85\n",
      "    L2 Cache Throughput                 %        32.60\n",
      "    SM Active Cycles                cycle   254,395.83\n",
      "    Compute (SM) Throughput             %        21.50\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                    299\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread         306,176\n",
      "    Waves Per SM                                                7.47\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        80.00\n",
      "    Achieved Active Warps Per SM           warp        25.60\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 20%                                                                                        \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (80.0%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (80, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.82\n",
      "    SM Frequency            cycle/usecond       563.88\n",
      "    Elapsed Cycles                  cycle       92,568\n",
      "    Memory Throughput                   %        26.71\n",
      "    DRAM Throughput                     %        18.65\n",
      "    Duration                      usecond       164.16\n",
      "    L1/TEX Cache Throughput             %        37.91\n",
      "    L2 Cache Throughput                 %        12.99\n",
      "    SM Active Cycles                cycle    65,204.03\n",
      "    Compute (SM) Throughput             %        11.32\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     80\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          81,920\n",
      "    Waves Per SM                                                   2\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        65.09\n",
      "    Achieved Active Warps Per SM           warp        20.83\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 34.91%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (65.1%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (80, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.90\n",
      "    SM Frequency            cycle/usecond       574.26\n",
      "    Elapsed Cycles                  cycle       62,002\n",
      "    Memory Throughput                   %        21.17\n",
      "    DRAM Throughput                     %        21.17\n",
      "    Duration                      usecond       107.97\n",
      "    L1/TEX Cache Throughput             %        12.64\n",
      "    L2 Cache Throughput                 %         8.19\n",
      "    SM Active Cycles                cycle    55,334.75\n",
      "    Compute (SM) Throughput             %         3.30\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     80\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          81,920\n",
      "    Waves Per SM                                                   2\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        59.56\n",
      "    Achieved Active Warps Per SM           warp        19.06\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 40.44%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (59.6%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (80, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.76\n",
      "    SM Frequency            cycle/usecond       557.29\n",
      "    Elapsed Cycles                  cycle       75,137\n",
      "    Memory Throughput                   %        70.17\n",
      "    DRAM Throughput                     %        70.17\n",
      "    Duration                      usecond       134.82\n",
      "    L1/TEX Cache Throughput             %        38.01\n",
      "    L2 Cache Throughput                 %        22.39\n",
      "    SM Active Cycles                cycle    71,174.12\n",
      "    Compute (SM) Throughput             %        17.25\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
      "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
      "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
      "          whether there are values you can (re)compute.                                                                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     80\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          81,920\n",
      "    Waves Per SM                                                   2\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        84.35\n",
      "    Achieved Active Warps Per SM           warp        26.99\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 15.65%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (84.3%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (40, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.97\n",
      "    SM Frequency            cycle/usecond       581.04\n",
      "    Elapsed Cycles                  cycle       17,262\n",
      "    Memory Throughput                   %        30.19\n",
      "    DRAM Throughput                     %         5.38\n",
      "    Duration                      usecond        29.70\n",
      "    L1/TEX Cache Throughput             %        60.37\n",
      "    L2 Cache Throughput                 %         3.13\n",
      "    SM Active Cycles                cycle    15,498.02\n",
      "    Compute (SM) Throughput             %        27.39\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     40\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          40,960\n",
      "    Waves Per SM                                                   1\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the \n",
      "          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   \n",
      "          hardware busy.                                                                                                \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        98.86\n",
      "    Achieved Active Warps Per SM           warp        31.63\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (80, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.91\n",
      "    SM Frequency            cycle/usecond       570.17\n",
      "    Elapsed Cycles                  cycle        3,709\n",
      "    Memory Throughput                   %        17.94\n",
      "    DRAM Throughput                     %        17.04\n",
      "    Duration                      usecond         6.50\n",
      "    L1/TEX Cache Throughput             %        34.12\n",
      "    L2 Cache Throughput                 %        17.94\n",
      "    SM Active Cycles                cycle     2,129.68\n",
      "    Compute (SM) Throughput             %        13.56\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     80\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          81,920\n",
      "    Waves Per SM                                                   2\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        80.21\n",
      "    Achieved Active Warps Per SM           warp        25.67\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 19.79%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (80.2%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  cumulatedDegreeUpdateTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned long long) (80, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.95\n",
      "    SM Frequency            cycle/usecond       579.59\n",
      "    Elapsed Cycles                  cycle       35,823\n",
      "    Memory Throughput                   %        31.71\n",
      "    DRAM Throughput                     %        31.71\n",
      "    Duration                      usecond        61.79\n",
      "    L1/TEX Cache Throughput             %        37.65\n",
      "    L2 Cache Throughput                 %        12.00\n",
      "    SM Active Cycles                cycle    26,633.53\n",
      "    Compute (SM) Throughput             %        15.13\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     80\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          81,920\n",
      "    Waves Per SM                                                   2\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        78.47\n",
      "    Achieved Active Warps Per SM           warp        25.11\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 21.53%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (78.5%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (10, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.92\n",
      "    SM Frequency            cycle/usecond       575.62\n",
      "    Elapsed Cycles                  cycle       12,732\n",
      "    Memory Throughput                   %         9.20\n",
      "    DRAM Throughput                     %         1.70\n",
      "    Duration                      usecond        22.11\n",
      "    L1/TEX Cache Throughput             %        40.73\n",
      "    L2 Cache Throughput                 %         1.13\n",
      "    SM Active Cycles                cycle     2,873.70\n",
      "    Compute (SM) Throughput             %         7.45\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     10\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          10,240\n",
      "    Waves Per SM                                                0.25\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 75%                                                                                        \n",
      "          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 40             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        98.54\n",
      "    Achieved Active Warps Per SM           warp        31.53\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (20, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.75\n",
      "    SM Frequency            cycle/usecond       555.52\n",
      "    Elapsed Cycles                  cycle        2,761\n",
      "    Memory Throughput                   %         5.70\n",
      "    DRAM Throughput                     %         5.49\n",
      "    Duration                      usecond         4.96\n",
      "    L1/TEX Cache Throughput             %        28.76\n",
      "    L2 Cache Throughput                 %         5.70\n",
      "    SM Active Cycles                cycle       501.30\n",
      "    Compute (SM) Throughput             %         4.25\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     20\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          20,480\n",
      "    Waves Per SM                                                0.50\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 50%                                                                                        \n",
      "          The grid for this launch is configured to execute only 20 blocks, which is less than the GPU's 40             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        88.11\n",
      "    Achieved Active Warps Per SM           warp        28.20\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 11.89%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (88.1%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  graphContractionTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned long long, unsigned long long) (80, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.53\n",
      "    SM Frequency            cycle/usecond       530.00\n",
      "    Elapsed Cycles                  cycle      147,697\n",
      "    Memory Throughput                   %        30.30\n",
      "    DRAM Throughput                     %        30.30\n",
      "    Duration                      usecond       278.66\n",
      "    L1/TEX Cache Throughput             %        59.33\n",
      "    L2 Cache Throughput                 %        27.08\n",
      "    SM Active Cycles                cycle   113,416.50\n",
      "    Compute (SM) Throughput             %        16.60\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     80\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          81,920\n",
      "    Waves Per SM                                                   2\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        74.89\n",
      "    Achieved Active Warps Per SM           warp        23.97\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 25.11%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (74.9%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (20, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.97\n",
      "    SM Frequency            cycle/usecond       582.02\n",
      "    Elapsed Cycles                  cycle      115,584\n",
      "    Memory Throughput                   %        10.17\n",
      "    DRAM Throughput                     %         6.49\n",
      "    Duration                      usecond       198.59\n",
      "    L1/TEX Cache Throughput             %        37.00\n",
      "    L2 Cache Throughput                 %         7.14\n",
      "    SM Active Cycles                cycle    31,780.05\n",
      "    Compute (SM) Throughput             %         4.00\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     20\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          20,480\n",
      "    Waves Per SM                                                0.50\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 50%                                                                                        \n",
      "          The grid for this launch is configured to execute only 20 blocks, which is less than the GPU's 40             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        58.41\n",
      "    Achieved Active Warps Per SM           warp        18.69\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 41.59%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (58.4%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (20, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.96\n",
      "    SM Frequency            cycle/usecond       581.05\n",
      "    Elapsed Cycles                  cycle       18,476\n",
      "    Memory Throughput                   %        22.05\n",
      "    DRAM Throughput                     %        22.05\n",
      "    Duration                      usecond        31.78\n",
      "    L1/TEX Cache Throughput             %        16.05\n",
      "    L2 Cache Throughput                 %         7.72\n",
      "    SM Active Cycles                cycle     7,204.52\n",
      "    Compute (SM) Throughput             %         2.74\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     20\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          20,480\n",
      "    Waves Per SM                                                0.50\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 50%                                                                                        \n",
      "          The grid for this launch is configured to execute only 20 blocks, which is less than the GPU's 40             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        59.25\n",
      "    Achieved Active Warps Per SM           warp        18.96\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 40.75%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (59.2%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (20, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.61\n",
      "    SM Frequency            cycle/usecond       539.54\n",
      "    Elapsed Cycles                  cycle       20,066\n",
      "    Memory Throughput                   %        46.59\n",
      "    DRAM Throughput                     %        46.59\n",
      "    Duration                      usecond        37.18\n",
      "    L1/TEX Cache Throughput             %        43.78\n",
      "    L2 Cache Throughput                 %        22.20\n",
      "    SM Active Cycles                cycle     8,354.65\n",
      "    Compute (SM) Throughput             %        16.31\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     20\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          20,480\n",
      "    Waves Per SM                                                0.50\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 50%                                                                                        \n",
      "          The grid for this launch is configured to execute only 20 blocks, which is less than the GPU's 40             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        82.35\n",
      "    Achieved Active Warps Per SM           warp        26.35\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 17.65%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (82.3%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (10, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.95\n",
      "    SM Frequency            cycle/usecond       579.43\n",
      "    Elapsed Cycles                  cycle       12,744\n",
      "    Memory Throughput                   %         9.19\n",
      "    DRAM Throughput                     %         1.74\n",
      "    Duration                      usecond        21.98\n",
      "    L1/TEX Cache Throughput             %        40.69\n",
      "    L2 Cache Throughput                 %         1.09\n",
      "    SM Active Cycles                cycle     2,876.65\n",
      "    Compute (SM) Throughput             %         7.44\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     10\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          10,240\n",
      "    Waves Per SM                                                0.25\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 75%                                                                                        \n",
      "          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 40             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        98.52\n",
      "    Achieved Active Warps Per SM           warp        31.53\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (20, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.96\n",
      "    SM Frequency            cycle/usecond       579.83\n",
      "    Elapsed Cycles                  cycle        2,862\n",
      "    Memory Throughput                   %         5.55\n",
      "    DRAM Throughput                     %         5.15\n",
      "    Duration                      usecond         4.93\n",
      "    L1/TEX Cache Throughput             %        29.48\n",
      "    L2 Cache Throughput                 %         5.55\n",
      "    SM Active Cycles                cycle       507.27\n",
      "    Compute (SM) Throughput             %         4.10\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     20\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          20,480\n",
      "    Waves Per SM                                                0.50\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 50%                                                                                        \n",
      "          The grid for this launch is configured to execute only 20 blocks, which is less than the GPU's 40             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        88.30\n",
      "    Achieved Active Warps Per SM           warp        28.26\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 11.7%                                                                                      \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (88.3%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  cumulatedDegreeUpdateTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned long long) (20, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.90\n",
      "    SM Frequency            cycle/usecond       573.64\n",
      "    Elapsed Cycles                  cycle       35,622\n",
      "    Memory Throughput                   %        12.76\n",
      "    DRAM Throughput                     %        12.76\n",
      "    Duration                      usecond        62.08\n",
      "    L1/TEX Cache Throughput             %        38.90\n",
      "    L2 Cache Throughput                 %         5.22\n",
      "    SM Active Cycles                cycle    10,731.83\n",
      "    Compute (SM) Throughput             %         5.67\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     20\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          20,480\n",
      "    Waves Per SM                                                0.50\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 50%                                                                                        \n",
      "          The grid for this launch is configured to execute only 20 blocks, which is less than the GPU's 40             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        70.03\n",
      "    Achieved Active Warps Per SM           warp        22.41\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 29.97%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (70.0%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (3, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.96\n",
      "    SM Frequency            cycle/usecond       580.67\n",
      "    Elapsed Cycles                  cycle       11,261\n",
      "    Memory Throughput                   %         2.73\n",
      "    DRAM Throughput                     %         0.44\n",
      "    Duration                      usecond        19.39\n",
      "    L1/TEX Cache Throughput             %        41.33\n",
      "    L2 Cache Throughput                 %         0.39\n",
      "    SM Active Cycles                cycle       743.58\n",
      "    Compute (SM) Throughput             %         2.09\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      3\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           3,072\n",
      "    Waves Per SM                                                0.07\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 92.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 3 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        98.43\n",
      "    Achieved Active Warps Per SM           warp        31.50\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (5, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.72\n",
      "    SM Frequency            cycle/usecond       550.67\n",
      "    Elapsed Cycles                  cycle        2,626\n",
      "    Memory Throughput                   %         1.17\n",
      "    DRAM Throughput                     %         0.88\n",
      "    Duration                      usecond         4.77\n",
      "    L1/TEX Cache Throughput             %        23.34\n",
      "    L2 Cache Throughput                 %         1.17\n",
      "    SM Active Cycles                cycle       107.95\n",
      "    Compute (SM) Throughput             %         0.78\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      5\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           5,120\n",
      "    Waves Per SM                                                0.12\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 87.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 5 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        82.33\n",
      "    Achieved Active Warps Per SM           warp        26.35\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 17.67%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (82.3%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  graphContractionTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned long long, unsigned long long) (20, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.91\n",
      "    SM Frequency            cycle/usecond       574.41\n",
      "    Elapsed Cycles                  cycle      145,413\n",
      "    Memory Throughput                   %        12.74\n",
      "    DRAM Throughput                     %         9.49\n",
      "    Duration                      usecond       253.15\n",
      "    L1/TEX Cache Throughput             %        44.77\n",
      "    L2 Cache Throughput                 %        11.84\n",
      "    SM Active Cycles                cycle    41,382.97\n",
      "    Compute (SM) Throughput             %         6.40\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                     20\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread          20,480\n",
      "    Waves Per SM                                                0.50\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 50%                                                                                        \n",
      "          The grid for this launch is configured to execute only 20 blocks, which is less than the GPU's 40             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        63.33\n",
      "    Achieved Active Warps Per SM           warp        20.27\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 36.67%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (63.3%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (5, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.04\n",
      "    SM Frequency            cycle/usecond       589.79\n",
      "    Elapsed Cycles                  cycle      181,679\n",
      "    Memory Throughput                   %         3.00\n",
      "    DRAM Throughput                     %         1.95\n",
      "    Duration                      usecond       308.03\n",
      "    L1/TEX Cache Throughput             %        37.34\n",
      "    L2 Cache Throughput                 %         2.55\n",
      "    SM Active Cycles                cycle    14,613.33\n",
      "    Compute (SM) Throughput             %         1.09\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      5\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           5,120\n",
      "    Waves Per SM                                                0.12\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 87.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 5 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        57.33\n",
      "    Achieved Active Warps Per SM           warp        18.34\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 42.67%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (57.3%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (5, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.92\n",
      "    SM Frequency            cycle/usecond       576.87\n",
      "    Elapsed Cycles                  cycle        7,536\n",
      "    Memory Throughput                   %        16.26\n",
      "    DRAM Throughput                     %        16.26\n",
      "    Duration                      usecond        13.06\n",
      "    L1/TEX Cache Throughput             %        43.50\n",
      "    L2 Cache Throughput                 %         4.74\n",
      "    SM Active Cycles                cycle       675.95\n",
      "    Compute (SM) Throughput             %         1.58\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      5\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           5,120\n",
      "    Waves Per SM                                                0.12\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 87.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 5 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        78.80\n",
      "    Achieved Active Warps Per SM           warp        25.21\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 21.2%                                                                                      \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (78.8%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (5, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.91\n",
      "    SM Frequency            cycle/usecond       575.33\n",
      "    Elapsed Cycles                  cycle       15,450\n",
      "    Memory Throughput                   %        11.88\n",
      "    DRAM Throughput                     %        11.88\n",
      "    Duration                      usecond        26.85\n",
      "    L1/TEX Cache Throughput             %        53.93\n",
      "    L2 Cache Throughput                 %         6.69\n",
      "    SM Active Cycles                cycle     1,596.65\n",
      "    Compute (SM) Throughput             %         4.88\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      5\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           5,120\n",
      "    Waves Per SM                                                0.12\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 87.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 5 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        79.03\n",
      "    Achieved Active Warps Per SM           warp        25.29\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 20.97%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (79.0%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  prescan(unsigned int *, unsigned int *, unsigned int *, int, int) (3, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.92\n",
      "    SM Frequency            cycle/usecond       576.15\n",
      "    Elapsed Cycles                  cycle       11,266\n",
      "    Memory Throughput                   %         2.73\n",
      "    DRAM Throughput                     %         0.50\n",
      "    Duration                      usecond        19.55\n",
      "    L1/TEX Cache Throughput             %        41.32\n",
      "    L2 Cache Throughput                 %         0.36\n",
      "    SM Active Cycles                cycle       743.75\n",
      "    Compute (SM) Throughput             %         2.09\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      3\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block      Kbyte/block            8.19\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           3,072\n",
      "    Waves Per SM                                                0.07\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 92.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 3 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        98.64\n",
      "    Achieved Active Warps Per SM           warp        31.57\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "  final_sum(unsigned int *, unsigned int *, unsigned int) (5, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.80\n",
      "    SM Frequency            cycle/usecond       561.94\n",
      "    Elapsed Cycles                  cycle        2,608\n",
      "    Memory Throughput                   %         1.15\n",
      "    DRAM Throughput                     %         0.92\n",
      "    Duration                      usecond         4.64\n",
      "    L1/TEX Cache Throughput             %        23.08\n",
      "    L2 Cache Throughput                 %         1.15\n",
      "    SM Active Cycles                cycle       109.20\n",
      "    Compute (SM) Throughput             %         0.79\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      5\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           5,120\n",
      "    Waves Per SM                                                0.12\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 87.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 5 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        82.26\n",
      "    Achieved Active Warps Per SM           warp        26.32\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 17.74%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (82.3%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  cumulatedDegreeUpdateTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned long long) (5, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.10\n",
      "    SM Frequency            cycle/usecond       596.89\n",
      "    Elapsed Cycles                  cycle       53,283\n",
      "    Memory Throughput                   %         3.60\n",
      "    DRAM Throughput                     %         3.60\n",
      "    Duration                      usecond        89.25\n",
      "    L1/TEX Cache Throughput             %        37.14\n",
      "    L2 Cache Throughput                 %         1.53\n",
      "    SM Active Cycles                cycle     4,385.48\n",
      "    Compute (SM) Throughput             %         1.44\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      5\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           5,120\n",
      "    Waves Per SM                                                0.12\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 87.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 5 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        65.40\n",
      "    Achieved Active Warps Per SM           warp        20.93\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 34.6%                                                                                      \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (65.4%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  graphContractionTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned long long, unsigned long long) (5, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.98\n",
      "    SM Frequency            cycle/usecond       583.54\n",
      "    Elapsed Cycles                  cycle      189,734\n",
      "    Memory Throughput                   %         4.08\n",
      "    DRAM Throughput                     %         3.19\n",
      "    Duration                      usecond       325.12\n",
      "    L1/TEX Cache Throughput             %        46.60\n",
      "    L2 Cache Throughput                 %         3.83\n",
      "    SM Active Cycles                cycle    16,595.47\n",
      "    Compute (SM) Throughput             %         1.89\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      5\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           5,120\n",
      "    Waves Per SM                                                0.12\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 87.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 5 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        63.22\n",
      "    Achieved Active Warps Per SM           warp        20.23\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 36.78%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (63.2%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (2, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.95\n",
      "    SM Frequency            cycle/usecond       579.88\n",
      "    Elapsed Cycles                  cycle      223,158\n",
      "    Memory Throughput                   %         1.17\n",
      "    DRAM Throughput                     %         0.71\n",
      "    Duration                      usecond       384.83\n",
      "    L1/TEX Cache Throughput             %        41.48\n",
      "    L2 Cache Throughput                 %         1.05\n",
      "    SM Active Cycles                cycle     6,319.12\n",
      "    Compute (SM) Throughput             %         0.39\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      2\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           2,048\n",
      "    Waves Per SM                                                0.05\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 95%                                                                                        \n",
      "          The grid for this launch is configured to execute only 2 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        64.33\n",
      "    Achieved Active Warps Per SM           warp        20.58\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 35.67%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (64.3%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (2, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.88\n",
      "    SM Frequency            cycle/usecond       572.88\n",
      "    Elapsed Cycles                  cycle        6,804\n",
      "    Memory Throughput                   %         5.08\n",
      "    DRAM Throughput                     %         5.08\n",
      "    Duration                      usecond        11.87\n",
      "    L1/TEX Cache Throughput             %        35.79\n",
      "    L2 Cache Throughput                 %         1.33\n",
      "    SM Active Cycles                cycle       194.62\n",
      "    Compute (SM) Throughput             %         0.44\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      2\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           2,048\n",
      "    Waves Per SM                                                0.05\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 95%                                                                                        \n",
      "          The grid for this launch is configured to execute only 2 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        72.48\n",
      "    Achieved Active Warps Per SM           warp        23.19\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 27.52%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (72.5%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (2, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.01\n",
      "    SM Frequency            cycle/usecond       587.20\n",
      "    Elapsed Cycles                  cycle       16,331\n",
      "    Memory Throughput                   %         3.02\n",
      "    DRAM Throughput                     %         3.02\n",
      "    Duration                      usecond        27.81\n",
      "    L1/TEX Cache Throughput             %        41.75\n",
      "    L2 Cache Throughput                 %         1.63\n",
      "    SM Active Cycles                cycle       553.05\n",
      "    Compute (SM) Throughput             %         1.24\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      2\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           2,048\n",
      "    Waves Per SM                                                0.05\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 95%                                                                                        \n",
      "          The grid for this launch is configured to execute only 2 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        60.68\n",
      "    Achieved Active Warps Per SM           warp        19.42\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 39.32%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (60.7%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  cumulatedDegreeUpdateTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned long long) (2, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.95\n",
      "    SM Frequency            cycle/usecond       579.49\n",
      "    Elapsed Cycles                  cycle       65,255\n",
      "    Memory Throughput                   %         1.25\n",
      "    DRAM Throughput                     %         1.25\n",
      "    Duration                      usecond       112.61\n",
      "    L1/TEX Cache Throughput             %        35.29\n",
      "    L2 Cache Throughput                 %         0.51\n",
      "    SM Active Cycles                cycle     1,832.58\n",
      "    Compute (SM) Throughput             %         0.48\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      2\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           2,048\n",
      "    Waves Per SM                                                0.05\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 95%                                                                                        \n",
      "          The grid for this launch is configured to execute only 2 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        69.15\n",
      "    Achieved Active Warps Per SM           warp        22.13\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 30.85%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (69.2%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  graphContractionTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned long long, unsigned long long) (2, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.00\n",
      "    SM Frequency            cycle/usecond       585.10\n",
      "    Elapsed Cycles                  cycle      238,704\n",
      "    Memory Throughput                   %         1.33\n",
      "    DRAM Throughput                     %         1.08\n",
      "    Duration                      usecond       407.97\n",
      "    L1/TEX Cache Throughput             %        46.05\n",
      "    L2 Cache Throughput                 %         1.26\n",
      "    SM Active Cycles                cycle     6,874.50\n",
      "    Compute (SM) Throughput             %         0.62\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      2\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           2,048\n",
      "    Waves Per SM                                                0.05\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 95%                                                                                        \n",
      "          The grid for this launch is configured to execute only 2 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        64.54\n",
      "    Achieved Active Warps Per SM           warp        20.65\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 35.46%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (64.5%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.96\n",
      "    SM Frequency            cycle/usecond       580.88\n",
      "    Elapsed Cycles                  cycle      182,017\n",
      "    Memory Throughput                   %         0.63\n",
      "    DRAM Throughput                     %         0.38\n",
      "    Duration                      usecond       313.34\n",
      "    L1/TEX Cache Throughput             %        25.26\n",
      "    L2 Cache Throughput                 %         0.17\n",
      "    SM Active Cycles                cycle     4,572.80\n",
      "    Compute (SM) Throughput             %         0.19\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        18.45\n",
      "    Achieved Active Warps Per SM           warp         5.90\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 81.55%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (18.5%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.94\n",
      "    SM Frequency            cycle/usecond       579.82\n",
      "    Elapsed Cycles                  cycle        4,046\n",
      "    Memory Throughput                   %         2.14\n",
      "    DRAM Throughput                     %         2.14\n",
      "    Duration                      usecond         6.98\n",
      "    L1/TEX Cache Throughput             %        22.62\n",
      "    L2 Cache Throughput                 %         0.58\n",
      "    SM Active Cycles                cycle        72.08\n",
      "    Compute (SM) Throughput             %         0.21\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        42.37\n",
      "    Achieved Active Warps Per SM           warp        13.56\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 57.63%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (42.4%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.09\n",
      "    SM Frequency            cycle/usecond       595.73\n",
      "    Elapsed Cycles                  cycle        8,485\n",
      "    Memory Throughput                   %         1.34\n",
      "    DRAM Throughput                     %         1.34\n",
      "    Duration                      usecond        14.24\n",
      "    L1/TEX Cache Throughput             %        29.59\n",
      "    L2 Cache Throughput                 %         0.55\n",
      "    SM Active Cycles                cycle       174.38\n",
      "    Compute (SM) Throughput             %         0.61\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        27.97\n",
      "    Achieved Active Warps Per SM           warp         8.95\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 72.03%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (28.0%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  cumulatedDegreeUpdateTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned long long) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.98\n",
      "    SM Frequency            cycle/usecond       583.64\n",
      "    Elapsed Cycles                  cycle       44,133\n",
      "    Memory Throughput                   %         0.78\n",
      "    DRAM Throughput                     %         0.78\n",
      "    Duration                      usecond        75.62\n",
      "    L1/TEX Cache Throughput             %        30.25\n",
      "    L2 Cache Throughput                 %         0.25\n",
      "    SM Active Cycles                cycle     1,070.17\n",
      "    Compute (SM) Throughput             %         0.28\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        19.38\n",
      "    Achieved Active Warps Per SM           warp         6.20\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 80.62%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (19.4%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  graphContractionTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned long long, unsigned long long) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.93\n",
      "    SM Frequency            cycle/usecond       577.22\n",
      "    Elapsed Cycles                  cycle      164,110\n",
      "    Memory Throughput                   %         0.58\n",
      "    DRAM Throughput                     %         0.58\n",
      "    Duration                      usecond       284.29\n",
      "    L1/TEX Cache Throughput             %        22.59\n",
      "    L2 Cache Throughput                 %         0.52\n",
      "    SM Active Cycles                cycle     4,116.77\n",
      "    Compute (SM) Throughput             %         0.33\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        19.79\n",
      "    Achieved Active Warps Per SM           warp         6.33\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 80.21%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (19.8%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.99\n",
      "    SM Frequency            cycle/usecond       584.25\n",
      "    Elapsed Cycles                  cycle      190,420\n",
      "    Memory Throughput                   %         0.21\n",
      "    DRAM Throughput                     %         0.12\n",
      "    Duration                      usecond       325.92\n",
      "    L1/TEX Cache Throughput             %         8.28\n",
      "    L2 Cache Throughput                 %         0.03\n",
      "    SM Active Cycles                cycle     4,735.07\n",
      "    Compute (SM) Throughput             %         0.06\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         5.52\n",
      "    Achieved Active Warps Per SM           warp         1.77\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 94.48%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (5.5%) can be the result of warp scheduling overheads    \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.83\n",
      "    SM Frequency            cycle/usecond       563.76\n",
      "    Elapsed Cycles                  cycle        3,410\n",
      "    Memory Throughput                   %         0.53\n",
      "    DRAM Throughput                     %         0.53\n",
      "    Duration                      usecond         6.05\n",
      "    L1/TEX Cache Throughput             %        13.59\n",
      "    L2 Cache Throughput                 %         0.48\n",
      "    SM Active Cycles                cycle        56.12\n",
      "    Compute (SM) Throughput             %         0.13\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        40.42\n",
      "    Achieved Active Warps Per SM           warp        12.94\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 59.58%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (40.4%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.05\n",
      "    SM Frequency            cycle/usecond       589.70\n",
      "    Elapsed Cycles                  cycle        4,605\n",
      "    Memory Throughput                   %         0.47\n",
      "    DRAM Throughput                     %         0.47\n",
      "    Duration                      usecond         7.81\n",
      "    L1/TEX Cache Throughput             %        13.28\n",
      "    L2 Cache Throughput                 %         0.34\n",
      "    SM Active Cycles                cycle        83.60\n",
      "    Compute (SM) Throughput             %         0.24\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        30.17\n",
      "    Achieved Active Warps Per SM           warp         9.65\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 69.83%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (30.2%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  cumulatedDegreeUpdateTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned long long) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.99\n",
      "    SM Frequency            cycle/usecond       583.74\n",
      "    Elapsed Cycles                  cycle       42,534\n",
      "    Memory Throughput                   %         0.31\n",
      "    DRAM Throughput                     %         0.28\n",
      "    Duration                      usecond        72.86\n",
      "    L1/TEX Cache Throughput             %        12.62\n",
      "    L2 Cache Throughput                 %         0.12\n",
      "    SM Active Cycles                cycle     1,037.28\n",
      "    Compute (SM) Throughput             %         0.10\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         7.24\n",
      "    Achieved Active Warps Per SM           warp         2.32\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 92.76%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (7.2%) can be the result of warp scheduling overheads    \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  graphContractionTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned long long, unsigned long long) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.00\n",
      "    SM Frequency            cycle/usecond       584.92\n",
      "    Elapsed Cycles                  cycle      216,017\n",
      "    Memory Throughput                   %         0.16\n",
      "    DRAM Throughput                     %         0.16\n",
      "    Duration                      usecond       369.31\n",
      "    L1/TEX Cache Throughput             %         6.13\n",
      "    L2 Cache Throughput                 %         0.14\n",
      "    SM Active Cycles                cycle     5,375.23\n",
      "    Compute (SM) Throughput             %         0.10\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         5.52\n",
      "    Achieved Active Warps Per SM           warp         1.77\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 94.48%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (5.5%) can be the result of warp scheduling overheads    \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         5.00\n",
      "    SM Frequency            cycle/usecond       585.22\n",
      "    Elapsed Cycles                  cycle      180,965\n",
      "    Memory Throughput                   %         0.08\n",
      "    DRAM Throughput                     %         0.05\n",
      "    Duration                      usecond       309.22\n",
      "    L1/TEX Cache Throughput             %         3.06\n",
      "    L2 Cache Throughput                 %         0.02\n",
      "    SM Active Cycles                cycle     4,492.27\n",
      "    Compute (SM) Throughput             %         0.05\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.56\n",
      "    Achieved Active Warps Per SM           warp         1.14\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 96.44%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (3.6%) can be the result of warp scheduling overheads    \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.80\n",
      "    SM Frequency            cycle/usecond       562.13\n",
      "    Elapsed Cycles                  cycle        3,346\n",
      "    Memory Throughput                   %         0.43\n",
      "    DRAM Throughput                     %         0.17\n",
      "    Duration                      usecond         5.95\n",
      "    L1/TEX Cache Throughput             %         8.65\n",
      "    L2 Cache Throughput                 %         0.43\n",
      "    SM Active Cycles                cycle        53.48\n",
      "    Compute (SM) Throughput             %         0.12\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        40.03\n",
      "    Achieved Active Warps Per SM           warp        12.81\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 59.97%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (40.0%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.87\n",
      "    SM Frequency            cycle/usecond       568.77\n",
      "    Elapsed Cycles                  cycle        4,878\n",
      "    Memory Throughput                   %         0.30\n",
      "    DRAM Throughput                     %         0.17\n",
      "    Duration                      usecond         8.58\n",
      "    L1/TEX Cache Throughput             %         8.96\n",
      "    L2 Cache Throughput                 %         0.30\n",
      "    SM Active Cycles                cycle        91.47\n",
      "    Compute (SM) Throughput             %         0.17\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        24.38\n",
      "    Achieved Active Warps Per SM           warp         7.80\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 75.62%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (24.4%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  cumulatedDegreeUpdateTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned long long) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.98\n",
      "    SM Frequency            cycle/usecond       583.11\n",
      "    Elapsed Cycles                  cycle       49,487\n",
      "    Memory Throughput                   %         0.10\n",
      "    DRAM Throughput                     %         0.09\n",
      "    Duration                      usecond        84.86\n",
      "    L1/TEX Cache Throughput             %         3.98\n",
      "    L2 Cache Throughput                 %         0.07\n",
      "    SM Active Cycles                cycle     1,205.42\n",
      "    Compute (SM) Throughput             %         0.07\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         4.74\n",
      "    Achieved Active Warps Per SM           warp         1.52\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 95.26%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (4.7%) can be the result of warp scheduling overheads    \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  graphContractionTexture(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned long long, unsigned long long) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.99\n",
      "    SM Frequency            cycle/usecond       584.46\n",
      "    Elapsed Cycles                  cycle      117,211\n",
      "    Memory Throughput                   %         0.05\n",
      "    DRAM Throughput                     %         0.05\n",
      "    Duration                      usecond       200.54\n",
      "    L1/TEX Cache Throughput             %         1.98\n",
      "    L2 Cache Throughput                 %         0.05\n",
      "    SM Active Cycles                cycle     2,902.80\n",
      "    Compute (SM) Throughput             %         0.05\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.79\n",
      "    Achieved Active Warps Per SM           warp         1.21\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 96.21%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (3.8%) can be the result of warp scheduling overheads    \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  findCheapestTexture(GraphStruct *, unsigned int *, unsigned long long, unsigned long long) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.93\n",
      "    SM Frequency            cycle/usecond       577.37\n",
      "    Elapsed Cycles                  cycle       16,832\n",
      "    Memory Throughput                   %         0.12\n",
      "    DRAM Throughput                     %         0.03\n",
      "    Duration                      usecond        29.15\n",
      "    L1/TEX Cache Throughput             %         1.73\n",
      "    L2 Cache Throughput                 %         0.12\n",
      "    SM Active Cycles                cycle       392.70\n",
      "    Compute (SM) Throughput             %         0.05\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         8.08\n",
      "    Achieved Active Warps Per SM           warp         2.58\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 91.92%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (8.1%) can be the result of warp scheduling overheads    \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  mirroredEdgesRemoval(GraphStruct *, unsigned int *, unsigned long long *) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.84\n",
      "    SM Frequency            cycle/usecond       563.75\n",
      "    Elapsed Cycles                  cycle        3,248\n",
      "    Memory Throughput                   %         0.39\n",
      "    DRAM Throughput                     %         0.08\n",
      "    Duration                      usecond         5.76\n",
      "    L1/TEX Cache Throughput             %         7.76\n",
      "    L2 Cache Throughput                 %         0.39\n",
      "    SM Active Cycles                cycle        54.10\n",
      "    Compute (SM) Throughput             %         0.12\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        40.64\n",
      "    Achieved Active Warps Per SM           warp        13.00\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 59.36%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (40.6%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "  colorationProcess(GraphStruct *, unsigned int *, unsigned int *) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         4.82\n",
      "    SM Frequency            cycle/usecond       563.02\n",
      "    Elapsed Cycles                  cycle        3,496\n",
      "    Memory Throughput                   %         0.42\n",
      "    DRAM Throughput                     %         0.12\n",
      "    Duration                      usecond         6.21\n",
      "    L1/TEX Cache Throughput             %         8.59\n",
      "    L2 Cache Throughput                 %         0.42\n",
      "    SM Active Cycles                cycle        58.80\n",
      "    Compute (SM) Throughput             %         0.14\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                 1,024\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              24\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    Threads                                   thread           1,024\n",
      "    Waves Per SM                                                0.03\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Estimated Speedup: 97.5%                                                                                      \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            2\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            1\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        36.24\n",
      "    Achieved Active Warps Per SM           warp        11.60\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Estimated Speedup: 63.76%                                                                                     \n",
      "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
      "          theoretical (100.0%) and measured achieved occupancy (36.2%) can be the result of warp scheduling overheads   \n",
      "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
      "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
      "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ncu ./mstGPUETex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXKSm3Dbn1ja"
   },
   "source": [
    "# RELEASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s07dyEM-n3g0"
   },
   "source": [
    "# CPU CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ttRwu7Bx3og"
   },
   "source": [
    "## Prim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definizione MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nr0tpOgXeTAs"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"mst.h\" --group \"CPU\"\n",
    "\n",
    "#ifndef MST_H\n",
    "#define MST_H\n",
    "\n",
    "// Header file di C++\n",
    "#include <vector>\n",
    "\n",
    "struct mst {\n",
    "    std::vector<int> *stree;\n",
    "    long int totalWeight;\n",
    "\n",
    "    mst() {\n",
    "        stree = NULL;\n",
    "        totalWeight = 0;\n",
    "    }\n",
    "\n",
    "    ~mst() {\n",
    "        if (stree != NULL) {\n",
    "            delete[] stree;\n",
    "        }\n",
    "        stree = NULL;\n",
    "        totalWeight = 0;\n",
    "    }\n",
    "};\n",
    "\n",
    "#endif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definizione Heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eAjIA8eMsyM"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"heap.h\" --group \"CPU\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <vector>\n",
    "\n",
    "// Header file custom\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "#ifndef HEAP_H\n",
    "#define HEAP_H\n",
    "\n",
    "struct edge {\n",
    "    edge () {\n",
    "        source = UINT_MAX;\n",
    "        destination = UINT_MAX;\n",
    "        offset = UINT_MAX;\n",
    "        weight = INT_MAX;\n",
    "    }\n",
    "\n",
    "    ~edge () {\n",
    "        source = UINT_MAX;\n",
    "        destination = UINT_MAX;\n",
    "        offset = UINT_MAX;\n",
    "        weight = INT_MAX;\n",
    "    }\n",
    "\n",
    "    edge (uint source, uint destination, uint offset, int weight) {\n",
    "        this->source = source;\n",
    "        this->destination = destination;\n",
    "        this->offset = offset;\n",
    "        this->weight = weight;\n",
    "    }\n",
    "\n",
    "    bool operator<(const edge& other) const {\n",
    "        if (this->weight == other.weight) {\n",
    "            return this->destination < other.destination;\n",
    "        }\n",
    "        return this->weight < other.weight;\n",
    "    }\n",
    "\n",
    "    bool operator>(const edge& other) const {\n",
    "        if (this->weight == other.weight) {\n",
    "            return this->destination > other.destination;\n",
    "        }\n",
    "        return this->weight > other.weight;\n",
    "    }\n",
    "\n",
    "    uint source, destination, offset;\n",
    "    int weight;\n",
    "};\n",
    "\n",
    "class Heap {\n",
    "    public:\n",
    "        Heap () {\n",
    "            size = 0;\n",
    "            map = NULL;\n",
    "        }\n",
    "\n",
    "        Heap (uint size) {\n",
    "            mapSize = size;\n",
    "            map = new uint[mapSize];\n",
    "            for (uint i = 0; i < mapSize; i++) {\n",
    "                map[i] = UINT_MAX;\n",
    "            }\n",
    "            this->size = 0;\n",
    "        }\n",
    "\n",
    "        ~Heap () {\n",
    "            delete[] map;\n",
    "            map = NULL;\n",
    "        }\n",
    "\n",
    "        uint getLeftChild (uint index) {\n",
    "            return 2 * index + 1;\n",
    "        }\n",
    "\n",
    "        uint getRightChild (uint index) {\n",
    "            return 2 * index + 2;\n",
    "        }\n",
    "\n",
    "        uint getParent (uint index) {\n",
    "            return (index - 1) / 2;\n",
    "        }\n",
    "\n",
    "        edge getKey (uint index) {\n",
    "            return heap[index];\n",
    "        }\n",
    "\n",
    "        uint getPosition (uint key) {\n",
    "            return map[key];\n",
    "        }\n",
    "\n",
    "        void insert (uint source, uint destination, uint offset, int weight) {\n",
    "            // Insert the new edge\n",
    "            edge newEdge = edge(source, destination, offset, weight);\n",
    "            heap.push_back(newEdge);\n",
    "            size++;\n",
    "\n",
    "            map[destination] = size - 1;\n",
    "\n",
    "            uint i = size - 1;\n",
    "            while (i > 0 && heap[getParent(i)] > heap[i]) {\n",
    "                swap(heap[i], heap[getParent(i)]);\n",
    "                swap(map[heap[i].destination], map[heap[getParent(i)].destination]);\n",
    "                i = getParent(i);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        void heapify (uint subtree) {\n",
    "            uint left = getLeftChild(subtree);\n",
    "            uint right = getRightChild(subtree);\n",
    "            uint minimum = subtree;\n",
    "\n",
    "            if (left < size && heap[left] < heap[minimum]) {\n",
    "                minimum = left;\n",
    "            }\n",
    "\n",
    "            if (right < size && heap[right] < heap[minimum]) {\n",
    "                minimum = right;\n",
    "            }\n",
    "\n",
    "            if (minimum != subtree) {\n",
    "                swap(heap[subtree], heap[minimum]);\n",
    "                swap(map[heap[subtree].destination], map[heap[minimum].destination]);\n",
    "\n",
    "                heapify(minimum);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        void print() {\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"(\" << heap[i].source << \", \" << heap[i].destination << \")[\" << heap[i].weight << \"]\" << endl;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        void printMap() {\n",
    "            for (uint i = 0; i < mapSize; i++) {\n",
    "                cout << i << \", \" << map[i] << endl;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        edge peek() {\n",
    "            return heap[0];\n",
    "        }\n",
    "\n",
    "        edge pop() {\n",
    "            edge min;\n",
    "            if (size == 0) {\n",
    "                return min;\n",
    "            }\n",
    "\n",
    "            swap(heap[0], heap[size - 1]);\n",
    "            swap(map[heap[0].destination], map[heap[size - 1].destination]);\n",
    "            min = heap[size - 1];\n",
    "\n",
    "            heap.erase(heap.end());\n",
    "            map[min.destination] = UINT_MAX;\n",
    "            size--;\n",
    "\n",
    "            if (size == 0) {\n",
    "                return min;\n",
    "            }\n",
    "\n",
    "            heapify(0);\n",
    "            return min;\n",
    "        }\n",
    "\n",
    "        bool isEmpty() {\n",
    "            if (size == 0) {\n",
    "                return true;\n",
    "            }\n",
    "            return false;\n",
    "        }\n",
    "\n",
    "        void keyDecrease(uint i, uint source, int weight) {\n",
    "            heap[i].weight = weight;\n",
    "            heap[i].source = source;\n",
    "\n",
    "            while (i > 0 && heap[getParent(i)] > heap[i]) {\n",
    "                swap(heap[i], heap[getParent(i)]);\n",
    "                swap(map[heap[i].destination], map[heap[getParent(i)].destination]);\n",
    "                i = getParent(i);\n",
    "            }\n",
    "        }\n",
    "\n",
    "    private:\n",
    "        uint size, mapSize;\n",
    "        uint *map;\n",
    "        vector<edge> heap;\n",
    "};\n",
    "\n",
    "#endif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prim MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjPq8Y4QuL2M"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"CPUEfficientMst.cu\" --group \"CPU\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "#include <string>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <limits.h>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "#include \"../COMMON/readGraph.h\"\n",
    "#include \"mst.h\"\n",
    "#include \"heap.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "mst *primMST (uint size, default_random_engine &eng, GraphStruct *str) {\n",
    "    // Setup the mst\n",
    "    mst *tree = new mst();\n",
    "    tree->stree = new vector<int>[size];\n",
    "    tree->totalWeight = 0;\n",
    "\n",
    "    // Select a starting node\n",
    "    vector<node> Remaining;\n",
    "    uniform_real_distribution<> randR(0.0, 1.0);\n",
    "    node randV;\n",
    "    randV = (node)(randR(eng) * size);\n",
    "    cout << \"Source for the MST: \" << randV << endl;\n",
    "\n",
    "    // Initializing the heap structure\n",
    "    Heap *heap = new Heap(size);\n",
    "    for (int i = 0; i < size; ++i) {\n",
    "        int offset = str->isNeighbor(randV, i);\n",
    "        if (offset >= 0) {\n",
    "            heap->insert(randV, i, offset, str->getWeight(randV, offset));\n",
    "        }\n",
    "        else if (i != randV) {\n",
    "            heap->insert(UINT_MAX, i, UINT_MAX, INT_MAX);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // While the heap is not empty\n",
    "    while (!heap->isEmpty()) {\n",
    "        edge candidateEdge = heap->pop();\n",
    "        node destinationCandidate = candidateEdge.destination;\n",
    "\n",
    "        for (uint i = 0; i < str->deg(destinationCandidate); i++) {\n",
    "            node neigh = str->getNeigh(destinationCandidate, i);\n",
    "            node weight = str->getWeight(destinationCandidate, i);\n",
    "            uint pos = heap->getPosition(neigh);\n",
    "            bool inMst = false;\n",
    "\n",
    "            if (pos == UINT_MAX) {\n",
    "                inMst = true;\n",
    "            }\n",
    "\n",
    "            if (!inMst && weight < heap->getKey(pos).weight) {\n",
    "                heap->keyDecrease(pos, destinationCandidate, weight);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Add the newfound edge to the mst\n",
    "        tree->totalWeight += candidateEdge.weight;\n",
    "        tree->stree[candidateEdge.source].push_back(candidateEdge.destination);\n",
    "    }\n",
    "\n",
    "    delete heap;\n",
    "    heap = NULL;\n",
    "\n",
    "    return tree;\n",
    "}\n",
    "\n",
    "int main () {\n",
    "    // Generation of a random graph\n",
    "    std::random_device rd;\n",
    "    std::default_random_engine fixedEng(FIXED_SEED);\n",
    "    std::default_random_engine variableEng(rd());\n",
    "    Graph *graph;\n",
    "    uint size = SIZE;\n",
    "    uint maxWeight = MAX_WEIGHT;\n",
    "    float prob = PROBABILITY;\n",
    "    bool GPUEnabled = 0;\n",
    "\n",
    "    // events to measure time\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    // Call to the Prim MST solver\n",
    "    if (TESTING) {\n",
    "        string path(TEST);\n",
    "        printf(\"Generating graph from file\\n\");\n",
    "        graph = rgraph(path, false);\n",
    "    }\n",
    "    else {\n",
    "        graph = new Graph(size, GPUEnabled);\n",
    "        graph->randGraph(prob, true, maxWeight, fixedEng);\n",
    "    }\n",
    "\n",
    "    GraphStruct *str = graph->getStruct();\n",
    "    size = str->nodeSize;\n",
    "\n",
    "    // Test the printing procedure\n",
    "    if (size < 15) {\n",
    "        cout << \"Printing the graph\" << endl;\n",
    "        graph->print(true);\n",
    "    }\n",
    "    cout << \"Computing the MST solution for a graph containing \" << size << \" nodes and \" << str->edgeSize << endl;\n",
    "\n",
    "    double go = seconds();\n",
    "    mst *tree = primMST(size, variableEng, str);\n",
    "    float CPUtime = seconds() - go;\n",
    "    cout << \"Time elapsed for CPU computation: \" << CPUtime << endl;\n",
    "    cout << \"Total weight: \" << tree->totalWeight << endl;\n",
    "    cout << \"\\n\\n\\n\\n\";\n",
    "\n",
    "    string path(LOGPATH + string(\"cpu\"));\n",
    "\n",
    "    ofstream logfile(path, ios_base::app);\n",
    "\n",
    "    if (logfile.is_open()){\n",
    "        cout << \"Writing to file \" << path << endl;\n",
    "        logfile << tree->totalWeight << \"\\n\" << CPUtime << \"\\n\";\n",
    "        logfile.close();\n",
    "    }\n",
    "    else {\n",
    "        cout << \"Unable to open file\";\n",
    "    }\n",
    "\n",
    "    // Memory deallocation\n",
    "    delete graph;\n",
    "    delete tree;\n",
    "    tree = NULL;\n",
    "    graph = NULL;\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urv_sqyZ07NV",
    "outputId": "f0be3fdf-4669-4174-e98b-eff2277d3941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating graph from file\n",
      "264346\t733846\n",
      "Closing the file and freeing memory\n",
      "Computing the MST solution for a graph containing 264346 nodes and 733846\n",
      "Source for the MST: 45539\n",
      "Time elapsed for CPU computation: 0.697397\n",
      "Total weight: 261159288\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Writing to file /content/result_cpu\n"
     ]
    }
   ],
   "source": [
    "# Compilazione ed esecuzione\n",
    "# CPU\n",
    "!nvcc -arch=sm_75  GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/COMMON/readGraph.cu src/CPU/CPUEfficientMst.cu -o CPUEfficientMst\n",
    "!./CPUEfficientMst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIcBAaOzRfVK"
   },
   "source": [
    "## Boruvka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gn7T4pjVRg3j"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"bka.cu\" --group \"TESTING\"\n",
    "#include \"../COMMON/readGraph.h\"\n",
    "\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "#include <limits>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "struct Subset {\n",
    "    int parent, rank;\n",
    "};\n",
    "\n",
    "// Find the root of the node 'i' with path compression\n",
    "int find(vector<Subset>& subsets, int i) {\n",
    "    if (subsets[i].parent != i) {\n",
    "        subsets[i].parent = find(subsets, subsets[i].parent);\n",
    "    }\n",
    "    return subsets[i].parent;\n",
    "}\n",
    "\n",
    "// Union of two subsets by rank\n",
    "void unionSets(vector<Subset>& subsets, int u, int v) {\n",
    "    int rootU = find(subsets, u);\n",
    "    int rootV = find(subsets, v);\n",
    "\n",
    "    if (subsets[rootU].rank < subsets[rootV].rank) {\n",
    "        subsets[rootU].parent = rootV;\n",
    "    } else if (subsets[rootU].rank > subsets[rootV].rank) {\n",
    "        subsets[rootV].parent = rootU;\n",
    "    } else {\n",
    "        subsets[rootV].parent = rootU;\n",
    "        subsets[rootU].rank++;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Borvka's Algorithm to find MST\n",
    "unsigned long long int boruvkaMST(int V, vector<Edge> edges) {\n",
    "    vector<Subset> subsets(V);\n",
    "    for (int v = 0; v < V; v++) {\n",
    "        subsets[v].parent = v;\n",
    "        subsets[v].rank = 0;\n",
    "    }\n",
    "\n",
    "    unsigned long long int mstWeight = 0;\n",
    "    int numComponents = V;\n",
    "\n",
    "    while (numComponents > 1) {\n",
    "        vector<int> cheapest(V, -1);\n",
    "\n",
    "        // Find cheapest edge for each component\n",
    "        for (int i = 0; i < edges.size(); i++) {\n",
    "            int u = edges[i].src;\n",
    "            int v = edges[i].dest;\n",
    "            int weight = edges[i].weight;\n",
    "            int setU = find(subsets, u);\n",
    "            int setV = find(subsets, v);\n",
    "\n",
    "            if (setU != setV) {\n",
    "                if (cheapest[setU] == -1 || edges[cheapest[setU]].weight > weight) {\n",
    "                    cheapest[setU] = i;\n",
    "                }\n",
    "                if (cheapest[setV] == -1 || edges[cheapest[setV]].weight > weight) {\n",
    "                    cheapest[setV] = i;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Add the selected edges to the MST\n",
    "        for (int i = 0; i < V; i++) {\n",
    "            if (cheapest[i] != -1) {\n",
    "                int u = edges[cheapest[i]].src;\n",
    "                int v = edges[cheapest[i]].dest;\n",
    "                int setU = find(subsets, u);\n",
    "                int setV = find(subsets, v);\n",
    "\n",
    "                if (setU != setV) {\n",
    "                    mstWeight += edges[cheapest[i]].weight;\n",
    "                    unionSets(subsets, setU, setV);\n",
    "                    numComponents--;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Print the MST\n",
    "    cout << \"Minimum Spanning Tree weight: \" << mstWeight << endl;\n",
    "    return mstWeight;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    CPUGraph *graph;\n",
    "\n",
    "    // Generation of the graph\n",
    "    if (TESTING) {\n",
    "        string path(TEST);\n",
    "        printf(\"Generating graph from file\\n\");\n",
    "        graph = rgraphCPU(path);\n",
    "    }\n",
    "    else {\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    double go = seconds();\n",
    "    unsigned long long int weight = boruvkaMST(graph->nodeSize, graph->edges);\n",
    "    float CPUtime = seconds() - go;\n",
    "    cout << \"Time elapsed for CPU computation: \" << CPUtime << endl;\n",
    "    cout << \"\\n\\n\\n\\n\";\n",
    "\n",
    "    string path(LOGPATH + string(\"bka\"));\n",
    "\n",
    "    ofstream logfile(path, ios_base::app);\n",
    "\n",
    "    if (logfile.is_open()){\n",
    "        cout << \"Writing to file \" << path << endl;\n",
    "        logfile << weight << \"\\n\" << CPUtime << \"\\n\";\n",
    "        logfile.close();\n",
    "    }\n",
    "    else {\n",
    "        cout << \"Unable to open file\";\n",
    "    }\n",
    "\n",
    "    delete graph;\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFnSB5fyRqbQ",
    "outputId": "4763051e-7e7b-4fcc-abbb-2a87b54ceff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating graph from file\n",
      "Closing the file and freeing memory\n",
      "Minimum Spanning Tree weight: 6492121041\n",
      "Time elapsed for CPU computation: 7.41779\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Writing to file /content/result_bka\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_75  GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/COMMON/readGraph.cu src/TESTING/bka.cu -o test\n",
    "!./test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v59BY4C1n5jH"
   },
   "source": [
    "# GPU CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "io-LW2esLlMF"
   },
   "outputs": [],
   "source": [
    "%%cuda_group_save --name \"mstGPU.cu\" --group \"GPU\"\n",
    "\n",
    "// Header file di C++\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "#include <fstream>\n",
    "#include <string>\n",
    "\n",
    "// Header file C\n",
    "#include <time.h>\n",
    "#include <limits.h>\n",
    "\n",
    "// Custom files\n",
    "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
    "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
    "#include \"../../GPUcomputing/utils/common.h\"\n",
    "#include \"../COMMON/sharedMacros.h\"\n",
    "#include \"../COMMON/readGraph.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "/*****\n",
    "* Device function that gets the degree of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The node we are interested in\n",
    "*****/\n",
    "__device__ node d_deg (GraphStruct *str, node i) {\n",
    "    return str->cumDegs[i + 1] - str->cumDegs[i];\n",
    "}\n",
    "\n",
    "/*****\n",
    "* Device function that gets the weight of a certain edge\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ int d_getWeight (GraphStruct *str, node i, uint offset) {\n",
    "    return str->weights[str->cumDegs[i] + offset];\n",
    "\n",
    "/*****\n",
    "* Device function that gets the neighbour of a certain node\n",
    "* @param str - The structure of the graph\n",
    "* @param i - The source node of the edge\n",
    "* @param offset - The offset of the destination node in the adjacency list of\n",
    "*                 the source\n",
    "*****/\n",
    "__device__ node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
    "    return str->neighs[str->cumDegs[i] + offset];\n",
    "}\n",
    "\n",
    "__device__ uint d_getRoot (uint i, uint *d_flag, uint *d_colors) {\n",
    "    return max(0, d_flag[d_colors[i]]);\n",
    "}\n",
    "\n",
    "uint getRoot (uint i, uint *flag, uint *colors) {\n",
    "    return max(0, flag[colors[i]]);\n",
    "}\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that finds the cheapest edge in the adjacency list of every node\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "*****/\n",
    "__global__ void findCheapest (GraphStruct *str, uint *d_candidates) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    // Initialize the minimum value\n",
    "    uint minimum = UINT_MAX;\n",
    "    int minimumWeight = INT_MAX;\n",
    "}\n",
    "\n",
    "    // Find the cheapest edge in each adjacency list\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        int edgeWeight = d_getWeight(str, idx, i);\n",
    "        if (edgeWeight < minimumWeight) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "        else if (edgeWeight == minimumWeight &&\n",
    "                 d_getNeigh(str, idx, i) < d_getNeigh(str, idx, minimum)) {\n",
    "            minimumWeight = edgeWeight;\n",
    "            minimum = i;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Update the return vector\n",
    "    d_candidates[idx] = minimum;\n",
    "}\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that removes the mirrored edges from the graph. A mirrored edge is\n",
    "* simply an edge pointing from the source to the destination and vice versa in\n",
    "* an oriented graph, the removal logic is to cut the edge with the lowest source\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "*****/\n",
    "__global__ void mirroredEdgesRemoval (GraphStruct *str, uint *d_candidates, unsigned long long int *d_weight) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint destinationOffset = d_candidates[idx];\n",
    "    node destination = d_getNeigh(str, idx, destinationOffset);\n",
    "    if (idx < destination) {\n",
    "        uint sourceOffset = d_candidates[destination];\n",
    "        node destinationNeigh = d_getNeigh(str, destination, sourceOffset);\n",
    "\n",
    "        // The vertex cannot be a candidate anymore because it would create a cycle\n",
    "        if (destinationNeigh == idx) {\n",
    "            d_candidates[idx] = UINT_MAX;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (d_candidates[idx] != UINT_MAX) {\n",
    "        atomicAdd(d_weight, d_getWeight(str, idx, d_candidates[idx]));\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "/*****\n",
    "* Helper device function that recursively colors the nodes of the graph\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree (edges saved as offsets in the CSR\n",
    "*                       representation of the graph)\n",
    "* @param i - The index of the node to be colored\n",
    "* @param d_colors - The device-level array of colors assigned to each vertex\n",
    "*****/\n",
    "__device__ uint *d_recursiveColorationHelper (GraphStruct *str, uint *d_candidates, node i, uint *d_colors) {\n",
    "    uint color = UINT_MAX;\n",
    "    if (d_candidates[i] == UINT_MAX) {\n",
    "        color = i;\n",
    "    }\n",
    "    else {\n",
    "        node neigh = d_getNeigh(str, i, d_candidates[i]);\n",
    "        color = d_recursiveColorationHelper(str, d_candidates, neigh, d_colors)[neigh];\n",
    "    }\n",
    "\n",
    "    if (color != UINT_MAX) {\n",
    "        d_colors[i] = color;\n",
    "    }\n",
    "    return d_colors;\n",
    "}\n",
    "\n",
    "\n",
    "/*****\n",
    "* Kernel that recognizes the connected components in the graph and colors them\n",
    "* @param str - The structure of the graph\n",
    "* @param d_candidates - The device-level array of candidates to become part of\n",
    "*                       the spanning tree\n",
    "* @param d_colors - The device-level array of colors assigned to each vertex\n",
    "*****/\n",
    "__global__ void colorationProcess(GraphStruct *str, uint *d_candidates, uint *d_colors) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    d_recursiveColorationHelper(str, d_candidates, idx, d_colors);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "//*** SCAN FUNCTIONS ***//\n",
    "\n",
    "__global__ void prescan(uint *g_odata, uint *g_idata, uint *aux, int n, int smemSize)\n",
    "{\n",
    "  extern __shared__ int temp[];// allocated on invocation\n",
    "  int thid = threadIdx.x;\n",
    "  int offset = 1;\n",
    "  int idx = blockIdx.x * blockDim.x + thid;\n",
    "\n",
    "  // load input into shared memory\n",
    "  temp[2 * thid] =  (2 * idx < n) ? g_idata[2 * idx] : 0;\n",
    "  temp[2 * thid + 1] = (2 * idx + 1 < n) ? g_idata[2 * idx + 1] : 0;\n",
    "\n",
    "  for (int d =smemSize>>1; d > 0; d >>= 1) // build sum in place up the tree\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        temp[bi] += temp[ai];\n",
    "      }\n",
    "    }\n",
    "    offset *= 2;\n",
    "  }\n",
    "\n",
    "  if (thid == 0)\n",
    "  {\n",
    "    aux[blockIdx.x] = temp[smemSize - 1];\n",
    "    temp[smemSize - 1] = 0;\n",
    "  }\n",
    "\n",
    "  for (int d = 1; d < smemSize; d *= 2) // traverse down tree & build scan\n",
    "  {\n",
    "      offset >>= 1;\n",
    "    __syncthreads();\n",
    "\n",
    "    if (thid < d)\n",
    "    {\n",
    "      int ai = offset * (2 * thid + 1) - 1;\n",
    "      int bi = offset * (2 * thid + 2) - 1;\n",
    "      if (bi < smemSize && ai < smemSize) {\n",
    "        int t = temp[ai];\n",
    "        temp[ai] = temp[bi];\n",
    "        temp[bi] += t;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "\n",
    "  __syncthreads();\n",
    "  if (idx <= (n / 2)) {\n",
    "      g_odata[2*idx] = temp[2*thid]; // write results to device memory\n",
    "      g_odata[2*idx+1] = temp[2*thid+1];\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "void cpuScan(uint *array, int start, int end) {\n",
    "    if (end - start <= 1) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    int temp = array[start + 1];\n",
    "    array[start + 1] = array[start];\n",
    "    array[start] = 0;\n",
    "\n",
    "    for (uint i = start + 1; i < end - 1; i++) {\n",
    "        int sum = array[i] + temp;\n",
    "        temp = array[i + 1];\n",
    "        array[i + 1] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void cfinal_sum(uint *g_odata, uint *aux, uint n)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "  if (blockIdx.x == 0 || 2 * idx >= n) {\n",
    "      return;\n",
    "  }\n",
    "\n",
    "  uint sum = 0;\n",
    "  for (uint i = 0; i < blockIdx.x; ++i) {\n",
    "      sum += aux[i];\n",
    "  }\n",
    "\n",
    "  if (2 * idx == n - 1) {\n",
    "      g_odata[2 * idx] += sum;\n",
    "      return;\n",
    "  }\n",
    "\n",
    "  g_odata[2 * idx] += sum;\n",
    "  g_odata[2 * idx + 1] += sum;\n",
    "}\n",
    "\n",
    "//****************//\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void cumulatedDegreeUpdate(GraphStruct *str, uint *d_cumDegs, uint *d_colors, uint *d_flag) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint color = d_colors[idx];\n",
    "    node svSuccessor = d_getRoot(idx, d_flag, d_colors);\n",
    "    uint sum = 0;\n",
    "\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        node neigh = d_getNeigh(str, idx, i);\n",
    "        uint neighColor = d_colors[neigh];\n",
    "\n",
    "        if (color != neighColor) {\n",
    "            sum++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    atomicAdd(&(d_cumDegs[svSuccessor]), sum);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void graphContraction(GraphStruct *str, uint *d_colors, uint *d_flag,\n",
    "                                 uint *d_cumDegs, node *d_newNeighs, uint *d_newWeights) {\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    uint color = d_colors[idx];\n",
    "    node superVertex = d_getRoot(idx, d_flag, d_colors);\n",
    "\n",
    "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
    "        node neigh = d_getNeigh(str, idx, i);\n",
    "        uint neighColor = d_colors[neigh];\n",
    "\n",
    "        if (color != neighColor) {\n",
    "            int weight = d_getWeight(str, idx, i);\n",
    "            uint position = atomicAdd(&(d_cumDegs[superVertex]), 1);\n",
    "            d_newNeighs[position] = d_getRoot(neigh, d_flag, d_colors);\n",
    "            d_newWeights[position] = weight;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__global__ void svIdentification (GraphStruct *str, uint *d_colors, uint *d_candidates, uint *d_flag) {\n",
    "    // Initialize one thread per node\n",
    "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // If the index is out of bounds returns immediately\n",
    "    if (idx >= str->nodeSize) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    if (d_colors[idx] == idx) {\n",
    "        d_flag[idx] = 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "int main () {\n",
    "    // Generation of a random graph\n",
    "    std::random_device rd;\n",
    "    std::default_random_engine eng(FIXED_SEED);\n",
    "    uint maxWeight = MAX_WEIGHT;\n",
    "    float prob = .5;\n",
    "    bool GPUEnabled = 1;\n",
    "    Graph *graphPointer;\n",
    "\n",
    "    // Generation of the graph\n",
    "    if (TESTING) {\n",
    "        string path(TEST);\n",
    "        printf(\"Generating graph from file\\n\");\n",
    "        graphPointer = rgraph(path, true);\n",
    "    }\n",
    "    else {\n",
    "        graphPointer = new Graph(SIZE, GPUEnabled);\n",
    "        graphPointer->randGraph(prob, true, maxWeight, eng);\n",
    "\n",
    "        if (!graphPointer->isConnected()) {\n",
    "            cout << \"The graph is not connected\" << endl;\n",
    "            return -1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    uint iterations = 0;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    // Configuration of the GPU kernel\n",
    "    uint blockDim = BLOCK_SIZE;\n",
    "    uint *candidates;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    // Events to measure time\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    float milliseconds;\n",
    "    float spliTime = 0;\n",
    "    float totalTime = 0;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    // Variables calculating the MST weight\n",
    "    unsigned long long int mstWeight = 0;\n",
    "    unsigned long long int *d_mstWeight;\n",
    "    CHECK(cudaMalloc((void **)&d_mstWeight, sizeof(unsigned long long int)));\n",
    "    CHECK(cudaMemcpy(d_mstWeight, &mstWeight, sizeof(unsigned long long int), cudaMemcpyHostToDevice));\n",
    "\n",
    "\n",
    "    // Main block of the algorithm\n",
    "    while (graphPointer->getStruct()->nodeSize > 1) {\n",
    "        // Initialization of the variables associated with the graph\n",
    "        GraphStruct *str = graphPointer->getStruct();\n",
    "        uint size = str->nodeSize;\n",
    "        uint edgeSize = str->edgeSize;\n",
    "        cout << \"Processing a graph of size: \" << size << \" with \" << edgeSize << \" edges.\\n\\n\";\n",
    "        uint gridDim = (size + blockDim - 1) / blockDim;\n",
    "        if (DEBUGGING && size < 15 && str->edgeSize < 100) {\n",
    "            graphPointer->print(true);\n",
    "            print_d<<<1, 1>>>(str, 1);\n",
    "            CHECK(cudaDeviceSynchronize());\n",
    "        }\n",
    "        candidates = new uint[size];\n",
    "\n",
    "\n",
    "\n",
    "        // First setp of the algorithm\n",
    "        uint *d_candidates;\n",
    "        CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
    "        cout << \"Launching kernel FIND CHEAPEST -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        findCheapest<<<gridDim, blockDim>>>(str, d_candidates);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // ~Debugging~ print the cheapest edge for every vertex\n",
    "        if (DEBUGGING && size < 15) {\n",
    "            cout << \"The cheapest edge for every vertex\" << endl;\n",
    "            CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"node (\" << i << \") -> \" << str->getNeigh(i, candidates[i]) << \"(\"\n",
    "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
    "            }\n",
    "            cout << \"\\n\\n\\n\";\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        // Second step of the algorithm\n",
    "        cout << \"Launching kernel MIRRORED EDGES REMOVAL -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        mirroredEdgesRemoval<<<gridDim, blockDim>>>(str, d_candidates, d_mstWeight);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        CHECK(cudaMemcpy(&mstWeight, d_mstWeight, sizeof(unsigned long long int), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // ~Debugging~ print the cheapest edge for every vertex update\n",
    "        if (DEBUGGING && size < 15) {\n",
    "            cout << \"Update of the cheapest edge for every vertex\" << endl;\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                cout << \"node (\" << i << \") -> \";\n",
    "                if (candidates[i] != UINT_MAX) {\n",
    "                    cout << str->getNeigh(i, candidates[i]) << \"(\"\n",
    "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
    "                }\n",
    "                else {\n",
    "                    cout << \"NULL\" << endl;\n",
    "                }\n",
    "            }\n",
    "            printf (\"%llu\\n\", mstWeight);\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        cout << \"The MST weight at the end of iteration \" << iterations + 1 << \" is: \" << mstWeight << endl;\n",
    "\n",
    "\n",
    "\n",
    "        // Third step of the algorithm\n",
    "        cout << \"Launching kernel COLORATION PROCESS -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "\n",
    "        // Initialize the color array\n",
    "        uint *colors = new uint[size];\n",
    "        uint *d_colors;\n",
    "        CHECK(cudaMalloc((void**)&d_colors, size * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_colors, UINT_MAX, size * sizeof(uint)));\n",
    "\n",
    "\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        colorationProcess<<<gridDim, blockDim>>>(str, d_candidates, d_colors);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaMemcpy(colors, d_colors, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Print the coloring\n",
    "        if (DEBUGGING) {\n",
    "            uint *checkColoring = new uint[size];\n",
    "\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                checkColoring[i] = 0;\n",
    "            }\n",
    "\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                checkColoring[colors[i]]++;\n",
    "            }\n",
    "\n",
    "            uint nonZeroColors = 0;\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                if (checkColoring[i] != 0) {\n",
    "                    nonZeroColors++;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            cout << \"There is a total of \" << nonZeroColors << \" colors\" << endl;\n",
    "\n",
    "            cout << \"\\n\\n\\n\";\n",
    "\n",
    "            delete[] checkColoring;\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        /**\n",
    "         * If the coloring coming out of the last kernel contains only one color\n",
    "         * then it means that the edge added in the last step was the one needed\n",
    "         * to merge the partial trees\n",
    "         **/\n",
    "        uint color = colors[0];\n",
    "        bool uniqueColor = true;\n",
    "        for (uint i = 1; i < size; i++) {\n",
    "            if (colors[i] != color) {\n",
    "                uniqueColor = false;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "        if (uniqueColor) {\n",
    "            cout << \"THE CALCULATION OF THE MST IS COMPLETE\\n\";\n",
    "            cout << \"THE MST WEIGHT IS: \" << mstWeight << endl;\n",
    "            printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
    "\n",
    "            // Cuda event dealloc\n",
    "            CHECK(cudaEventDestroy(start));\n",
    "            CHECK(cudaEventDestroy(stop));\n",
    "\n",
    "            // Cuda memory deallocation\n",
    "            CHECK(cudaFree(d_candidates));\n",
    "            CHECK(cudaFree(d_colors));\n",
    "            CHECK(cudaFree(d_mstWeight));\n",
    "\n",
    "            // Host memory deallocation\n",
    "            delete[] candidates;\n",
    "            delete[] colors;\n",
    "            delete graphPointer;\n",
    "\n",
    "            if (TESTING) {\n",
    "                string path(LOGPATH + string(\"gpuU\"));\n",
    "\n",
    "                ofstream logfile(path, ios_base::app);\n",
    "\n",
    "                if (logfile.is_open()){\n",
    "                    cout << \"Writing to file \" << path << endl;\n",
    "                    logfile << mstWeight << \"\\n\" << totalTime << \"\\n\";\n",
    "                    logfile.close();\n",
    "                }\n",
    "                else {\n",
    "                    cout << \"Unable to open file\";\n",
    "                }\n",
    "            }\n",
    "\n",
    "            return 0;\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Fourth step of the algorithm\n",
    "        cout << \"Doing a round of scan on the flag vector, size: \" << size << endl;\n",
    "        uint *flag = new uint[size];\n",
    "        uint *cFlag = new uint[size];\n",
    "        uint *d_flag, *d_ogFlag;\n",
    "\n",
    "        // setup di d_ogFlag\n",
    "        CHECK(cudaMalloc((void**)&d_ogFlag, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_ogFlag, 0, (size) * sizeof(uint)));\n",
    "        cudaEventRecord(start);\n",
    "        svIdentification <<< gridDim, blockDim >>> (str, d_colors, d_candidates, d_ogFlag);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Building the flag array took:   %.5f seconds\\n\", spliTime);\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            CHECK(cudaMemcpy(cFlag, d_ogFlag, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        }\n",
    "\n",
    "        // SMEM kernel configuration\n",
    "        uint smemSize = 2 * blockDim;\n",
    "        uint smem = smemSize * sizeof(uint);\n",
    "        uint numSmemBlock = (size + smemSize - 1) / smemSize;\n",
    "\n",
    "        // Setup the auxiliary array\n",
    "        uint *aux, *d_aux;\n",
    "        aux = new uint[numSmemBlock];\n",
    "        CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_aux, 0, (numSmemBlock) * sizeof(uint)));\n",
    "\n",
    "        // Setup of the d_flag array\n",
    "        CHECK(cudaMalloc((void**)&d_flag, (size) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_flag, 0, (size) * sizeof(uint)));\n",
    "\n",
    "        printf(\"prescan procedure on the flag array of size: %d ...\\n\", size);\n",
    "        cudaEventRecord(start);\n",
    "        prescan <<<  numSmemBlock, blockDim, smem >>> (d_flag, d_ogFlag, d_aux, size, smemSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"The first prescan procedure took:   %.5f seconds\\n\", spliTime);\n",
    "\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        // Put everything together\n",
    "        printf(\"final summation procedure...\\n\");\n",
    "        cudaEventRecord(start);\n",
    "        cfinal_sum <<< gridDim, blockDim >>> (d_flag, d_aux, size);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"The final summation procedure took:   %.5f seconds\\n\\n\", spliTime);\n",
    "\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        CHECK(cudaMemcpy(flag, d_flag, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            cpuScan(cFlag, 0, size);\n",
    "\n",
    "            for (uint i = 0; i < size - 1; i++) {\n",
    "                if (cFlag[i] != flag[i]) {\n",
    "                    cout << \"I due array sono diversi in posizione \" << i << \"   \" << cFlag[i] << \"   \" << flag[i] << endl;\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            delete[] cFlag;\n",
    "        }\n",
    "        cout << \"The contracted graph will contain \" << flag[size - 1] << \" supervertices\\n\\n\" << endl;\n",
    "        // Spring Cleaning\n",
    "        delete[] (aux);\n",
    "        CHECK(cudaFree(d_aux));\n",
    "        CHECK(cudaFree(d_ogFlag));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Fifth step of the algorithm\n",
    "\n",
    "        // Allocating resources for the new cumulated degrees array\n",
    "        uint newNodeSize = flag[size - 1];\n",
    "        uint cumDegSize = newNodeSize + 1;\n",
    "        uint *cumDegs = new uint[cumDegSize];\n",
    "        uint *d_cumDegs;\n",
    "        CHECK(cudaMalloc((void**)&d_cumDegs, (cumDegSize) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
    "\n",
    "        cout << \"Launching kernel CUMULATED DEGREE UPDATE -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "\n",
    "        cudaEventRecord(start);\n",
    "        cumulatedDegreeUpdate<<<gridDim, blockDim>>>(str, d_cumDegs, d_colors, d_flag);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"Doing the computation of the cumulated degrees took: %.5f seconds\\n\\n\", spliTime);\n",
    "\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        CHECK(cudaMemcpy(cumDegs, d_cumDegs, cumDegSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Perform another prefix sum on the cumDegrees array\n",
    "        // Setup aux\n",
    "        aux = new uint[numSmemBlock];\n",
    "        CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock) * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_aux, 0, (numSmemBlock) * sizeof(uint)));\n",
    "\n",
    "        uint *cCumDegs;\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            cCumDegs = new uint[cumDegSize];\n",
    "            for (uint i = 0; i < cumDegSize; i++) {\n",
    "                cCumDegs[i] = cumDegs[i];\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Setup d_ogCumDegs\n",
    "        uint *d_ogCumDegs;\n",
    "        CHECK(cudaMalloc((void **) &d_ogCumDegs, cumDegSize * sizeof(uint)));\n",
    "        CHECK(cudaMemcpy(d_ogCumDegs, cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyHostToDevice));\n",
    "\n",
    "        printf(\"prescan procedure on the cumDegs array of size: %d ...\\n\", size);\n",
    "        cudaEventRecord(start);\n",
    "        prescan <<<  numSmemBlock, blockDim, smem >>> (d_cumDegs, d_ogCumDegs, d_aux, cumDegSize, smemSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"The first prescan procedure took:   %.5f seconds\\n\", spliTime);\n",
    "\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        // Put everything together\n",
    "        printf(\"final summation procedure...\\n\");\n",
    "        cudaEventRecord(start);\n",
    "        cfinal_sum <<< gridDim, blockDim >>> (d_cumDegs, d_aux, cumDegSize);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        CHECK(cudaGetLastError());\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"The final summation procedure took:   %.5f seconds\\n\\n\", spliTime);\n",
    "\n",
    "        totalTime += spliTime;\n",
    "\n",
    "        CHECK(cudaMemcpy(cumDegs, d_cumDegs, cumDegSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "        if (DEBUGGING) {\n",
    "            cpuScan(cCumDegs, 0, cumDegSize);\n",
    "\n",
    "            for (uint i = 0; i < cumDegSize - 1; i++) {\n",
    "                if (cCumDegs[i] != cumDegs[i]) {\n",
    "                    cout << \"I due array sono diversi in posizione \" << i << endl;\n",
    "                    cout << cCumDegs[i] << \"   \" << cumDegs[i];\n",
    "                    return -1;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        cout << \"The contracted graph will contain \" << cumDegs[cumDegSize - 1] << \" edges\" << endl;\n",
    "        cout << \"The old graph structure contained \" << str->edgeSize << \" edges\\n\\n\" << endl;\n",
    "\n",
    "        // Spring cleaning\n",
    "        free(aux);\n",
    "        CHECK(cudaFree(d_aux));\n",
    "        CHECK(cudaFree(d_ogCumDegs));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Allocating space for the arrays in the newly contracted graph\n",
    "        uint newEdgeSize = cumDegs[cumDegSize - 1];\n",
    "        node *newNeighs = new node[newEdgeSize];\n",
    "        uint *newWeights = new uint[newEdgeSize];\n",
    "\n",
    "        uint *d_newNeighs, *d_newWeights;\n",
    "        CHECK(cudaMalloc((void **)&d_newNeighs, newEdgeSize * sizeof(node)));\n",
    "        CHECK(cudaMalloc((void **)&d_newWeights, newEdgeSize * sizeof(uint)));\n",
    "        CHECK(cudaMemset(d_newNeighs, 0, newEdgeSize * sizeof(node)));\n",
    "        CHECK(cudaMemset(d_newWeights, 0, newEdgeSize * sizeof(uint)));\n",
    "\n",
    "        cout << \"Launching kernel GRAPH CONTRACTION -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
    "        cudaEventRecord(start);\n",
    "        graphContraction<<<gridDim, blockDim>>>(str, d_colors, d_flag, d_cumDegs, d_newNeighs, d_newWeights);\n",
    "        CHECK(cudaDeviceSynchronize());\n",
    "        CHECK(cudaEventRecord(stop));\n",
    "        CHECK(cudaEventSynchronize(stop));\n",
    "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "        spliTime = milliseconds / 1000.0;\n",
    "        printf(\"The contratcion of the new neighbour and weight arrays took: %.5f seconds\\n\\n\", spliTime);\n",
    "        CHECK(cudaMemcpy(newNeighs, d_newNeighs, newEdgeSize * sizeof(node), cudaMemcpyDeviceToHost));\n",
    "        CHECK(cudaMemcpy(newWeights, d_newWeights, newEdgeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        if (DEBUGGING) {\n",
    "            node *checkNewNeighs = new node[newEdgeSize];\n",
    "            uint *checkNewWeights = new uint[newEdgeSize];\n",
    "            // Copy the contents of cumDegs into a new array\n",
    "            for (uint i = 0; i < cumDegSize; i++) {\n",
    "                cCumDegs[i] = cumDegs[i];\n",
    "            }\n",
    "\n",
    "            cudaEventRecord(start);\n",
    "            for (uint i = 0; i < size; i++) {\n",
    "                uint color = colors[i];\n",
    "                node superVertex = getRoot(i, flag, colors);\n",
    "\n",
    "                for (uint j = 0; j < str->deg(i); j++) {\n",
    "                    node neigh = str->getNeigh(i, j);\n",
    "                    uint neighColor = colors[neigh];\n",
    "\n",
    "                    if (color != neighColor) {\n",
    "                        int weight = str->getWeight(i, j);\n",
    "                        uint position = cCumDegs[superVertex];\n",
    "                        checkNewNeighs[position] = getRoot(neigh, flag, colors);\n",
    "                        checkNewWeights[position] = weight;\n",
    "                        cCumDegs[superVertex]++;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            cout << \"I due array sono uguali\" << endl;\n",
    "            delete[] cCumDegs;\n",
    "            delete[] checkNewNeighs;\n",
    "            delete[] checkNewWeights;\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Reconstructing the graph\n",
    "        graphPointer->copyConstructor(newNodeSize, newEdgeSize, newNeighs, newWeights, cumDegs);\n",
    "\n",
    "        printf(\"----------------------------------\\n\\n\");\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Updating the iteration information\n",
    "        totalTime += spliTime;\n",
    "        iterations++;\n",
    "\n",
    "\n",
    "        // Cuda memory deallocation\n",
    "        CHECK(cudaFree(d_candidates));\n",
    "        CHECK(cudaFree(d_colors));\n",
    "        CHECK(cudaFree(d_flag));\n",
    "        CHECK(cudaFree(d_cumDegs));\n",
    "        CHECK(cudaFree(d_newNeighs));\n",
    "        CHECK(cudaFree(d_newWeights));\n",
    "\n",
    "\n",
    "\n",
    "        // Host memory deallocation\n",
    "        delete[] candidates;\n",
    "        delete[] colors;\n",
    "        delete[] flag;\n",
    "        delete[] cumDegs;\n",
    "        delete[] newNeighs;\n",
    "        delete[] newWeights;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "At2S3Eyn_lXx",
    "outputId": "49f2a241-519a-44ad-c8ca-f9d8b3eebab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptxas warning : Stack size for entry function '_Z17colorationProcessP11GraphStructPjS1_' cannot be statically determined\n",
      "Generating graph from file\n",
      "3598623\t8778114\n",
      "Closing the file and freeing memory\n",
      "Processing a graph of size: 3598623 with 8778114 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (3515, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.02367 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (3515, 1, 1)\n",
      "Removing the mirrored edges required: 0.00390 seconds\n",
      "\n",
      "The MST weight at the end of iteration 1 is: 3600959869\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (3515, 1, 1)\n",
      "Removing the mirrored edges required: 0.00472 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 3598623\n",
      "Building the flag array took:   0.00472 seconds\n",
      "prescan procedure on the flag array of size: 3598623 ...\n",
      "The first prescan procedure took:   0.00080 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00446 seconds\n",
      "\n",
      "The contracted graph will contain 1062154 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (3515, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00089 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 3598623 ...\n",
      "The first prescan procedure took:   0.00074 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00045 seconds\n",
      "\n",
      "The contracted graph will contain 3574292 edges\n",
      "The old graph structure contained 8778114 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONTRACTION -- (1024, 1, 1) -- (3515, 1, 1)\n",
      "The contratcion of the new neighbour and weight arrays took: 0.00230 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 1062154 with 3574292 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1038, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00825 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1038, 1, 1)\n",
      "Removing the mirrored edges required: 0.00117 seconds\n",
      "\n",
      "The MST weight at the end of iteration 2 is: 5382535889\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1038, 1, 1)\n",
      "Removing the mirrored edges required: 0.00143 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 1062154\n",
      "Building the flag array took:   0.00143 seconds\n",
      "prescan procedure on the flag array of size: 1062154 ...\n",
      "The first prescan procedure took:   0.00025 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00044 seconds\n",
      "\n",
      "The contracted graph will contain 306135 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1038, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00030 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 1062154 ...\n",
      "The first prescan procedure took:   0.00023 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00007 seconds\n",
      "\n",
      "The contracted graph will contain 1687286 edges\n",
      "The old graph structure contained 3574292 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONTRACTION -- (1024, 1, 1) -- (1038, 1, 1)\n",
      "The contratcion of the new neighbour and weight arrays took: 0.00117 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 306135 with 1687286 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (299, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00562 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (299, 1, 1)\n",
      "Removing the mirrored edges required: 0.00037 seconds\n",
      "\n",
      "The MST weight at the end of iteration 3 is: 6129570962\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (299, 1, 1)\n",
      "Removing the mirrored edges required: 0.00044 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 306135\n",
      "Building the flag array took:   0.00044 seconds\n",
      "prescan procedure on the flag array of size: 306135 ...\n",
      "The first prescan procedure took:   0.00009 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00007 seconds\n",
      "\n",
      "The contracted graph will contain 81802 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (299, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00013 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 306135 ...\n",
      "The first prescan procedure took:   0.00009 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00002 seconds\n",
      "\n",
      "The contracted graph will contain 780526 edges\n",
      "The old graph structure contained 1687286 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONTRACTION -- (1024, 1, 1) -- (299, 1, 1)\n",
      "The contratcion of the new neighbour and weight arrays took: 0.00070 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 81802 with 780526 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (80, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00181 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (80, 1, 1)\n",
      "Removing the mirrored edges required: 0.00012 seconds\n",
      "\n",
      "The MST weight at the end of iteration 4 is: 6388035581\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (80, 1, 1)\n",
      "Removing the mirrored edges required: 0.00014 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 81802\n",
      "Building the flag array took:   0.00014 seconds\n",
      "prescan procedure on the flag array of size: 81802 ...\n",
      "The first prescan procedure took:   0.00003 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00002 seconds\n",
      "\n",
      "The contracted graph will contain 20199 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (80, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00014 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 81802 ...\n",
      "The first prescan procedure took:   0.00004 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 337784 edges\n",
      "The old graph structure contained 780526 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONTRACTION -- (1024, 1, 1) -- (80, 1, 1)\n",
      "The contratcion of the new neighbour and weight arrays took: 0.00046 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 20199 with 337784 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (20, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00100 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (20, 1, 1)\n",
      "Removing the mirrored edges required: 0.00004 seconds\n",
      "\n",
      "The MST weight at the end of iteration 5 is: 6464478690\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (20, 1, 1)\n",
      "Removing the mirrored edges required: 0.00004 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 20199\n",
      "Building the flag array took:   0.00004 seconds\n",
      "prescan procedure on the flag array of size: 20199 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 4699 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (20, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00007 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 20199 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 140204 edges\n",
      "The old graph structure contained 337784 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONTRACTION -- (1024, 1, 1) -- (20, 1, 1)\n",
      "The contratcion of the new neighbour and weight arrays took: 0.00045 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 4699 with 140204 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (5, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00060 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (5, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 6 is: 6485093286\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (5, 1, 1)\n",
      "Removing the mirrored edges required: 0.00003 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 4699\n",
      "Building the flag array took:   0.00003 seconds\n",
      "prescan procedure on the flag array of size: 4699 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 1071 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (5, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00009 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 4699 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 57840 edges\n",
      "The old graph structure contained 140204 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONTRACTION -- (1024, 1, 1) -- (5, 1, 1)\n",
      "The contratcion of the new neighbour and weight arrays took: 0.00060 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 1071 with 57840 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (2, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00046 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (2, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 7 is: 6490534969\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (2, 1, 1)\n",
      "Removing the mirrored edges required: 0.00004 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 1071\n",
      "Building the flag array took:   0.00004 seconds\n",
      "prescan procedure on the flag array of size: 1071 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 226 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (2, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00011 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 1071 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 23814 edges\n",
      "The old graph structure contained 57840 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONTRACTION -- (1024, 1, 1) -- (2, 1, 1)\n",
      "The contratcion of the new neighbour and weight arrays took: 0.00058 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 226 with 23814 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00038 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 8 is: 6491801063\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 226\n",
      "Building the flag array took:   0.00002 seconds\n",
      "prescan procedure on the flag array of size: 226 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 42 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00007 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 226 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 7840 edges\n",
      "The old graph structure contained 23814 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONTRACTION -- (1024, 1, 1) -- (1, 1, 1)\n",
      "The contratcion of the new neighbour and weight arrays took: 0.00046 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 42 with 7840 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00031 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 9 is: 6492055731\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 42\n",
      "Building the flag array took:   0.00002 seconds\n",
      "prescan procedure on the flag array of size: 42 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 9 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00007 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 42 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 3054 edges\n",
      "The old graph structure contained 7840 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONTRACTION -- (1024, 1, 1) -- (1, 1, 1)\n",
      "The contratcion of the new neighbour and weight arrays took: 0.00057 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 9 with 3054 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00033 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 10 is: 6492111754\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "Doing a round of scan on the flag vector, size: 9\n",
      "Building the flag array took:   0.00002 seconds\n",
      "prescan procedure on the flag array of size: 9 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 2 supervertices\n",
      "\n",
      "\n",
      "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Doing the computation of the cumulated degrees took: 0.00008 seconds\n",
      "\n",
      "prescan procedure on the cumDegs array of size: 9 ...\n",
      "The first prescan procedure took:   0.00002 seconds\n",
      "final summation procedure...\n",
      "The final summation procedure took:   0.00001 seconds\n",
      "\n",
      "The contracted graph will contain 104 edges\n",
      "The old graph structure contained 3054 edges\n",
      "\n",
      "\n",
      "Launching kernel GRAPH CONTRACTION -- (1024, 1, 1) -- (1, 1, 1)\n",
      "The contratcion of the new neighbour and weight arrays took: 0.00043 seconds\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Processing a graph of size: 2 with 104 edges.\n",
      "\n",
      "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Finding the cheapest edge for every vertex took: 0.00016 seconds\n",
      "\n",
      "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00002 seconds\n",
      "\n",
      "The MST weight at the end of iteration 11 is: 6492121041\n",
      "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
      "Removing the mirrored edges required: 0.00001 seconds\n",
      "\n",
      "THE CALCULATION OF THE MST IS COMPLETE\n",
      "THE MST WEIGHT IS: 6492121041\n",
      "Total elapsed time: 0.07999 seconds\n",
      "\n",
      "Writing to file /content/result_gpuU\n"
     ]
    }
   ],
   "source": [
    "# Compilazione ed esecuzione\n",
    "\n",
    "!nvcc -arch=sm_75 GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/COMMON/readGraph.cu src/GPU/mstGPU.cu -o mstGPU\n",
    "!./mstGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AO_DSyKfkb5l",
    "outputId": "75ea9054-d68a-425d-99fc-bed45e7c66d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==47556== NVPROF is profiling process 47556, command: ./mstGPU\n",
      "==47556== Profiling application: ./mstGPU\n",
      "==47556== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   55.76%  68.840ms        11  6.2582ms  139.26us  46.223ms  findCheapest(GraphStruct*, unsigned int*)\n",
      "                   18.17%  22.434ms        83  270.29us  1.5680us  3.0442ms  [CUDA memcpy DtoH]\n",
      "                    6.91%  8.5295ms        10  852.95us  374.55us  2.8168ms  graphContraction(GraphStruct*, unsigned int*, unsigned int*, unsigned int*, unsigned int*, unsigned int*)\n",
      "                    5.48%  6.7624ms        11  614.77us  3.6480us  4.7012ms  colorationProcess(GraphStruct*, unsigned int*, unsigned int*)\n",
      "                    4.47%  5.5165ms        20  275.82us  1.8880us  4.4441ms  cfinal_sum(unsigned int*, unsigned int*, unsigned int)\n",
      "                    4.47%  5.5132ms        11  501.20us  3.3920us  3.8457ms  mirroredEdgesRemoval(GraphStruct*, unsigned int*, __int64*)\n",
      "                    1.86%  2.3024ms        20  115.12us  11.136us  796.72us  prescan(unsigned int*, unsigned int*, unsigned int*, int, int)\n",
      "                    1.37%  1.6903ms        10  169.03us  49.088us  864.98us  cumulatedDegreeUpdate(GraphStruct*, unsigned int*, unsigned int*, unsigned int*)\n",
      "                    0.72%  894.13us        11  81.284us     704ns  737.33us  [CUDA memcpy HtoD]\n",
      "                    0.57%  698.23us        92  7.5890us     640ns  65.855us  [CUDA memset]\n",
      "                    0.22%  276.57us        10  27.657us  2.5600us  184.45us  svIdentification(GraphStruct*, unsigned int*, unsigned int*, unsigned int*)\n",
      "      API calls:   48.38%  143.66ms        44  3.2649ms  3.8370us  139.70ms  cudaMallocManaged\n",
      "                   33.78%  100.30ms       103  973.81us  4.3700us  46.248ms  cudaDeviceSynchronize\n",
      "                   10.55%  31.323ms        94  333.22us  5.3450us  3.3932ms  cudaMemcpy\n",
      "                    4.95%  14.692ms       147  99.942us  2.6710us  1.7582ms  cudaFree\n",
      "                    1.19%  3.5218ms       103  34.192us  2.8240us  310.86us  cudaMalloc\n",
      "                    0.39%  1.1569ms       103  11.231us  4.2760us  225.19us  cudaLaunchKernel\n",
      "                    0.28%  821.36us        92  8.9270us  2.1160us  43.724us  cudaMemset\n",
      "                    0.19%  560.50us       206  2.7200us  1.2590us  16.918us  cudaEventRecord\n",
      "                    0.18%  539.05us        93  5.7960us  5.1030us  7.0430us  cudaEventSynchronize\n",
      "                    0.06%  183.15us       114  1.6060us     191ns  70.270us  cuDeviceGetAttribute\n",
      "                    0.04%  130.04us       103  1.2620us     766ns  3.1700us  cudaEventElapsedTime\n",
      "                    0.01%  25.657us         2  12.828us  1.3430us  24.314us  cudaEventCreate\n",
      "                    0.00%  13.534us         1  13.534us  13.534us  13.534us  cuDeviceGetName\n",
      "                    0.00%  9.8680us        40     246ns     154ns     398ns  cudaGetLastError\n",
      "                    0.00%  7.4700us         1  7.4700us  7.4700us  7.4700us  cuDeviceGetPCIBusId\n",
      "                    0.00%  6.3650us         1  6.3650us  6.3650us  6.3650us  cuDeviceTotalMem\n",
      "                    0.00%  2.5030us         3     834ns     355ns  1.7530us  cuDeviceGetCount\n",
      "                    0.00%  2.0460us         2  1.0230us     551ns  1.4950us  cudaEventDestroy\n",
      "                    0.00%     931ns         2     465ns     247ns     684ns  cuDeviceGet\n",
      "                    0.00%     523ns         1     523ns     523ns     523ns  cuModuleGetLoadingMode\n",
      "                    0.00%     374ns         1     374ns     374ns     374ns  cuDeviceGetUuid\n",
      "\n",
      "==47556== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    5705  25.318KB  4.0000KB  0.9961MB  141.0586MB  25.55121ms  Host To Device\n",
      "      42  32.000KB  4.0000KB  60.000KB  1.312500MB  170.8760us  Device To Host\n",
      "     246         -         -         -           -  75.39331ms  Gpu page fault groups\n",
      "Total CPU Page faults: 470\n"
     ]
    }
   ],
   "source": [
    "!nvprof ./mstGPU > nvprof_gpuU.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBgpvkGfkcVE"
   },
   "outputs": [],
   "source": [
    "!ncu ./mstGPU > ncu_gpuU.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ysbZKBMHUnM"
   },
   "source": [
    "# Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nd3tOpVTHVu6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "base_dir = \"/content/result_\"\n",
    "platforms = [\"cpu\", \"bka\"]\n",
    "\n",
    "weights_dict = {\n",
    "    \"cpu\": np.zeros(7),\n",
    "    \"bka\": np.zeros(7)\n",
    "}\n",
    "ets_dict = {\n",
    "    \"cpu\": np.zeros(7),\n",
    "    \"bka\": np.zeros(7)\n",
    "}\n",
    "\n",
    "for platform in platforms:\n",
    "    filepath = base_dir + platform\n",
    "\n",
    "    elapsedTime = 0.0\n",
    "    weight = 0\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        j = 0\n",
    "        while j < 14:\n",
    "            weights_dict[platform][int(j / 2)] = lines[j]\n",
    "            j += 1\n",
    "            ets_dict[platform][int(j / 2)] = np.float64(lines[j])\n",
    "            j += 1\n",
    "        f.close()\n",
    "\n",
    "    if platform == \"cpu\":\n",
    "        ets_dict[platform] = ets_dict[platform][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "P_FYf8k2hSGZ",
    "outputId": "79ca35ac-118b-49b7-ba46-48578b658cc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'My CPU (Prim)': array([ 0.697397,  1.19776 ,  3.2021  ,  4.17939 ,  5.85372 , 10.1876  ,\n",
      "       12.4059  ]), 'My CPU (Brka)': array([0.443077, 0.543661, 0.668324, 3.04013 , 4.52005 , 5.34692 ,\n",
      "       7.41779 ]), 'Sousa2015 CPU': array([0.055, 0.06 , 0.08 , 0.22 , 0.4  , 0.5  , 0.8  ]), 'Sousa2015 GPU': array([0.015, 0.015, 0.018, 0.025, 0.035, 0.045, 0.05 ]), 'gpuU_avg': array([0.0132458 , 0.01225238, 0.01388284, 0.02645332, 0.04709682,\n",
      "       0.06983636, 0.08831696]), 'gpuE_avg': array([0.01047352, 0.01095006, 0.01295532, 0.02414482, 0.04680142,\n",
      "       0.06690456, 0.08030418]), 'gpuU_std': array([0.0020043 , 0.00057546, 0.00056955, 0.00120096, 0.00353918,\n",
      "       0.00684323, 0.01071194]), 'gpuE_std': array([0.00035854, 0.00034388, 0.00170608, 0.00068753, 0.00485536,\n",
      "       0.00532681, 0.00765168])}\n",
      "[ 0.697397  1.19776   3.2021    4.17939   5.85372  10.1876   12.4059  ]\n",
      "My CPU (Prim)\n",
      "[0.443077 0.543661 0.668324 3.04013  4.52005  5.34692  7.41779 ]\n",
      "My CPU (Brka)\n",
      "[0.055 0.06  0.08  0.22  0.4   0.5   0.8  ]\n",
      "Sousa2015 CPU\n",
      "[0.015 0.015 0.018 0.025 0.035 0.045 0.05 ]\n",
      "Sousa2015 GPU\n",
      "[0.0132458  0.01225238 0.01388284 0.02645332 0.04709682 0.06983636\n",
      " 0.08831696]\n",
      "gpuU_avg\n",
      "[0.01047352 0.01095006 0.01295532 0.02414482 0.04680142 0.06690456\n",
      " 0.08030418]\n",
      "gpuE_avg\n",
      "[0.0020043  0.00057546 0.00056955 0.00120096 0.00353918 0.00684323\n",
      " 0.01071194]\n",
      "gpuU_std\n",
      "[0.00035854 0.00034388 0.00170608 0.00068753 0.00485536 0.00532681\n",
      " 0.00765168]\n",
      "gpuE_std\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "categories = [\"NY\", \"BAY\", \"COL\", \"FLA\", \"CAL\", \"LKS\", \"E\"]\n",
    "num_categories = len(categories)\n",
    "colors = [\"blue\", \"orange\", \"green\", \"brown\", \"red\", \"purple\"]\n",
    "\n",
    "# Example execution times (ms) for each configuration\n",
    "data = {\n",
    "    \"My CPU (Prim)\": ets_dict[\"cpu\"],\n",
    "    \"My CPU (Brka)\": ets_dict[\"bka\"],\n",
    "    \"Sousa2015 CPU\": np.asarray([0.055, 0.06, 0.08, 0.22, 0.4, 0.5, 0.8]),\n",
    "    \"Sousa2015 GPU\": np.asarray([0.015, 0.015, 0.018, 0.025, 0.035, 0.045, 0.05]),\n",
    "    \"gpuU_avg\": np.empty(0),\n",
    "    \"gpuE_avg\": np.empty(0),\n",
    "    \"gpuU_std\": np.empty(0),\n",
    "    \"gpuE_std\": np.empty(0)\n",
    "}\n",
    "\n",
    "base_dir = \"/content/result_\"\n",
    "platforms = [\"gpuU\", \"gpuE\"]\n",
    "p = 0\n",
    "\n",
    "for platform in platforms:\n",
    "    filepath = base_dir + platform\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        avg_time = np.zeros(num_categories)\n",
    "        std_time = np.zeros(num_categories)\n",
    "\n",
    "        for i in range(num_categories):\n",
    "            j = 0\n",
    "            checkWeight = 0\n",
    "            times = np.zeros(5)\n",
    "            while j < 10:\n",
    "                if checkWeight == 0:\n",
    "                    checkWeight = lines[10 * i + j]\n",
    "                else:\n",
    "                    weight = lines[10 * i + j]\n",
    "                    if checkWeight != weight:\n",
    "                        print(f\"The two weight vectors are different at position {10 * i} {checkWeight}  {weight}\")\n",
    "                        exit(1)\n",
    "                j += 1\n",
    "                times[int(j / 2)] = lines[10 * i + j]\n",
    "                j += 1\n",
    "\n",
    "            avg_time[i] = np.mean(times)\n",
    "            std_time[i] = np.std(times)\n",
    "        f.close()\n",
    "    if platform == \"gpuU\":\n",
    "        data[\"gpuU_avg\"] = avg_time[::-1]\n",
    "        data[\"gpuU_std\"] = std_time[::-1]\n",
    "    else:\n",
    "        data[f\"{platform}_avg\"] = avg_time\n",
    "        data[f\"{platform}_std\"] = std_time\n",
    "\n",
    "print(data)\n",
    "\n",
    "# Parameters for bar width and positions\n",
    "bar_width = 0.1\n",
    "x = np.arange(num_categories)\n",
    "\n",
    "# Create figure and set log scale for y-axis\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "# Plot each data series with a different color and hatch pattern\n",
    "for i, (label, values) in enumerate(data.items()):\n",
    "    print(values)\n",
    "    print(label)\n",
    "    if label == \"gpuU_std\":\n",
    "        ax.errorbar(x + (i - 2) * bar_width, data[\"gpuU_avg\"], values, capsize=5, ecolor='black', linestyle=\"\")\n",
    "    elif label == \"gpuE_std\":\n",
    "        ax.errorbar(x + (i - 2) * bar_width, data[\"gpuE_avg\"], values, capsize=5, ecolor='black', linestyle=\"\")\n",
    "    else:\n",
    "        ax.bar(x + i * bar_width, values, width=bar_width, label=label, edgecolor='black', color=colors[i])\n",
    "\n",
    "\n",
    "# Set labels, title, and legend\n",
    "ax.set_xlabel(\"Graph\", fontsize=12)\n",
    "ax.set_ylabel(\"Execution Time (ms)\", fontsize=12)\n",
    "ax.set_xticks(x + bar_width * 2)  # Center x-ticks\n",
    "ax.set_xticklabels(categories, rotation=45)\n",
    "ax.legend(loc=\"upper left\", fontsize=10, title=\"Legend\", title_fontsize='13')\n",
    "\n",
    "# Show grid and plot\n",
    "ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "0Y_SjlAhe6L-",
    "4KqoBgM--a13",
    "by0GWqS5bH8o",
    "4OhoBGXoHMZ1",
    "p5kobMdtrh8v",
    "3xvmvZC2mHq9",
    "I4teSJBKrl0F",
    "ADIG-V2U4Q0o",
    "mwhvV2EtcDXQ",
    "iwQlFQ0uR2nc",
    "scPfLP48iEId"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
