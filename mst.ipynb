{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y_SjlAhe6L-"
      },
      "source": [
        "# Setup section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG2d4EbyeMga",
        "outputId": "092823c8-f0dc-4567-dfc8-99718f0fd355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXvV86RSebx8",
        "outputId": "719b9a5d-7e8c-4ebf-e788-367fdd626e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct  8 16:39:43 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nEpZlmmeesZ",
        "outputId": "ace86667-8f75-4e6f-bc6f-419704670eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'GPUcomputing': No such file or directory\n",
            "Cloning into 'GPUcomputing'...\n",
            "remote: Enumerating objects: 723, done.\u001b[K\n",
            "remote: Counting objects: 100% (376/376), done.\u001b[K\n",
            "remote: Compressing objects: 100% (210/210), done.\u001b[K\n",
            "remote: Total 723 (delta 207), reused 306 (delta 154), pack-reused 347 (from 1)\u001b[K\n",
            "Receiving objects: 100% (723/723), 2.81 MiB | 20.10 MiB/s, done.\n",
            "Resolving deltas: 100% (364/364), done.\n"
          ]
        }
      ],
      "source": [
        "# Download repositories\n",
        "\n",
        "!sudo rm -dr GPUcomputing\n",
        "!git clone https://github.com/S3gmentati0nFault/GPUcomputing.git\n",
        "!mkdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjcFCeg2erat",
        "outputId": "9ada1406-2494-4e0b-bfd6-09f8543ba180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GPUcomputing/utils/nvcc4jupyter-master\n",
            "\u001b[1m* Creating isolated environment: venv+pip...\u001b[0m\n",
            "\u001b[1m* Installing packages in isolated environment:\u001b[0m\n",
            "  - setuptools >= 40.8.0\n",
            "\u001b[1m* Getting build dependencies for sdist...\u001b[0m\n",
            "running egg_info\n",
            "creating nvcc4jupyter.egg-info\n",
            "writing nvcc4jupyter.egg-info/PKG-INFO\n",
            "writing dependency_links to nvcc4jupyter.egg-info/dependency_links.txt\n",
            "writing top-level names to nvcc4jupyter.egg-info/top_level.txt\n",
            "writing manifest file 'nvcc4jupyter.egg-info/SOURCES.txt'\n",
            "reading manifest file 'nvcc4jupyter.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'nvcc4jupyter.egg-info/SOURCES.txt'\n",
            "\u001b[1m* Building sdist...\u001b[0m\n",
            "running sdist\n",
            "running egg_info\n",
            "writing nvcc4jupyter.egg-info/PKG-INFO\n",
            "writing dependency_links to nvcc4jupyter.egg-info/dependency_links.txt\n",
            "writing top-level names to nvcc4jupyter.egg-info/top_level.txt\n",
            "reading manifest file 'nvcc4jupyter.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'nvcc4jupyter.egg-info/SOURCES.txt'\n",
            "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
            "\n",
            "running check\n",
            "creating nvcc4jupyter-0.1.0\n",
            "creating nvcc4jupyter-0.1.0/nvcc4jupyter\n",
            "creating nvcc4jupyter-0.1.0/nvcc4jupyter.egg-info\n",
            "copying files to nvcc4jupyter-0.1.0...\n",
            "copying LICENSE -> nvcc4jupyter-0.1.0\n",
            "copying setup.py -> nvcc4jupyter-0.1.0\n",
            "copying nvcc4jupyter/__init__.py -> nvcc4jupyter-0.1.0/nvcc4jupyter\n",
            "copying nvcc4jupyter/parsers.py -> nvcc4jupyter-0.1.0/nvcc4jupyter\n",
            "copying nvcc4jupyter/plugin.py -> nvcc4jupyter-0.1.0/nvcc4jupyter\n",
            "copying nvcc4jupyter.egg-info/PKG-INFO -> nvcc4jupyter-0.1.0/nvcc4jupyter.egg-info\n",
            "copying nvcc4jupyter.egg-info/SOURCES.txt -> nvcc4jupyter-0.1.0/nvcc4jupyter.egg-info\n",
            "copying nvcc4jupyter.egg-info/dependency_links.txt -> nvcc4jupyter-0.1.0/nvcc4jupyter.egg-info\n",
            "copying nvcc4jupyter.egg-info/top_level.txt -> nvcc4jupyter-0.1.0/nvcc4jupyter.egg-info\n",
            "copying nvcc4jupyter.egg-info/SOURCES.txt -> nvcc4jupyter-0.1.0/nvcc4jupyter.egg-info\n",
            "Writing nvcc4jupyter-0.1.0/setup.cfg\n",
            "Creating tar archive\n",
            "removing 'nvcc4jupyter-0.1.0' (and everything under it)\n",
            "\u001b[1m* Building wheel from sdist\u001b[0m\n",
            "\u001b[1m* Creating isolated environment: venv+pip...\u001b[0m\n",
            "\u001b[1m* Installing packages in isolated environment:\u001b[0m\n",
            "  - setuptools >= 40.8.0\n",
            "\u001b[1m* Getting build dependencies for wheel...\u001b[0m\n",
            "running egg_info\n",
            "writing nvcc4jupyter.egg-info/PKG-INFO\n",
            "writing dependency_links to nvcc4jupyter.egg-info/dependency_links.txt\n",
            "writing top-level names to nvcc4jupyter.egg-info/top_level.txt\n",
            "reading manifest file 'nvcc4jupyter.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'nvcc4jupyter.egg-info/SOURCES.txt'\n",
            "\u001b[1m* Building wheel...\u001b[0m\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build/lib/nvcc4jupyter\n",
            "copying nvcc4jupyter/parsers.py -> build/lib/nvcc4jupyter\n",
            "copying nvcc4jupyter/__init__.py -> build/lib/nvcc4jupyter\n",
            "copying nvcc4jupyter/plugin.py -> build/lib/nvcc4jupyter\n",
            "installing to build/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64/wheel\n",
            "creating build/bdist.linux-x86_64/wheel/nvcc4jupyter\n",
            "copying build/lib/nvcc4jupyter/parsers.py -> build/bdist.linux-x86_64/wheel/./nvcc4jupyter\n",
            "copying build/lib/nvcc4jupyter/__init__.py -> build/bdist.linux-x86_64/wheel/./nvcc4jupyter\n",
            "copying build/lib/nvcc4jupyter/plugin.py -> build/bdist.linux-x86_64/wheel/./nvcc4jupyter\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "writing nvcc4jupyter.egg-info/PKG-INFO\n",
            "writing dependency_links to nvcc4jupyter.egg-info/dependency_links.txt\n",
            "writing top-level names to nvcc4jupyter.egg-info/top_level.txt\n",
            "reading manifest file 'nvcc4jupyter.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'nvcc4jupyter.egg-info/SOURCES.txt'\n",
            "Copying nvcc4jupyter.egg-info to build/bdist.linux-x86_64/wheel/./nvcc4jupyter-0.1.0-py3.10.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.linux-x86_64/wheel/nvcc4jupyter-0.1.0.dist-info/WHEEL\n",
            "creating '/content/GPUcomputing/utils/nvcc4jupyter-master/dist/.tmp-4t1b4a46/nvcc4jupyter-0.1.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "adding 'nvcc4jupyter/__init__.py'\n",
            "adding 'nvcc4jupyter/parsers.py'\n",
            "adding 'nvcc4jupyter/plugin.py'\n",
            "adding 'nvcc4jupyter-0.1.0.dist-info/LICENSE'\n",
            "adding 'nvcc4jupyter-0.1.0.dist-info/METADATA'\n",
            "adding 'nvcc4jupyter-0.1.0.dist-info/WHEEL'\n",
            "adding 'nvcc4jupyter-0.1.0.dist-info/top_level.txt'\n",
            "adding 'nvcc4jupyter-0.1.0.dist-info/RECORD'\n",
            "removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[1m\u001b[92mSuccessfully built \u001b[4mnvcc4jupyter-0.1.0.tar.gz\u001b[0m\u001b[1m\u001b[92m and \u001b[4mnvcc4jupyter-0.1.0-py3-none-any.whl\u001b[0m\u001b[1m\u001b[92m\u001b[0m\n",
            "Source files will be saved in \"./src\".\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd GPUcomputing/utils/nvcc4jupyter-master/\n",
        "!python3 -m build\n",
        "%load_ext nvcc4jupyter\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaynNOTreu9O",
        "outputId": "56de46e6-bda9-4707-b35a-0a7a32e04f01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          12.2 / 12.2\n",
            "  GPU arch name:                                 Turing\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15102 MBytes (15835660288 bytes)\n",
            "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory                65536 bytes\n",
            "  Total amount of shared memory per block        49152 bytes\n",
            "  Total number of registers available per block  65536\n",
            "  Warp size                                      32\n",
            "  Maximum number of threads per multiprocessor   1024\n",
            "  Maximum number of threads per block            1024\n",
            "  Max dimension size of a thread block (x,y,z)  (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z)  (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch                           2147483647 bytes\n",
            "  Texture alignment                              512 bytes\n",
            "  Concurrent copy and kernel execution           Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels                      No\n",
            "  Integrated GPU sharing Host Memory             No\n",
            "  Support host page-locked memory mapping        Yes\n",
            "  Alignment requirement for Surfaces             Yes\n",
            "  Device has ECC support                         Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n"
          ]
        }
      ],
      "source": [
        "# DeviceQuery dell'attuale device (su Colab!)\n",
        "\n",
        "!nvcc -arch=sm_75 /content/GPUcomputing/utils/deviceQuery.cu -o deviceQuery\n",
        "!./deviceQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgIfmOPIA5hu",
        "outputId": "d39a058c-95a8-4fd3-e55f-f8ce793daf14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  gdb libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n",
            "  libsource-highlight-common libsource-highlight4v5\n",
            "Suggested packages:\n",
            "  gdb-doc gdbserver valgrind-dbg valgrind-mpi kcachegrind alleyoop valkyrie\n",
            "The following NEW packages will be installed:\n",
            "  gdb libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n",
            "  libsource-highlight-common libsource-highlight4v5 valgrind\n",
            "0 upgraded, 9 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 32.3 MB of archives.\n",
            "After this operation, 111 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod-common all 0.186-1build1 [7,878 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libbabeltrace1 amd64 1.5.8-2build1 [160 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod1 amd64 0.186-1build1 [12.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libipt2 amd64 2.0.5-1 [46.4 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight-common all 3.1.9-4.1build2 [64.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight4v5 amd64 3.1.9-4.1build2 [207 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gdb amd64 12.1-0ubuntu1~22.04.2 [3,920 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc6-dbg amd64 2.35-0ubuntu3.8 [13.8 MB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 valgrind amd64 1:3.18.1-1ubuntu2 [14.1 MB]\n",
            "Fetched 32.3 MB in 3s (9,443 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libdebuginfod-common.\n",
            "(Reading database ... 123621 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libdebuginfod-common_0.186-1build1_all.deb ...\n",
            "Unpacking libdebuginfod-common (0.186-1build1) ...\n",
            "Selecting previously unselected package libbabeltrace1:amd64.\n",
            "Preparing to unpack .../1-libbabeltrace1_1.5.8-2build1_amd64.deb ...\n",
            "Unpacking libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
            "Selecting previously unselected package libdebuginfod1:amd64.\n",
            "Preparing to unpack .../2-libdebuginfod1_0.186-1build1_amd64.deb ...\n",
            "Unpacking libdebuginfod1:amd64 (0.186-1build1) ...\n",
            "Selecting previously unselected package libipt2.\n",
            "Preparing to unpack .../3-libipt2_2.0.5-1_amd64.deb ...\n",
            "Unpacking libipt2 (2.0.5-1) ...\n",
            "Selecting previously unselected package libsource-highlight-common.\n",
            "Preparing to unpack .../4-libsource-highlight-common_3.1.9-4.1build2_all.deb ...\n",
            "Unpacking libsource-highlight-common (3.1.9-4.1build2) ...\n",
            "Selecting previously unselected package libsource-highlight4v5.\n",
            "Preparing to unpack .../5-libsource-highlight4v5_3.1.9-4.1build2_amd64.deb ...\n",
            "Unpacking libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
            "Selecting previously unselected package gdb.\n",
            "Preparing to unpack .../6-gdb_12.1-0ubuntu1~22.04.2_amd64.deb ...\n",
            "Unpacking gdb (12.1-0ubuntu1~22.04.2) ...\n",
            "Selecting previously unselected package libc6-dbg:amd64.\n",
            "Preparing to unpack .../7-libc6-dbg_2.35-0ubuntu3.8_amd64.deb ...\n",
            "Unpacking libc6-dbg:amd64 (2.35-0ubuntu3.8) ...\n",
            "Selecting previously unselected package valgrind.\n",
            "Preparing to unpack .../8-valgrind_1%3a3.18.1-1ubuntu2_amd64.deb ...\n",
            "Unpacking valgrind (1:3.18.1-1ubuntu2) ...\n",
            "Setting up libdebuginfod-common (0.186-1build1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/profile.d/debuginfod.sh with new version\n",
            "\n",
            "Creating config file /etc/profile.d/debuginfod.csh with new version\n",
            "Setting up libdebuginfod1:amd64 (0.186-1build1) ...\n",
            "Setting up libsource-highlight-common (3.1.9-4.1build2) ...\n",
            "Setting up libc6-dbg:amd64 (2.35-0ubuntu3.8) ...\n",
            "Setting up libipt2 (2.0.5-1) ...\n",
            "Setting up libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
            "Setting up valgrind (1:3.18.1-1ubuntu2) ...\n",
            "Setting up libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
            "Setting up gdb (12.1-0ubuntu1~22.04.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Installation of the Valgrind utility\n",
        "\n",
        "!sudo apt install valgrind"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKn7gG7FdeYe"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsKCN_DwDB7q"
      },
      "source": [
        "Test interessanti:\n",
        "\n",
        "SIZE 20000\n",
        "\n",
        "MAX_WEIGHT 50000\n",
        "\n",
        "FIXED_SEED 78651423"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "jDQeHkBtddXu"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save --name \"sharedMacros.h\" --group \"COMMON\"\n",
        "\n",
        "#ifndef SHARED_MACROS_H\n",
        "#define SHARED_MACROS_H\n",
        "\n",
        "#define DEBUGGING 0\n",
        "#define SIZE 20000\n",
        "#define MAX_WEIGHT 50000\n",
        "#define TESTING 0\n",
        "#define TEST_SIZE 3\n",
        "#define FIXED_SEED 394867\n",
        "#define LOGPATH \"/content/logs/\"\n",
        "#define BLOCK_SIZE 1024\n",
        "\n",
        "#endif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmgJ3ZD9TZka"
      },
      "source": [
        "# CPU zone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cm-rFSvKa2j"
      },
      "source": [
        "## MST solution with Prim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Nr0tpOgXeTAs"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save --name \"mst.h\" --group \"CPU\"\n",
        "\n",
        "#ifndef MST_H\n",
        "#define MST_H\n",
        "\n",
        "// Header file di C++\n",
        "#include <vector>\n",
        "\n",
        "struct mst {\n",
        "    std::vector<int> *stree;\n",
        "    int totalWeight;\n",
        "\n",
        "    mst() {\n",
        "        stree = NULL;\n",
        "        totalWeight = 0;\n",
        "    }\n",
        "\n",
        "    ~mst() {\n",
        "        if (stree != NULL) {\n",
        "            delete[] stree;\n",
        "        }\n",
        "        stree = NULL;\n",
        "        totalWeight = 0;\n",
        "    }\n",
        "};\n",
        "\n",
        "#endif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEIZ7tyYPNfB"
      },
      "source": [
        "### Heap implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "0eAjIA8eMsyM"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save --name \"heap.h\" --group \"CPU\"\n",
        "\n",
        "// Header file di C++\n",
        "#include <vector>\n",
        "\n",
        "// Header file custom\n",
        "#include \"../COMMON/sharedMacros.h\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#ifndef HEAP_H\n",
        "#define HEAP_H\n",
        "\n",
        "struct edge {\n",
        "    edge () {\n",
        "        source = UINT_MAX;\n",
        "        destination = UINT_MAX;\n",
        "        offset = UINT_MAX;\n",
        "        weight = INT_MAX;\n",
        "    }\n",
        "\n",
        "    ~edge () {\n",
        "        source = UINT_MAX;\n",
        "        destination = UINT_MAX;\n",
        "        offset = UINT_MAX;\n",
        "        weight = INT_MAX;\n",
        "    }\n",
        "\n",
        "    edge (uint source, uint destination, uint offset, int weight) {\n",
        "        this->source = source;\n",
        "        this->destination = destination;\n",
        "        this->offset = offset;\n",
        "        this->weight = weight;\n",
        "    }\n",
        "\n",
        "    bool operator<(const edge& other) const {\n",
        "        if (this->weight == other.weight) {\n",
        "            return this->destination < other.destination;\n",
        "        }\n",
        "        return this->weight < other.weight;\n",
        "    }\n",
        "\n",
        "    bool operator>(const edge& other) const {\n",
        "        if (this->weight == other.weight) {\n",
        "            return this->destination > other.destination;\n",
        "        }\n",
        "        return this->weight > other.weight;\n",
        "    }\n",
        "\n",
        "    uint source, destination, offset;\n",
        "    int weight;\n",
        "};\n",
        "\n",
        "class Heap {\n",
        "    public:\n",
        "        Heap () {\n",
        "            size = 0;\n",
        "            map = NULL;\n",
        "        }\n",
        "\n",
        "        Heap (uint size) {\n",
        "            mapSize = size;\n",
        "            map = new uint[mapSize];\n",
        "            for (uint i = 0; i < mapSize; i++) {\n",
        "                map[i] = UINT_MAX;\n",
        "            }\n",
        "            this->size = 0;\n",
        "        }\n",
        "\n",
        "        ~Heap () {\n",
        "            delete[] map;\n",
        "            map = NULL;\n",
        "        }\n",
        "\n",
        "        uint getLeftChild (uint index) {\n",
        "            return 2 * index + 1;\n",
        "        }\n",
        "\n",
        "        uint getRightChild (uint index) {\n",
        "            return 2 * index + 2;\n",
        "        }\n",
        "\n",
        "        uint getParent (uint index) {\n",
        "            return (index - 1) / 2;\n",
        "        }\n",
        "\n",
        "        edge getKey (uint index) {\n",
        "            return heap[index];\n",
        "        }\n",
        "\n",
        "        uint getPosition (uint key) {\n",
        "            return map[key];\n",
        "        }\n",
        "\n",
        "        void insert (uint source, uint destination, uint offset, int weight) {\n",
        "            // Insert the new edge\n",
        "            edge newEdge = edge(source, destination, offset, weight);\n",
        "            heap.push_back(newEdge);\n",
        "            size++;\n",
        "\n",
        "            map[destination] = size - 1;\n",
        "\n",
        "            uint i = size - 1;\n",
        "            while (i > 0 && heap[getParent(i)] > heap[i]) {\n",
        "                swap(heap[i], heap[getParent(i)]);\n",
        "                swap(map[heap[i].destination], map[heap[getParent(i)].destination]);\n",
        "                i = getParent(i);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        void heapify (uint subtree) {\n",
        "            uint left = getLeftChild(subtree);\n",
        "            uint right = getRightChild(subtree);\n",
        "            uint minimum = subtree;\n",
        "\n",
        "            if (left < size && heap[left] < heap[minimum]) {\n",
        "                minimum = left;\n",
        "            }\n",
        "\n",
        "            if (right < size && heap[right] < heap[minimum]) {\n",
        "                minimum = right;\n",
        "            }\n",
        "\n",
        "            if (minimum != subtree) {\n",
        "                swap(heap[subtree], heap[minimum]);\n",
        "                swap(map[heap[subtree].destination], map[heap[minimum].destination]);\n",
        "\n",
        "                heapify(minimum);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        void print() {\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                cout << \"(\" << heap[i].source << \", \" << heap[i].destination << \")[\" << heap[i].weight << \"]\" << endl;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        void printMap() {\n",
        "            for (uint i = 0; i < mapSize; i++) {\n",
        "                cout << i << \", \" << map[i] << endl;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        edge peek() {\n",
        "            return heap[0];\n",
        "        }\n",
        "\n",
        "        edge pop() {\n",
        "            edge min;\n",
        "            if (size == 0) {\n",
        "                return min;\n",
        "            }\n",
        "\n",
        "            swap(heap[0], heap[size - 1]);\n",
        "            swap(map[heap[0].destination], map[heap[size - 1].destination]);\n",
        "            min = heap[size - 1];\n",
        "\n",
        "            heap.erase(heap.end());\n",
        "            map[min.destination] = UINT_MAX;\n",
        "            size--;\n",
        "\n",
        "            if (size == 0) {\n",
        "                return min;\n",
        "            }\n",
        "\n",
        "            heapify(0);\n",
        "            return min;\n",
        "        }\n",
        "\n",
        "        bool isEmpty() {\n",
        "            if (size == 0) {\n",
        "                return true;\n",
        "            }\n",
        "            return false;\n",
        "        }\n",
        "\n",
        "        void keyDecrease(uint i, uint source, int weight) {\n",
        "            heap[i].weight = weight;\n",
        "            heap[i].source = source;\n",
        "\n",
        "            while (i > 0 && heap[getParent(i)] > heap[i]) {\n",
        "                swap(heap[i], heap[getParent(i)]);\n",
        "                swap(map[heap[i].destination], map[heap[getParent(i)].destination]);\n",
        "                i = getParent(i);\n",
        "            }\n",
        "        }\n",
        "\n",
        "    private:\n",
        "        uint size, mapSize;\n",
        "        uint *map;\n",
        "        vector<edge> heap;\n",
        "};\n",
        "\n",
        "#endif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i131S2JgPQ1M"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save --name \"heap.cu\" --group \"CPU\"\n",
        "\n",
        "#include <iostream>\n",
        "\n",
        "#include \"heap.h\"\n",
        "\n",
        "int main() {\n",
        "    Heap *heap = new Heap();\n",
        "\n",
        "    // void insert (uint source, uint destination, uint offset, int weight) {\n",
        "    heap->insert(3, 0, 0, 10);\n",
        "    heap->insert(3, 1, 0, 11);\n",
        "    heap->insert(3, 2, 0, 12);\n",
        "    heap->insert(3, 3, 0, 123);\n",
        "    heap->insert(3, 4, 0, 14);\n",
        "    heap->insert(3, 5, 0, 10);\n",
        "    heap->insert(3, 6, 0, 16);\n",
        "    heap->insert(3, 7, 0, 10);\n",
        "    heap->insert(3, 8, 0, 18);\n",
        "    heap->insert(3, 9, 0, 0);\n",
        "\n",
        "    heap->print();\n",
        "\n",
        "    printf(\"\\n\\n\");\n",
        "\n",
        "    heap->pop();\n",
        "\n",
        "    heap->print();\n",
        "\n",
        "    delete heap;\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOi-SNlRPUW5"
      },
      "outputs": [],
      "source": [
        "# Compilazione ed esecuzione\n",
        "\n",
        "!nvcc -arch=sm_75  GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/CPU/heap.cu -o heap\n",
        "!./heap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKNWqvmJQsYz"
      },
      "outputs": [],
      "source": [
        "# Compilazione ed esecuzione\n",
        "\n",
        "!nvcc -arch=sm_75  GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/CPU/heap.cu -o heap\n",
        "!valgrind ./heap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OLIQlpVKwJZ"
      },
      "source": [
        "### Valgrind testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC4SDm_w7BjU"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save --name \"nonTimedMstCPUPrim.cu\" --group \"CPU\"\n",
        "\n",
        "// Header file di C++\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <vector>\n",
        "#include <algorithm>\n",
        "\n",
        "// Header file C\n",
        "#include <time.h>\n",
        "#include <limits.h>\n",
        "\n",
        "// Custom files\n",
        "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
        "#include \"../../GPUcomputing/utils/common.h\"\n",
        "#include \"mst.h\"\n",
        "#include \"../COMMON/sharedMacros.h\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "mst *primMST (uint size, default_random_engine &eng, GraphStruct *str) {\n",
        "    // Initialize the tree to the emptyset\n",
        "    mst *tree = new mst;\n",
        "    tree->stree = new vector<int>[size];\n",
        "    tree->totalWeight = 0;\n",
        "\n",
        "    // Initialize the vertex set U to a random vertex in the graph\n",
        "    vector<node> U;\n",
        "    vector<node> Remaining;\n",
        "    uniform_real_distribution<> randR(0.0, 1.0);\n",
        "    node randV;\n",
        "    randV = (node)(randR(eng) * size);\n",
        "    cout << \"Source for the MST: \" << randV << endl;\n",
        "    U.push_back(randV);\n",
        "    for (node i = 0; i < size; i++) {\n",
        "        if (i != randV) {\n",
        "            Remaining.push_back(i);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // While the set U is different from the set V\n",
        "    while (!Remaining.empty()) {\n",
        "\n",
        "      /*\n",
        "       * Find the edge with the lowest weight in the adjacency list of the\n",
        "       * nodes currently in U\n",
        "      */\n",
        "      int minimum = INT_MAX;\n",
        "      int sourceCandidate = -1;\n",
        "      int destinationCandidate = -1;\n",
        "      for (node i = 0; i < U.size(); i++) {\n",
        "          for (uint j = 0; j < str->deg(U[i]); j++) {\n",
        "              node neigh = str->getNeigh(U[i], j);\n",
        "              uint occ = count(U.begin(), U.end(), neigh);\n",
        "              if (occ == 0 && (str->getWeight(U[i], j) < minimum ||\n",
        "                  (str->getWeight(U[i], j) == minimum && neigh < destinationCandidate))) {\n",
        "                  minimum = str->getWeight(U[i], j);\n",
        "                  sourceCandidate = U[i];\n",
        "                  destinationCandidate = neigh;\n",
        "              }\n",
        "          }\n",
        "      }\n",
        "\n",
        "      if (sourceCandidate != -1) {\n",
        "          if (DEBUGGING) {\n",
        "              cout << \"Source: \" << sourceCandidate << \" Destination: \" << destinationCandidate << \" Weight: \" << minimum << endl;\n",
        "          }\n",
        "\n",
        "          // Add the newfound edge to the mst\n",
        "          tree->stree[sourceCandidate].push_back(destinationCandidate);\n",
        "          tree->totalWeight += minimum;\n",
        "\n",
        "          // Add the destination vertex to the set U\n",
        "          U.push_back(destinationCandidate);\n",
        "\n",
        "          // Remove the element using erase function and iterators\n",
        "          auto it = find(Remaining.begin(), Remaining.end(), destinationCandidate);\n",
        "\n",
        "          // If element is found found, erase it\n",
        "          if (it != Remaining.end()) {\n",
        "              Remaining.erase(it);\n",
        "          }\n",
        "      }\n",
        "\n",
        "      else {\n",
        "          cout << \"CPU-MST [Error]: The graph appears to be disconnected\" << endl;\n",
        "          return tree;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    return tree;\n",
        "}\n",
        "\n",
        "int main () {\n",
        "    // Generation of a random graph\n",
        "    std::random_device rd;\n",
        "    std::default_random_engine fixedEng(FIXED_SEED);\n",
        "    std::default_random_engine variableEng(rd());\n",
        "    Graph *graph;\n",
        "    char path[] = \"/content/testing/primTest.txt\";\n",
        "    uint size = SIZE;\n",
        "    uint maxWeight = MAX_WEIGHT;\n",
        "    float prob = .5;\n",
        "    bool GPUEnabled = 0;\n",
        "\n",
        "    // Definition of testing variables\n",
        "    uint repetitions;\n",
        "    uint sizeArray[] = {50, 500, 1000};\n",
        "    FILE *fptr;\n",
        "\n",
        "    // Setup the testing variables\n",
        "    if (TESTING) {\n",
        "        repetitions = TEST_SIZE;\n",
        "        fptr = fopen(path, \"w\");\n",
        "        if (!fptr) {\n",
        "            std::perror(\"File opening failed\");\n",
        "            return -1;\n",
        "        }\n",
        "    }\n",
        "    else {\n",
        "        repetitions = 1;\n",
        "    }\n",
        "\n",
        "    // Call to the Prim MST solver\n",
        "    for (uint i = 0; i < repetitions; i++) {\n",
        "        // Generation of the random graph\n",
        "        if (TESTING) {\n",
        "            size = sizeArray[i];\n",
        "        }\n",
        "        graph = new Graph(size, GPUEnabled);\n",
        "        graph->randGraph(prob, true, maxWeight, fixedEng);\n",
        "\n",
        "        // Test the printing procedure\n",
        "        if (size < 15) {\n",
        "            cout << \"Printing the graph\" << endl;\n",
        "            graph->print(true);\n",
        "        }\n",
        "\n",
        "        cout << \"Computing the MST solution for a graph of size \" << size << endl;\n",
        "        //cudaEventRecord(start);\n",
        "        mst *tree = primMST(size, variableEng, graph->getStruct());\n",
        "        if (size < 15) {\n",
        "            cout << \"MST solution\" << endl;\n",
        "            for (int i = 0; i < size; ++i) {\n",
        "                cout << i << \": \";\n",
        "                for (int j = 0; j < tree->stree[i].size(); ++j) {\n",
        "                    cout << tree->stree[i][j] << \" \";\n",
        "                }\n",
        "                cout << endl;\n",
        "            }\n",
        "        }\n",
        "        cout << \"Total weight: \" << tree->totalWeight << endl;\n",
        "        cout << \"\\n\\n\\n\\n\";\n",
        "        if (TESTING) {\n",
        "            fprintf(fptr, \"%d,%d,\\n\", size, tree->totalWeight);\n",
        "        }\n",
        "\n",
        "        // Memory deallocation\n",
        "        delete tree;\n",
        "        delete graph;\n",
        "        tree = NULL;\n",
        "        graph = NULL;\n",
        "    }\n",
        "\n",
        "    if (TESTING) {\n",
        "        fclose(fptr);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuK7D_pe7UlX"
      },
      "outputs": [],
      "source": [
        "# Valgrind testing\n",
        "\n",
        "!nvcc -arch=sm_75  GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/CPU/nonTimedMstCPUPrim.cu -o valgrindCPU\n",
        "!valgrind ./valgrindCPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKuIUG8HKquY"
      },
      "source": [
        "### Simple run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuonZs1WasN1"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save --name \"mstCPUPrim.cu\" --group \"CPU\"\n",
        "\n",
        "// Header file di C++\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <vector>\n",
        "#include <algorithm>\n",
        "\n",
        "// Header file C\n",
        "#include <time.h>\n",
        "#include <limits.h>\n",
        "\n",
        "// Custom files\n",
        "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
        "#include \"../../GPUcomputing/utils/common.h\"\n",
        "#include \"mst.h\"\n",
        "#include \"../COMMON/sharedMacros.h\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "mst *primMST (uint size, default_random_engine &eng, GraphStruct *str) {\n",
        "    // Initialize the tree to the emptyset\n",
        "    mst *tree = new mst();\n",
        "    tree->stree = new vector<int>[size];\n",
        "    tree->totalWeight = 0;\n",
        "\n",
        "    // Initialize the vertex set U to a random vertex in the graph\n",
        "    vector<node> U;\n",
        "    vector<node> Remaining;\n",
        "    uniform_real_distribution<> randR(0.0, 1.0);\n",
        "    node randV;\n",
        "    randV = (node)(randR(eng) * size);\n",
        "    cout << \"Source for the MST: \" << randV << endl;\n",
        "    U.push_back(randV);\n",
        "    for (node i = 0; i < size; i++) {\n",
        "        if (i != randV) {\n",
        "            Remaining.push_back(i);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // While the set U is different from the set V\n",
        "    while (!Remaining.empty()) {\n",
        "\n",
        "      /*\n",
        "       * Find the edge with the lowest weight in the adjacency list of the\n",
        "       * nodes currently in U\n",
        "      */\n",
        "      int minimum = INT_MAX;\n",
        "      int sourceCandidate = -1;\n",
        "      int destinationCandidate = -1;\n",
        "      for (node i = 0; i < U.size(); i++) {\n",
        "          for (uint j = 0; j < str->deg(U[i]); j++) {\n",
        "              node neigh = str->getNeigh(U[i], j);\n",
        "              uint occ = count(U.begin(), U.end(), neigh);\n",
        "              if (occ == 0 && (str->getWeight(U[i], j) < minimum ||\n",
        "                  (str->getWeight(U[i], j) == minimum && neigh < destinationCandidate))) {\n",
        "                  minimum = str->getWeight(U[i], j);\n",
        "                  sourceCandidate = U[i];\n",
        "                  destinationCandidate = neigh;\n",
        "              }\n",
        "          }\n",
        "      }\n",
        "\n",
        "      if (sourceCandidate != -1) {\n",
        "          if (DEBUGGING) {\n",
        "              cout << \"Source: \" << sourceCandidate << \" Destination: \" << destinationCandidate << \" Weight: \" << minimum << endl;\n",
        "          }\n",
        "\n",
        "          // Add the newfound edge to the mst\n",
        "          tree->stree[sourceCandidate].push_back(destinationCandidate);\n",
        "          tree->totalWeight += minimum;\n",
        "\n",
        "          // Add the destination vertex to the set U\n",
        "          U.push_back(destinationCandidate);\n",
        "\n",
        "          // Remove the element using erase function and iterators\n",
        "          auto it = find(Remaining.begin(), Remaining.end(), destinationCandidate);\n",
        "\n",
        "          // If element is found found, erase it\n",
        "          if (it != Remaining.end()) {\n",
        "              Remaining.erase(it);\n",
        "          }\n",
        "      }\n",
        "\n",
        "      else {\n",
        "          cout << \"CPU-MST [Error]: The graph appears to be disconnected\" << endl;\n",
        "          return tree;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    return tree;\n",
        "}\n",
        "\n",
        "int main () {\n",
        "    // Generation of a random graph\n",
        "    std::random_device rd;\n",
        "    std::default_random_engine fixedEng(FIXED_SEED);\n",
        "    std::default_random_engine variableEng(rd());\n",
        "    Graph *graph;\n",
        "    char path[] = \"/content/testing/cpuTest.txt\";\n",
        "    uint size = SIZE;\n",
        "    uint maxWeight = MAX_WEIGHT;\n",
        "    float prob = .5;\n",
        "    bool GPUEnabled = 0;\n",
        "\n",
        "    // Definition of testing variables\n",
        "    uint repetitions;\n",
        "    uint sizeArray[] = {50, 500, 1000};\n",
        "    FILE *fptr;\n",
        "\n",
        "    // Setup the testing variables\n",
        "    if (TESTING) {\n",
        "        repetitions = TEST_SIZE;\n",
        "        fptr = fopen(path, \"w\");\n",
        "        if (!fptr) {\n",
        "            std::perror(\"File opening failed\");\n",
        "            return -1;\n",
        "        }\n",
        "    }\n",
        "    else {\n",
        "        repetitions = 1;\n",
        "    }\n",
        "\n",
        "    // events to measure time\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Call to the Prim MST solver\n",
        "    for (uint i = 0; i < repetitions; i++) {\n",
        "        // Generation of the random graph\n",
        "        if (TESTING) {\n",
        "            size = sizeArray[i];\n",
        "        }\n",
        "        graph = new Graph(size, GPUEnabled);\n",
        "        graph->randGraph(prob, true, maxWeight, fixedEng);\n",
        "\n",
        "        // Test the printing procedure\n",
        "        if (size < 15) {\n",
        "            cout << \"Printing the graph\" << endl;\n",
        "            graph->print(true);\n",
        "        }\n",
        "\n",
        "        cout << \"Computing the MST solution for a graph of size \" << size << endl;\n",
        "        cudaEventRecord(start);\n",
        "        mst *tree = primMST(size, variableEng, graph->getStruct());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        float milliseconds;\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        float CPUtime = milliseconds / 1000.0;\n",
        "        cout << \"Time elapsed for CPU computation: \" << CPUtime << endl;\n",
        "        if (size < 15) {\n",
        "            cout << \"MST solution\" << endl;\n",
        "            for (int i = 0; i < size; ++i) {\n",
        "                cout << i << \": \";\n",
        "                for (int j = 0; j < tree->stree[i].size(); ++j) {\n",
        "                    cout << tree->stree[i][j] << \" \";\n",
        "                }\n",
        "                cout << endl;\n",
        "            }\n",
        "        }\n",
        "        cout << \"Total weight: \" << tree->totalWeight << endl;\n",
        "        cout << \"\\n\\n\\n\\n\";\n",
        "        if (TESTING) {\n",
        "            fprintf(fptr, \"%d,%d,%f,\\n\", size, tree->totalWeight, CPUtime);\n",
        "        }\n",
        "\n",
        "        // Memory deallocation\n",
        "        delete tree;\n",
        "        delete graph;\n",
        "        tree = NULL;\n",
        "        graph = NULL;\n",
        "    }\n",
        "\n",
        "    if (TESTING) {\n",
        "        fclose(fptr);\n",
        "    }\n",
        "\n",
        "    CHECK(cudaEventDestroy(start));\n",
        "    CHECK(cudaEventDestroy(stop));\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWqBh9Rd-y3t"
      },
      "outputs": [],
      "source": [
        "# Compilazione ed esecuzione\n",
        "\n",
        "!nvcc -arch=sm_75  GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/CPU/mstCPUPrim.cu -o mstCPUPrim\n",
        "!./mstCPUPrim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foTWFNqyuMIw"
      },
      "source": [
        "## MST solution using the Prim solver with binary heap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "NjPq8Y4QuL2M"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save --name \"CPUEfficientMst.cu\" --group \"CPU\"\n",
        "\n",
        "// Header file di C++\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <vector>\n",
        "#include <algorithm>\n",
        "#include <string>\n",
        "\n",
        "// Header file C\n",
        "#include <time.h>\n",
        "#include <limits.h>\n",
        "\n",
        "// Custom files\n",
        "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
        "#include \"../../GPUcomputing/utils/common.h\"\n",
        "#include \"../COMMON/sharedMacros.h\"\n",
        "#include \"mst.h\"\n",
        "#include \"heap.h\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "mst *primMST (uint size, default_random_engine &eng, GraphStruct *str) {\n",
        "    // Setup the mst\n",
        "    mst *tree = new mst();\n",
        "    tree->stree = new vector<int>[size];\n",
        "    tree->totalWeight = 0;\n",
        "\n",
        "    // Select a starting node\n",
        "    vector<node> Remaining;\n",
        "    uniform_real_distribution<> randR(0.0, 1.0);\n",
        "    node randV;\n",
        "    randV = (node)(randR(eng) * size);\n",
        "    cout << \"Source for the MST: \" << randV << endl;\n",
        "\n",
        "    // Initializing the heap structure\n",
        "    Heap *heap = new Heap(size);\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        int offset = str->isNeighbor(randV, i);\n",
        "        if (offset >= 0) {\n",
        "            heap->insert(randV, i, offset, str->getWeight(randV, offset));\n",
        "        }\n",
        "        else if (i != randV) {\n",
        "            heap->insert(UINT_MAX, i, UINT_MAX, INT_MAX);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // While the heap is not empty\n",
        "    while (!heap->isEmpty()) {\n",
        "        edge candidateEdge = heap->pop();\n",
        "        node destinationCandidate = candidateEdge.destination;\n",
        "\n",
        "        for (uint i = 0; i < str->deg(destinationCandidate); i++) {\n",
        "            node neigh = str->getNeigh(destinationCandidate, i);\n",
        "            node weight = str->getWeight(destinationCandidate, i);\n",
        "            uint pos = heap->getPosition(neigh);\n",
        "            bool inMst = false;\n",
        "\n",
        "            if (pos == UINT_MAX) {\n",
        "                inMst = true;\n",
        "            }\n",
        "\n",
        "            if (!inMst && weight < heap->getKey(pos).weight) {\n",
        "                heap->keyDecrease(pos, destinationCandidate, weight);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Add the newfound edge to the mst\n",
        "        tree->totalWeight += candidateEdge.weight;\n",
        "        tree->stree[candidateEdge.source].push_back(candidateEdge.destination);\n",
        "    }\n",
        "\n",
        "    delete heap;\n",
        "    heap = NULL;\n",
        "\n",
        "    return tree;\n",
        "}\n",
        "\n",
        "int main () {\n",
        "    // Generation of a random graph\n",
        "    std::random_device rd;\n",
        "    std::default_random_engine fixedEng(FIXED_SEED);\n",
        "    std::default_random_engine variableEng(rd());\n",
        "    Graph *graph;\n",
        "    //string spath = LOGPATH + to_string(SIZE) + \"_\" + to_string(FIXED_SEED) + \".txt\";\n",
        "    //char path[] = spath.c_str();\n",
        "    uint size = SIZE;\n",
        "    uint maxWeight = MAX_WEIGHT;\n",
        "    float prob = .5;\n",
        "    bool GPUEnabled = 0;\n",
        "\n",
        "    //cout << path << endl;\n",
        "    //return 0;\n",
        "\n",
        "    // Definition of testing variables\n",
        "    uint repetitions;\n",
        "    uint sizeArray[] = {50, 500, 1000};\n",
        "    FILE *fptr;\n",
        "\n",
        "    // Setup the testing variables\n",
        "    if (TESTING) {\n",
        "        repetitions = TEST_SIZE;\n",
        "        //fptr = fopen(path, \"w\");\n",
        "        if (!fptr) {\n",
        "            std::perror(\"File opening failed\");\n",
        "            return -1;\n",
        "        }\n",
        "    }\n",
        "    else {\n",
        "        repetitions = 1;\n",
        "    }\n",
        "\n",
        "    // events to measure time\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Call to the Prim MST solver\n",
        "    for (uint i = 0; i < repetitions; i++) {\n",
        "        // Generation of the random graph\n",
        "        if (TESTING) {\n",
        "            size = sizeArray[i];\n",
        "        }\n",
        "        graph = new Graph(size, GPUEnabled);\n",
        "        graph->randGraph(prob, true, maxWeight, fixedEng);\n",
        "\n",
        "        // Test the printing procedure\n",
        "        if (size < 15) {\n",
        "            cout << \"Printing the graph\" << endl;\n",
        "            graph->print(true);\n",
        "        }\n",
        "        cudaEventRecord(start);\n",
        "        cout << \"Computing the MST solution for a graph of size \" << size << endl;\n",
        "        mst *tree = primMST(size, variableEng, graph->getStruct());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        float milliseconds;\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        float CPUtime = milliseconds / 1000.0;\n",
        "        cout << \"Time elapsed for CPU computation: \" << CPUtime << endl;\n",
        "        cout << \"Total weight: \" << tree->totalWeight << endl;\n",
        "        cout << \"\\n\\n\\n\\n\";\n",
        "        if (TESTING) {\n",
        "            fprintf(fptr, \"%d,%d,\\n\", size, tree->totalWeight);\n",
        "        }\n",
        "\n",
        "        // Memory deallocation\n",
        "        delete graph;\n",
        "        delete tree;\n",
        "        tree = NULL;\n",
        "        graph = NULL;\n",
        "    }\n",
        "\n",
        "    if (TESTING) {\n",
        "        fclose(fptr);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urv_sqyZ07NV",
        "outputId": "88dba576-740a-4fde-d11d-77f5b6a27746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01msrc/CPU/CPUEfficientMst.cu(103)\u001b[0m: \u001b[01;35mwarning\u001b[0m #549-D: variable \u001b[01m\"fptr\"\u001b[0m is used before its value is set\n",
            "          if (!fptr) {\n",
            "               ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01msrc/CPU/CPUEfficientMst.cu(103)\u001b[0m: \u001b[01;35mwarning\u001b[0m #549-D: variable \u001b[01m\"fptr\"\u001b[0m is used before its value is set\n",
            "          if (!fptr) {\n",
            "               ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "Computing the MST solution for a graph of size 20000\n",
            "Source for the MST: 11082\n",
            "Time elapsed for CPU computation: 6.59369\n",
            "Total weight: 111239\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compilazione ed esecuzione\n",
        "\n",
        "!nvcc -arch=sm_75  GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/CPU/CPUEfficientMst.cu -o CPUEfficientMst\n",
        "!./CPUEfficientMst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlgeSiIHTcFA"
      },
      "source": [
        "# GPU zone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KqoBgM--a13"
      },
      "source": [
        "## Hybrid approach\n",
        "\n",
        "The code below uses an hybrid approach where a part of the code is working with the GPU and a part of the code is using the CPU, namely:\n",
        "\n",
        "- Finding the cheapest edge for every node is implemented using a GPU kernel\n",
        "- The scan operation is implemented with a CPU procedure because it's more efficient than the naive GPU counterpart\n",
        "- The removal of mirrored edges is implemented using a GPU kernel\n",
        "- Finding the connected components is done through a recursive GPU kernel\n",
        "- Calculating the outdegrees for the supervertices is done with a GPU kernel\n",
        "- The new graph allocation is done through a CPU function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "4CkG5s5Ph76C"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save --name \"mstHBD.cu\" --group \"GPU\"\n",
        "\n",
        "// Header file di C++\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <vector>\n",
        "#include <algorithm>\n",
        "\n",
        "// Header file C\n",
        "#include <time.h>\n",
        "#include <limits.h>\n",
        "\n",
        "// Custom files\n",
        "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
        "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
        "#include \"../../GPUcomputing/utils/common.h\"\n",
        "#include \"../COMMON/sharedMacros.h\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/*****\n",
        "* Device function that gets the degree of a certain node\n",
        "* @param str - The structure of the graph\n",
        "* @param i - The node we are interested in\n",
        "*****/\n",
        "__device__ node d_deg (GraphStruct *str, node i) {\n",
        "    return str->cumDegs[i + 1] - str->cumDegs[i];\n",
        "}\n",
        "\n",
        "/*****\n",
        "* Device function that gets the weight of a certain edge\n",
        "* @param str - The structure of the graph\n",
        "* @param i - The source node of the edge\n",
        "* @param offset - The offset of the destination node in the adjacency list of\n",
        "*                 the source\n",
        "*****/\n",
        "__device__ int d_getWeight (GraphStruct *str, node i, uint offset) {\n",
        "    return str->weights[str->cumDegs[i] + offset];\n",
        "}\n",
        "\n",
        "/*****\n",
        "* Device function that gets the neighbour of a certain node\n",
        "* @param str - The structure of the graph\n",
        "* @param i - The source node of the edge\n",
        "* @param offset - The offset of the destination node in the adjacency list of\n",
        "*                 the source\n",
        "*****/\n",
        "__device__ node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
        "    return str->neighs[str->cumDegs[i] + offset];\n",
        "}\n",
        "\n",
        "__device__ uint d_getRoot (uint i, uint *d_flag, uint *d_colors) {\n",
        "    return max(0, d_flag[d_colors[i]] - 1);\n",
        "}\n",
        "\n",
        "uint getRoot (uint i, uint *flag, uint *colors) {\n",
        "    return max(0, flag[colors[i]] - 1);\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Kernel that finds the cheapest edge in the adjacency list of every node\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree (edges saved as offsets in the CSR\n",
        "*                       representation of the graph)\n",
        "*****/\n",
        "__global__ void findCheapest (GraphStruct *str, uint *d_candidates) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    // Initialize the minimum value\n",
        "    uint minimum = UINT_MAX;\n",
        "    int minimumWeight = INT_MAX;\n",
        "\n",
        "    // Find the cheapest edge in each adjacency list\n",
        "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
        "        int edgeWeight = d_getWeight(str, idx, i);\n",
        "        if (edgeWeight < minimumWeight) {\n",
        "            minimumWeight = edgeWeight;\n",
        "            minimum = i;\n",
        "        }\n",
        "        else if (edgeWeight == minimumWeight &&\n",
        "                 d_getNeigh(str, idx, i) < d_getNeigh(str, idx, minimum)) {\n",
        "            minimumWeight = edgeWeight;\n",
        "            minimum = i;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Update the return vector\n",
        "    d_candidates[idx] = minimum;\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Kernel that removes the mirrored edges from the graph. A mirrored edge is\n",
        "* simply an edge pointing from the source to the destination and vice versa in\n",
        "* an oriented graph, the removal logic is to cut the edge with the lowest source\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree (edges saved as offsets in the CSR\n",
        "*                       representation of the graph)\n",
        "*****/\n",
        "__global__ void mirroredEdgesRemoval (GraphStruct *str, uint *d_candidates, int *d_weight) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    uint destinationOffset = d_candidates[idx];\n",
        "    node destination = d_getNeigh(str, idx, destinationOffset);\n",
        "    if (idx < destination) {\n",
        "        uint sourceOffset = d_candidates[destination];\n",
        "        node destinationNeigh = d_getNeigh(str, destination, sourceOffset);\n",
        "\n",
        "        // The vertex cannot be a candidate anymore because it would create a cycle\n",
        "        if (destinationNeigh == idx) {\n",
        "            d_candidates[idx] = UINT_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (d_candidates[idx] != UINT_MAX) {\n",
        "        atomicAdd(d_weight, d_getWeight(str, idx, d_candidates[idx]));\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Helper device function that recursively colors the nodes of the graph\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree (edges saved as offsets in the CSR\n",
        "*                       representation of the graph)\n",
        "* @param i - The index of the node to be colored\n",
        "* @param d_colors - The device-level array of colors assigned to each vertex\n",
        "*****/\n",
        "__device__ uint *d_recursiveColorationHelper (GraphStruct *str, uint *d_candidates, node i, uint *d_colors) {\n",
        "    uint color = UINT_MAX;\n",
        "    if (d_candidates[i] == UINT_MAX) {\n",
        "        color = i;\n",
        "    }\n",
        "    else {\n",
        "        node neigh = d_getNeigh(str, i, d_candidates[i]);\n",
        "        color = d_recursiveColorationHelper(str, d_candidates, neigh, d_colors)[neigh];\n",
        "    }\n",
        "\n",
        "    if (color != UINT_MAX) {\n",
        "        d_colors[i] = color;\n",
        "    }\n",
        "    return d_colors;\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Kernel that recognizes the connected components in the graph and colors them\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree\n",
        "* @param d_colors - The device-level array of colors assigned to each vertex\n",
        "*****/\n",
        "__global__ void colorationProcess(GraphStruct *str, uint *d_candidates, uint *d_colors) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    d_recursiveColorationHelper(str, d_candidates, idx, d_colors);\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void cumulatedDegreeUpdate(GraphStruct *str, uint *d_cumDegs, uint *d_colors, uint *d_flag) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    uint color = d_colors[idx];\n",
        "    node svSuccessor = d_getRoot(idx, d_flag, d_colors) + 1;\n",
        "    uint sum = 0;\n",
        "\n",
        "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
        "        node neigh = d_getNeigh(str, idx, i);\n",
        "        uint neighColor = d_colors[neigh];\n",
        "\n",
        "        if (color != neighColor) {\n",
        "            sum++;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    atomicAdd(&(d_cumDegs[svSuccessor]), sum);\n",
        "}\n",
        "\n",
        "\n",
        "uint *CPUScan(uint *input, uint size) {\n",
        "    for (uint i = 1; i < size; i++) {\n",
        "        input[i] = input[i - 1] + input[i];\n",
        "    }\n",
        "    return input;\n",
        "}\n",
        "\n",
        "\n",
        "int main () {\n",
        "    // Generation of a random graph\n",
        "    std::random_device rd;\n",
        "    std::default_random_engine eng(FIXED_SEED);\n",
        "    uint maxWeight = MAX_WEIGHT;\n",
        "    float prob = .5;\n",
        "    bool GPUEnabled = 1;\n",
        "    Graph *graphPointer;\n",
        "    Graph graph(SIZE, GPUEnabled);\n",
        "    graphPointer = &graph;\n",
        "  \tgraphPointer->randGraph(prob, true, maxWeight, eng);\n",
        "    /**************************************************/\n",
        "\n",
        "\n",
        "    // Checking if the random graph is connected\n",
        "    if (!graphPointer->isConnected()) {\n",
        "        cout << \"The graph is not connected\" << endl;\n",
        "        return -1;\n",
        "    }\n",
        "    /************/\n",
        "\n",
        "\n",
        "    uint iterations = 0;\n",
        "\n",
        "\n",
        "    // Configuration of the GPU kernel\n",
        "    uint blockDim = BLOCK_SIZE;\n",
        "    uint *candidates;\n",
        "    /***************/\n",
        "\n",
        "\n",
        "    // Events to measure time\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    float milliseconds;\n",
        "    float spliTime = 0;\n",
        "    float totalTime = 0;\n",
        "    /******************/\n",
        "\n",
        "\n",
        "    // Variables calculating the MST weight\n",
        "    int mstWeight = 0;\n",
        "    int *d_mstWeight;\n",
        "    CHECK(cudaMalloc((void **)&d_mstWeight, sizeof(int)));\n",
        "    CHECK(cudaMemcpy(d_mstWeight, &mstWeight, sizeof(int), cudaMemcpyHostToDevice));\n",
        "    /******************************************************************************/\n",
        "\n",
        "\n",
        "    // Main block of the algorithm\n",
        "    while (graphPointer->getStruct()->nodeSize > 1) {\n",
        "        // Initialization of the variables associated with the graph\n",
        "        GraphStruct *str = graphPointer->getStruct();\n",
        "        uint size = str->nodeSize;\n",
        "        uint edgeSize = str->edgeSize;\n",
        "        cout << \"Processing a graph of size: \" << size << \" with \" << edgeSize << \" edges.\\n\\n\";\n",
        "        uint gridDim = (size + blockDim - 1) / blockDim;\n",
        "        if (DEBUGGING && size < 15 && str->edgeSize < 100) {\n",
        "            graphPointer->print(true);\n",
        "            print_d<<<1, 1>>>(str, 1);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "        }\n",
        "        candidates = new uint[size];\n",
        "        /**************************/\n",
        "\n",
        "        // First setp of the algorithm\n",
        "        uint *d_candidates;\n",
        "        CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
        "        cout << \"Launching kernel FIND CHEAPEST -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "        cudaEventRecord(start);\n",
        "        findCheapest<<<gridDim, blockDim>>>(str, d_candidates);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", spliTime);\n",
        "        totalTime += spliTime;\n",
        "        /********************/\n",
        "\n",
        "        // ~Debugging~ print the cheapest edge for every vertex\n",
        "        if (DEBUGGING && size < 15) {\n",
        "            cout << \"The cheapest edge for every vertex\" << endl;\n",
        "            CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                cout << \"node (\" << i << \") -> \" << str->getNeigh(i, candidates[i]) << \"(\"\n",
        "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
        "            }\n",
        "            cout << \"\\n\\n\\n\";\n",
        "        }\n",
        "        /*******************/\n",
        "\n",
        "\n",
        "\n",
        "        // Second step of the algorithm\n",
        "        cout << \"Launching kernel MIRRORED EDGES REMOVAL -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "        cudaEventRecord(start);\n",
        "        mirroredEdgesRemoval<<<gridDim, blockDim>>>(str, d_candidates, d_mstWeight);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "        CHECK(cudaMemcpy(&mstWeight, d_mstWeight, sizeof(int), cudaMemcpyDeviceToHost));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
        "        totalTime += spliTime;\n",
        "        /********************/\n",
        "\n",
        "        // ~Debugging~ print the cheapest edge for every vertex update\n",
        "        if (DEBUGGING && size < 15) {\n",
        "            cout << \"Update of the cheapest edge for every vertex\" << endl;\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                cout << \"node (\" << i << \") -> \";\n",
        "                if (candidates[i] != UINT_MAX) {\n",
        "                    cout << str->getNeigh(i, candidates[i]) << \"(\"\n",
        "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
        "                }\n",
        "                else {\n",
        "                    cout << \"NULL\" << endl;\n",
        "                }\n",
        "            }\n",
        "            printf (\"%d\\n\", mstWeight);\n",
        "        }\n",
        "        /*****************************/\n",
        "        printf (\"%d\\n\", mstWeight);\n",
        "\n",
        "\n",
        "\n",
        "        // Third step of the algorithm\n",
        "        cout << \"Launching kernel COLORATION PROCESS -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "\n",
        "        // Initialize the color array\n",
        "        uint *colors = new uint[size];\n",
        "        uint *d_colors;\n",
        "        CHECK(cudaMalloc((void**)&d_colors, size * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_colors, UINT_MAX, size * sizeof(uint)));\n",
        "        /*********************************************************/\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        colorationProcess<<<gridDim, blockDim>>>(str, d_candidates, d_colors);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        CHECK(cudaMemcpy(colors, d_colors, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
        "        totalTime += spliTime;\n",
        "\n",
        "        // Print the coloring\n",
        "        if (DEBUGGING) {\n",
        "            uint *checkColoring = new uint[size];\n",
        "\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                checkColoring[i] = 0;\n",
        "            }\n",
        "\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                checkColoring[colors[i]]++;\n",
        "            }\n",
        "\n",
        "            uint nonZeroColors = 0;\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                if (checkColoring[i] != 0) {\n",
        "                    cout << \"color \" << i << \"\\t\" << checkColoring[i] << endl;\n",
        "                    nonZeroColors++;\n",
        "                }\n",
        "            }\n",
        "\n",
        "            cout << \"There is a total of \" << nonZeroColors << \" colors\" << endl;\n",
        "\n",
        "            cout << \"\\n\\n\\n\";\n",
        "        }\n",
        "        /*******************/\n",
        "\n",
        "        /**\n",
        "         * If the coloring coming out of the last kernel contains only one color\n",
        "         * then it means that the edge added in the last step was the one needed\n",
        "         * to merge the partial trees\n",
        "         **/\n",
        "        uint color = colors[0];\n",
        "        bool uniqueColor = true;\n",
        "        for (uint i = 1; i < size; i++) {\n",
        "            if (colors[i] != color) {\n",
        "                uniqueColor = false;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "        if (uniqueColor) {\n",
        "            cout << \"THE CALCULATION OF THE MST IS COMPLETE\\n\";\n",
        "            cout << \"THE MST WEIGHT IS: \" << mstWeight << endl;\n",
        "            printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
        "\n",
        "            // Cuda memory deallocation\n",
        "            CHECK(cudaEventDestroy(start));\n",
        "            CHECK(cudaEventDestroy(stop));\n",
        "            CHECK(cudaFree(d_candidates));\n",
        "            CHECK(cudaFree(d_colors));\n",
        "\n",
        "            // Host memory deallocation\n",
        "            delete[] candidates;\n",
        "            delete[] colors;\n",
        "\n",
        "            return 0;\n",
        "        }\n",
        "        /***********/\n",
        "\n",
        "\n",
        "\n",
        "        // Fourth step of the algorithm\n",
        "        cout << \"Launching a round of CPU scan\\n\\n\" << endl;\n",
        "        uint *flag = new uint[size];\n",
        "        for (uint i = 0; i < size; i++) {\n",
        "            flag[i] = (colors[i] == i) ? 1 : 0;\n",
        "        }\n",
        "        cudaEventRecord(start);\n",
        "        flag = CPUScan(flag, size);\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Doing the prefix sum of the auxiliary flag array took: %.5f seconds\\n\\n\", spliTime);\n",
        "        totalTime += spliTime;\n",
        "        if (DEBUGGING) {\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                if (colors[i] == i) {\n",
        "                    cout << \"Mapping color \" << i << \" to \" << getRoot(i, flag, colors) << endl;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        uint *d_flag;\n",
        "\n",
        "        CHECK(cudaMalloc((void**)&d_flag, (size) * sizeof(uint)));\n",
        "        CHECK(cudaMemcpy(d_flag, flag, (size) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "        /*****************************************************************************/\n",
        "\n",
        "\n",
        "\n",
        "        // Fifth step of the algorithm\n",
        "\n",
        "        // Allocating resources for the new cumulated degrees array\n",
        "        uint newNodeSize = flag[size - 1];\n",
        "        uint cumDegSize = newNodeSize + 1;\n",
        "        uint *cumDegs = new uint[cumDegSize];\n",
        "        uint *d_cumDegs;\n",
        "        CHECK(cudaMalloc((void**)&d_cumDegs, (cumDegSize) * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
        "        /***********************************************************/\n",
        "\n",
        "        cout << \"Launching kernel CUMULATED DEGREE UPDATE -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        cumulatedDegreeUpdate<<<gridDim, blockDim>>>(str, d_cumDegs, d_colors, d_flag);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Doing the computation of the cumulated degrees took: %.5f seconds\\n\\n\", spliTime);\n",
        "        CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "\n",
        "        // ~Debugging~ looking for errors in the cumulated degrees array\n",
        "        if (DEBUGGING) {\n",
        "            uint *checkDegs = new uint[cumDegSize];\n",
        "            for (uint i = 0; i < cumDegSize; i++) {\n",
        "                checkDegs[i] = 0;\n",
        "            }\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                uint color = colors[i];\n",
        "                node svSuccessor = getRoot(i, flag, colors) + 1;\n",
        "                uint sum = 0;\n",
        "\n",
        "                for (uint j = 0; j < str->deg(i); j++) {\n",
        "                    node neigh = str->getNeigh(i, j);\n",
        "                    uint neighColor = colors[neigh];\n",
        "\n",
        "                    if (color != neighColor) {\n",
        "                        sum++;\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                checkDegs[svSuccessor] += sum;\n",
        "            }\n",
        "            for (uint i = 0; i < cumDegSize; i++) {\n",
        "                if (checkDegs[i] != cumDegs[i]) {\n",
        "                    cout << i << \" \" << checkDegs[i] << \" \" << cumDegs[i] << endl;\n",
        "                    return -1;\n",
        "                }\n",
        "            }\n",
        "            cout << \"The CPU check vector and the GPU computed one are the same\" << endl;\n",
        "            delete[] checkDegs;\n",
        "        }\n",
        "        /*********************/\n",
        "\n",
        "\n",
        "        // Perform another prefix sum on the cumDegrees array\n",
        "        cout << \"Launching a round of CPU scan\\n\\n\" << endl;\n",
        "        cudaEventRecord(start);\n",
        "        cumDegs = CPUScan(cumDegs, cumDegSize);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        printf(\"Doing the scan of the new cumDegs array took: %.5f seconds\\n\\n\", milliseconds/1000);\n",
        "        spliTime += milliseconds / 1000.0;\n",
        "\n",
        "        // ~Debugging~ print the results of the scan operation on the cum degrees array\n",
        "        if (DEBUGGING) {\n",
        "            uint j = 0;\n",
        "            for (uint i = 0; i < cumDegSize; i++) {\n",
        "                cout << cumDegs[i] << \"   \";\n",
        "                j++;\n",
        "                if (j == 10) {\n",
        "                    cout << endl;\n",
        "                    j = 0;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        /****************/\n",
        "\n",
        "\n",
        "        // Allocating space for the arrays in the newly contracted graph\n",
        "        uint newEdgeSize = cumDegs[cumDegSize - 1];\n",
        "        node *newNeighs = new node[newEdgeSize];\n",
        "        uint *newWeights = new uint[newEdgeSize];\n",
        "        /***************************************/\n",
        "\n",
        "        // Copy the contents of cumDegs into a new array\n",
        "        uint *cCumDegs = new uint[cumDegSize];\n",
        "        for (uint i = 0; i < cumDegSize; i++) {\n",
        "            cCumDegs[i] = cumDegs[i];\n",
        "        }\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        for (uint i = 0; i < size; i++) {\n",
        "            uint color = colors[i];\n",
        "            node superVertex = getRoot(i, flag, colors);\n",
        "\n",
        "            for (uint j = 0; j < str->deg(i); j++) {\n",
        "                node neigh = str->getNeigh(i, j);\n",
        "                uint neighColor = colors[neigh];\n",
        "\n",
        "                if (color != neighColor) {\n",
        "                    int weight = str->getWeight(i, j);\n",
        "                    uint position = cCumDegs[superVertex];\n",
        "                    newNeighs[position] = getRoot(neigh, flag, colors);\n",
        "                    newWeights[position] = weight;\n",
        "                    cCumDegs[superVertex]++;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        printf(\"The construction of the new neighbour and weight arrays took: %.5f seconds\\n\\n\", milliseconds/1000);\n",
        "        spliTime += milliseconds / 1000.0;\n",
        "\n",
        "\n",
        "\n",
        "        // Reconstructing the graph\n",
        "        graphPointer->copyConstructor(newNodeSize, newEdgeSize, newNeighs, newWeights, cumDegs);\n",
        "        printf(\"----------------------------------\\n\\n\");\n",
        "        /***********************************************/\n",
        "\n",
        "\n",
        "\n",
        "        // Updating the iteration information\n",
        "        totalTime += spliTime;\n",
        "        iterations++;\n",
        "        /***********/\n",
        "\n",
        "\n",
        "        // Cuda memory deallocation\n",
        "        CHECK(cudaFree(d_candidates));\n",
        "        CHECK(cudaFree(d_colors));\n",
        "        CHECK(cudaFree(d_flag));\n",
        "        CHECK(cudaFree(d_cumDegs));\n",
        "        /*************************/\n",
        "\n",
        "        // Host memory deallocation\n",
        "        delete[] candidates;\n",
        "        delete[] colors;\n",
        "        delete[] flag;\n",
        "        delete[] cumDegs;\n",
        "        delete[] newNeighs;\n",
        "        delete[] newWeights;\n",
        "        delete[] cCumDegs;\n",
        "        /****************/\n",
        "    }\n",
        "\n",
        "    printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
        "    printf(\"The calculation of the MST took %d iterations\\n\\n\", iterations);\n",
        "    printf(\"The total weight of the tree is %d\\n\", mstWeight);\n",
        "\n",
        "\n",
        "    CHECK(cudaEventDestroy(start));\n",
        "    CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL9T_IxiZvuv",
        "outputId": "ef07bda8-9d20-48a3-bf21-2f715c6edaec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas warning : Stack size for entry function '_Z17colorationProcessP11GraphStructPjS1_' cannot be statically determined\n",
            "Processing a graph of size: 20000 with 199990050 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (20, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 0.21779 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (20, 1, 1)\n",
            "Removing the mirrored edges required: 0.05990 seconds\n",
            "\n",
            "80484\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (20, 1, 1)\n",
            "Removing the mirrored edges required: 0.00007 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "\n",
            "\n",
            "Doing the prefix sum of the auxiliary flag array took: 0.00007 seconds\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (20, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.01221 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "\n",
            "\n",
            "Doing the scan of the new cumDegs array took: 0.00003 seconds\n",
            "\n",
            "The construction of the new neighbour and weight arrays took: 5.90433 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 4995 with 199931944 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (5, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 0.30730 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (5, 1, 1)\n",
            "Removing the mirrored edges required: 0.06095 seconds\n",
            "\n",
            "105640\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (5, 1, 1)\n",
            "Removing the mirrored edges required: 0.00003 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "\n",
            "\n",
            "Doing the prefix sum of the auxiliary flag array took: 0.00002 seconds\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (5, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.06600 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "\n",
            "\n",
            "Doing the scan of the new cumDegs array took: 0.00001 seconds\n",
            "\n",
            "The construction of the new neighbour and weight arrays took: 6.68306 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 970 with 199629554 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 1.08378 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.01363 seconds\n",
            "\n",
            "110463\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00004 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "\n",
            "\n",
            "Doing the prefix sum of the auxiliary flag array took: 0.00001 seconds\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.43221 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "\n",
            "\n",
            "Doing the scan of the new cumDegs array took: 0.00001 seconds\n",
            "\n",
            "The construction of the new neighbour and weight arrays took: 6.51093 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 149 with 197456180 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 1.72701 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00211 seconds\n",
            "\n",
            "111169\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00002 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "\n",
            "\n",
            "Doing the prefix sum of the auxiliary flag array took: 0.00000 seconds\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.74429 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "\n",
            "\n",
            "Doing the scan of the new cumDegs array took: 0.00001 seconds\n",
            "\n",
            "The construction of the new neighbour and weight arrays took: 5.75205 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 16 with 173633880 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 5.65565 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00056 seconds\n",
            "\n",
            "111226\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00002 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "\n",
            "\n",
            "Doing the prefix sum of the auxiliary flag array took: 0.00000 seconds\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 2.58358 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "\n",
            "\n",
            "Doing the scan of the new cumDegs array took: 0.00001 seconds\n",
            "\n",
            "The construction of the new neighbour and weight arrays took: 4.96688 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 4 with 107168814 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 5.19898 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00018 seconds\n",
            "\n",
            "111239\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00002 seconds\n",
            "\n",
            "THE CALCULATION OF THE MST IS COMPLETE\n",
            "THE MST WEIGHT IS: 111239\n",
            "Total elapsed time: 47.98376 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compilazione ed esecuzione\n",
        "\n",
        "!nvcc -arch=sm_75 GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/GPU/mstHBD.cu -o mstHBD\n",
        "!./mstHBD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OarhHSl-LfMO"
      },
      "source": [
        "## GPU only approach"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below is technically thought to work only on the GPU, the statement holds true with an asterisk (*)\n",
        "\n",
        "- A naive extraction of the methods calculating the graph contraction and the new cumulated degrees array has been done\n",
        "\n",
        "- The methods are not efficient to utilize the gpu's vector unit infact the methods that hurt the performance the most are the one looking for the cheapest edges and the one building the new arrays for the contracted graph\n",
        "\n",
        "- I wrote a function that is able to compute the scan in three phases:\n",
        "  - Compute the scan of the first part of the vector on the GPU using a work efficient technique (based on trees) [look at parprefix], this is computed on a window that is the maximum possible multiple of the smem window.\n",
        "  - Compute the scan of the rest of the array (if it's there is less than a smem window) on the CPU (*)\n",
        "  - Compute the scan of the auxiliary array containing the sum of the elements inside the block (*)\n",
        "  - Compute a final sum of the elements inside block j with the element in position j inside the new vector\n",
        "\n",
        "I decided to implement it this way because if the array is very small then computing the sum through a scan on the GPU is actually less efficient than doing it on the CPU.\n",
        "\n",
        "Finally the upgrade of this new version is not incredible but it's there, as an example:\n",
        "\n",
        "SIZE - 20000\n",
        "\n",
        "DENSITY - 0.5\n",
        "\n",
        "HBD_TIME - 47.98\n",
        "\n",
        "GPU_TIME - 41.67\n"
      ],
      "metadata": {
        "id": "WQg4HvyKHweg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "io-LW2esLlMF"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save --name \"mstGPUE.cu\" --group \"GPU\"\n",
        "\n",
        "// Header file di C++\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <vector>\n",
        "#include <algorithm>\n",
        "\n",
        "// Header file C\n",
        "#include <time.h>\n",
        "#include <limits.h>\n",
        "\n",
        "// Custom files\n",
        "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
        "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
        "#include \"../../GPUcomputing/utils/common.h\"\n",
        "#include \"../COMMON/sharedMacros.h\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/*****\n",
        "* Device function that gets the degree of a certain node\n",
        "* @param str - The structure of the graph\n",
        "* @param i - The node we are interested in\n",
        "*****/\n",
        "__device__ node d_deg (GraphStruct *str, node i) {\n",
        "    return str->cumDegs[i + 1] - str->cumDegs[i];\n",
        "}\n",
        "\n",
        "/*****\n",
        "* Device function that gets the weight of a certain edge\n",
        "* @param str - The structure of the graph\n",
        "* @param i - The source node of the edge\n",
        "* @param offset - The offset of the destination node in the adjacency list of\n",
        "*                 the source\n",
        "*****/\n",
        "__device__ int d_getWeight (GraphStruct *str, node i, uint offset) {\n",
        "    return str->weights[str->cumDegs[i] + offset];\n",
        "}\n",
        "\n",
        "/*****\n",
        "* Device function that gets the neighbour of a certain node\n",
        "* @param str - The structure of the graph\n",
        "* @param i - The source node of the edge\n",
        "* @param offset - The offset of the destination node in the adjacency list of\n",
        "*                 the source\n",
        "*****/\n",
        "__device__ node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
        "    return str->neighs[str->cumDegs[i] + offset];\n",
        "}\n",
        "\n",
        "__device__ uint d_getRoot (uint i, uint *d_flag, uint *d_colors) {\n",
        "    return max(0, d_flag[d_colors[i]]);\n",
        "}\n",
        "\n",
        "uint getRoot (uint i, uint *flag, uint *colors) {\n",
        "    return max(0, flag[colors[i]]);\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Kernel that finds the cheapest edge in the adjacency list of every node\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree (edges saved as offsets in the CSR\n",
        "*                       representation of the graph)\n",
        "*****/\n",
        "__global__ void findCheapest (GraphStruct *str, uint *d_candidates) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    // Initialize the minimum value\n",
        "    uint minimum = UINT_MAX;\n",
        "    int minimumWeight = INT_MAX;\n",
        "\n",
        "    // Find the cheapest edge in each adjacency list\n",
        "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
        "        int edgeWeight = d_getWeight(str, idx, i);\n",
        "        if (edgeWeight < minimumWeight) {\n",
        "            minimumWeight = edgeWeight;\n",
        "            minimum = i;\n",
        "        }\n",
        "        else if (edgeWeight == minimumWeight &&\n",
        "                 d_getNeigh(str, idx, i) < d_getNeigh(str, idx, minimum)) {\n",
        "            minimumWeight = edgeWeight;\n",
        "            minimum = i;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Update the return vector\n",
        "    d_candidates[idx] = minimum;\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Kernel that removes the mirrored edges from the graph. A mirrored edge is\n",
        "* simply an edge pointing from the source to the destination and vice versa in\n",
        "* an oriented graph, the removal logic is to cut the edge with the lowest source\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree (edges saved as offsets in the CSR\n",
        "*                       representation of the graph)\n",
        "*****/\n",
        "__global__ void mirroredEdgesRemoval (GraphStruct *str, uint *d_candidates, int *d_weight) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    uint destinationOffset = d_candidates[idx];\n",
        "    node destination = d_getNeigh(str, idx, destinationOffset);\n",
        "    if (idx < destination) {\n",
        "        uint sourceOffset = d_candidates[destination];\n",
        "        node destinationNeigh = d_getNeigh(str, destination, sourceOffset);\n",
        "\n",
        "        // The vertex cannot be a candidate anymore because it would create a cycle\n",
        "        if (destinationNeigh == idx) {\n",
        "            d_candidates[idx] = UINT_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (d_candidates[idx] != UINT_MAX) {\n",
        "        atomicAdd(d_weight, d_getWeight(str, idx, d_candidates[idx]));\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Helper device function that recursively colors the nodes of the graph\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree (edges saved as offsets in the CSR\n",
        "*                       representation of the graph)\n",
        "* @param i - The index of the node to be colored\n",
        "* @param d_colors - The device-level array of colors assigned to each vertex\n",
        "*****/\n",
        "__device__ uint *d_recursiveColorationHelper (GraphStruct *str, uint *d_candidates, node i, uint *d_colors) {\n",
        "    uint color = UINT_MAX;\n",
        "    if (d_candidates[i] == UINT_MAX) {\n",
        "        color = i;\n",
        "    }\n",
        "    else {\n",
        "        node neigh = d_getNeigh(str, i, d_candidates[i]);\n",
        "        color = d_recursiveColorationHelper(str, d_candidates, neigh, d_colors)[neigh];\n",
        "    }\n",
        "\n",
        "    if (color != UINT_MAX) {\n",
        "        d_colors[i] = color;\n",
        "    }\n",
        "    return d_colors;\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Kernel that recognizes the connected components in the graph and colors them\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree\n",
        "* @param d_colors - The device-level array of colors assigned to each vertex\n",
        "*****/\n",
        "__global__ void colorationProcess(GraphStruct *str, uint *d_candidates, uint *d_colors) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    d_recursiveColorationHelper(str, d_candidates, idx, d_colors);\n",
        "}\n",
        "\n",
        "\n",
        "/**\n",
        "* Kernel that computes the prefix sun of the auxiliary flag array, code taken\n",
        "* from the lectures and rearranged to follow the logic required for the\n",
        "* implementation of the algorithm\n",
        "* @param str - The structure of the graph\n",
        "* @param d_colors - The device-level array of colors assigned to each vertex\n",
        "* @param d_flag - The device-level array of flag values for the prefix sum.\n",
        "*                 d_flag[i] = 1 if and only if the vertex in position i has the\n",
        "*                 same color as the index => I recognize the root of the\n",
        "*                 connected component\n",
        "* @param d_auxiliarVector - The device-level array containing the last value of\n",
        "*                           the prefix sum calculation for every block\n",
        "**/\n",
        "__global__ void blockScan(uint *size, uint *input, uint *auxiliarVector) {\n",
        "   __shared__ uint smem[BLOCK_SIZE];\n",
        "   uint tid = threadIdx.x;\n",
        "   uint idx = tid + blockIdx.x * blockDim.x;\n",
        "\n",
        "   // If the index is out of bounds returns immediately\n",
        "    if (idx >= *size) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "   // Load input into shared memory.\n",
        "   smem[tid] = input[idx];\n",
        "   __syncthreads();\n",
        "\n",
        "   // do recursive sums\n",
        "   for (uint d = 1; d < BLOCK_SIZE; d *= 2) {\n",
        "      if (tid >= d)\n",
        "         smem[tid] += smem[tid - d];\n",
        "      __syncthreads();\n",
        "   }\n",
        "   input[idx] = smem[tid];\n",
        "   if (idx == ((blockIdx.x + 1) * blockDim.x - 1))\n",
        "      auxiliarVector[blockIdx.x] = input[idx];\n",
        "}\n",
        "\n",
        "\n",
        "/**\n",
        "* Auxiliary kernel that computes the sum of the partial values calculated using\n",
        "* the blockScan kernel\n",
        "* str - The structure of the graph\n",
        "* @param d_flag - The device-level array containing intermediate sums obtained\n",
        "*                 with the previous kernel\n",
        "* @param d_auxiliarVector - The device-level array containing the last value of\n",
        "*                           the prefix sum calculation for every block\n",
        "**/\n",
        "__global__ void sumBlockScan(uint *size, uint *input, uint *auxiliarVector) {\n",
        "   uint idx = threadIdx.x + blockIdx.x * blockDim.x;  // global index 0:n-1\n",
        "   uint s = 0;\n",
        "\n",
        "   // If the index is out of bounds returns immediately\n",
        "    if (idx >= *size) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "   if (blockIdx.x == 0) return;\n",
        "\n",
        "   for (uint j = 0; j < blockIdx.x; j++)\n",
        "      s += auxiliarVector[j];\n",
        "\n",
        "   // add term to input\n",
        "   input[idx] += s;\n",
        "}\n",
        "\n",
        "//*** SCAN FUNCTIONS ***//\n",
        "\n",
        "__global__ void prescan(uint *g_odata, uint *g_idata, uint *aux, int n, int smemSize)\n",
        "{\n",
        "  extern __shared__ int temp[];// allocated on invocation\n",
        "  int thid = threadIdx.x;\n",
        "  int offset = 1;\n",
        "  int idx = blockIdx.x * blockDim.x + thid;\n",
        "\n",
        "  temp[2*thid] = g_idata[2*idx]; // load input into shared memory\n",
        "  temp[2*thid+1] = g_idata[2*idx+1];\n",
        "\n",
        "  for (int d = n>>1; d > 0; d >>= 1) // build sum in place up the tree\n",
        "  {\n",
        "    __syncthreads();\n",
        "    if (thid < d)\n",
        "    {\n",
        "      int ai = offset*(2*thid+1)-1;\n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      if (bi < smemSize && ai < smemSize) {\n",
        "        temp[bi] += temp[ai];\n",
        "      }\n",
        "    }\n",
        "    offset *= 2;\n",
        "  }\n",
        "\n",
        "  if (thid == 0)\n",
        "  {\n",
        "    aux[blockIdx.x] = temp[smemSize - 1];\n",
        "    temp[smemSize - 1] = 0;\n",
        "  } // clear the last element\n",
        "\n",
        "  for (int d = 1; d < n; d *= 2) // traverse down tree & build scan\n",
        "  {\n",
        "    __syncthreads();\n",
        "    if (thid < d && offset > 0)\n",
        "    {\n",
        "      int ai = offset*(2*thid+1)-1;\n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      if (bi < smemSize && ai < smemSize) {\n",
        "        int t = temp[ai];\n",
        "        temp[ai] = temp[bi];\n",
        "        temp[bi] += t;\n",
        "      }\n",
        "    }\n",
        "    offset >>= 1;\n",
        "  }\n",
        "\n",
        "\n",
        "  __syncthreads();\n",
        "  if (idx <= (n / 2) - 1) {\n",
        "      g_odata[2*idx] = temp[2*thid]; // write results to device memory\n",
        "      g_odata[2*idx+1] = temp[2*thid+1];\n",
        "  }\n",
        "}\n",
        "\n",
        "void cpuScan(uint *array, int start, int end) {\n",
        "    if (end - start <= 1) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    int temp = array[start + 1];\n",
        "    array[start + 1] = array[start];\n",
        "    array[start] = 0;\n",
        "\n",
        "    for (uint i = start + 1; i < end - 1; i++) {\n",
        "        int sum = array[i] + temp;\n",
        "        temp = array[i + 1];\n",
        "        array[i + 1] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void final_sum(uint *g_odata, uint *aux, uint n)\n",
        "{\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "  if (blockIdx.x == 0 || 2 * idx >= n) {\n",
        "      return;\n",
        "  }\n",
        "\n",
        "  //printf(\"%d: ls - %d  rs - %d  aux - %d\\n\", idx, g_odata[2 * idx], g_odata[2 * idx + 1], aux[blockIdx.x - 1]);\n",
        "\n",
        "  if (2 * idx == n - 1) {\n",
        "      g_odata[2 * idx] += aux[blockIdx.x];\n",
        "      return;\n",
        "  }\n",
        "  g_odata[2 * idx] += aux[blockIdx.x];\n",
        "  g_odata[2 * idx + 1] += aux[blockIdx.x];\n",
        "}\n",
        "\n",
        "//****************//\n",
        "\n",
        "\n",
        "__global__ void cumulatedDegreeUpdate(GraphStruct *str, uint *d_cumDegs, uint *d_colors, uint *d_flag) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    uint color = d_colors[idx];\n",
        "    node svSuccessor = d_getRoot(idx, d_flag, d_colors);\n",
        "    uint sum = 0;\n",
        "\n",
        "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
        "        node neigh = d_getNeigh(str, idx, i);\n",
        "        uint neighColor = d_colors[neigh];\n",
        "\n",
        "        if (color != neighColor) {\n",
        "            sum++;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    atomicAdd(&(d_cumDegs[svSuccessor]), sum);\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void graphContraction(GraphStruct *str, uint *d_colors, uint *d_flag,\n",
        "                                 uint *d_cumDegs, node *d_newNeighs, uint *d_newWeights) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    uint color = d_colors[idx];\n",
        "    node superVertex = d_getRoot(idx, d_flag, d_colors);\n",
        "\n",
        "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
        "        node neigh = d_getNeigh(str, idx, i);\n",
        "        uint neighColor = d_colors[neigh];\n",
        "\n",
        "        if (color != neighColor) {\n",
        "            int weight = d_getWeight(str, idx, i);\n",
        "            uint position = atomicAdd(&(d_cumDegs[superVertex]), 1);\n",
        "            d_newNeighs[position] = d_getRoot(neigh, d_flag, d_colors);\n",
        "            d_newWeights[position] = weight;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main () {\n",
        "    // Generation of a random graph\n",
        "    std::random_device rd;\n",
        "    std::default_random_engine eng(FIXED_SEED);\n",
        "    uint maxWeight = MAX_WEIGHT;\n",
        "    float prob = .5;\n",
        "    bool GPUEnabled = 1;\n",
        "    Graph *graphPointer;\n",
        "    Graph graph(SIZE, GPUEnabled);\n",
        "    graphPointer = &graph;\n",
        "  \tgraphPointer->randGraph(prob, true, maxWeight, eng);\n",
        "    /**************************************************/\n",
        "\n",
        "\n",
        "    // Checking if the random graph is connected\n",
        "    if (!graphPointer->isConnected()) {\n",
        "        cout << \"The graph is not connected\" << endl;\n",
        "        return -1;\n",
        "    }\n",
        "    /************/\n",
        "\n",
        "\n",
        "    uint iterations = 0;\n",
        "\n",
        "\n",
        "    // Configuration of the GPU kernel\n",
        "    uint blockDim = BLOCK_SIZE;\n",
        "    uint *candidates;\n",
        "    /***************/\n",
        "\n",
        "\n",
        "    // Events to measure time\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    float milliseconds;\n",
        "    float spliTime = 0;\n",
        "    float totalTime = 0;\n",
        "    /******************/\n",
        "\n",
        "\n",
        "    // Variables calculating the MST weight\n",
        "    int mstWeight = 0;\n",
        "    int *d_mstWeight;\n",
        "    CHECK(cudaMalloc((void **)&d_mstWeight, sizeof(int)));\n",
        "    CHECK(cudaMemcpy(d_mstWeight, &mstWeight, sizeof(int), cudaMemcpyHostToDevice));\n",
        "    /******************************************************************************/\n",
        "\n",
        "\n",
        "    // Main block of the algorithm\n",
        "    while (graphPointer->getStruct()->nodeSize > 1) {\n",
        "        // Initialization of the variables associated with the graph\n",
        "        GraphStruct *str = graphPointer->getStruct();\n",
        "        uint size = str->nodeSize;\n",
        "        uint edgeSize = str->edgeSize;\n",
        "        cout << \"Processing a graph of size: \" << size << \" with \" << edgeSize << \" edges.\\n\\n\";\n",
        "        uint gridDim = (size + blockDim - 1) / blockDim;\n",
        "        if (DEBUGGING && size < 15 && str->edgeSize < 100) {\n",
        "            graphPointer->print(true);\n",
        "            print_d<<<1, 1>>>(str, 1);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "        }\n",
        "        candidates = new uint[size];\n",
        "        /******************************/\n",
        "\n",
        "        // First setp of the algorithm\n",
        "        uint *d_candidates;\n",
        "        CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
        "        cout << \"Launching kernel FIND CHEAPEST -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "        cudaEventRecord(start);\n",
        "        findCheapest<<<gridDim, blockDim>>>(str, d_candidates);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", spliTime);\n",
        "        totalTime += spliTime;\n",
        "        /********************/\n",
        "\n",
        "        // ~Debugging~ print the cheapest edge for every vertex\n",
        "        if (DEBUGGING && size < 15) {\n",
        "            cout << \"The cheapest edge for every vertex\" << endl;\n",
        "            CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                cout << \"node (\" << i << \") -> \" << str->getNeigh(i, candidates[i]) << \"(\"\n",
        "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
        "            }\n",
        "            cout << \"\\n\\n\\n\";\n",
        "        }\n",
        "        /*******************/\n",
        "\n",
        "\n",
        "\n",
        "        // Second step of the algorithm\n",
        "        cout << \"Launching kernel MIRRORED EDGES REMOVAL -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "        cudaEventRecord(start);\n",
        "        mirroredEdgesRemoval<<<gridDim, blockDim>>>(str, d_candidates, d_mstWeight);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "        CHECK(cudaMemcpy(&mstWeight, d_mstWeight, sizeof(int), cudaMemcpyDeviceToHost));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
        "        totalTime += spliTime;\n",
        "        /********************/\n",
        "\n",
        "        // ~Debugging~ print the cheapest edge for every vertex update\n",
        "        if (DEBUGGING && size < 15) {\n",
        "            cout << \"Update of the cheapest edge for every vertex\" << endl;\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                cout << \"node (\" << i << \") -> \";\n",
        "                if (candidates[i] != UINT_MAX) {\n",
        "                    cout << str->getNeigh(i, candidates[i]) << \"(\"\n",
        "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
        "                }\n",
        "                else {\n",
        "                    cout << \"NULL\" << endl;\n",
        "                }\n",
        "            }\n",
        "            printf (\"%d\\n\", mstWeight);\n",
        "        }\n",
        "        /*****************************/\n",
        "\n",
        "        cout << \"The MST weight at the end of iteration \" << iterations + 1 << \" is: \" << mstWeight << endl;\n",
        "\n",
        "\n",
        "\n",
        "        // Third step of the algorithm\n",
        "        cout << \"Launching kernel COLORATION PROCESS -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "\n",
        "        // Initialize the color array\n",
        "        uint *colors = new uint[size];\n",
        "        uint *d_colors;\n",
        "        CHECK(cudaMalloc((void**)&d_colors, size * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_colors, UINT_MAX, size * sizeof(uint)));\n",
        "        /**************************************************/\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        colorationProcess<<<gridDim, blockDim>>>(str, d_candidates, d_colors);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        CHECK(cudaMemcpy(colors, d_colors, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
        "        totalTime += spliTime;\n",
        "\n",
        "        // Print the coloring\n",
        "        if (DEBUGGING) {\n",
        "            uint *checkColoring = new uint[size];\n",
        "\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                checkColoring[i] = 0;\n",
        "            }\n",
        "\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                checkColoring[colors[i]]++;\n",
        "            }\n",
        "\n",
        "            uint nonZeroColors = 0;\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                if (checkColoring[i] != 0) {\n",
        "                    nonZeroColors++;\n",
        "                }\n",
        "            }\n",
        "\n",
        "            cout << \"There is a total of \" << nonZeroColors << \" colors\" << endl;\n",
        "\n",
        "            cout << \"\\n\\n\\n\";\n",
        "        }\n",
        "        /*******************/\n",
        "\n",
        "        /**\n",
        "         * If the coloring coming out of the last kernel contains only one color\n",
        "         * then it means that the edge added in the last step was the one needed\n",
        "         * to merge the partial trees\n",
        "         **/\n",
        "        uint color = colors[0];\n",
        "        bool uniqueColor = true;\n",
        "        for (uint i = 1; i < size; i++) {\n",
        "            if (colors[i] != color) {\n",
        "                uniqueColor = false;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "        if (uniqueColor) {\n",
        "            cout << \"THE CALCULATION OF THE MST IS COMPLETE\\n\";\n",
        "            cout << \"THE MST WEIGHT IS: \" << mstWeight << endl;\n",
        "            printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
        "\n",
        "            // Cuda memory deallocation\n",
        "            CHECK(cudaEventDestroy(start));\n",
        "            CHECK(cudaEventDestroy(stop));\n",
        "            CHECK(cudaFree(d_candidates));\n",
        "            CHECK(cudaFree(d_colors));\n",
        "\n",
        "            // Host memory deallocation\n",
        "            delete[] candidates;\n",
        "            delete[] colors;\n",
        "\n",
        "            return 0;\n",
        "        }\n",
        "        /***********/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Fourth step of the algorithm\n",
        "        cout << \"Doing a round of scan on the flag vector, size: \" << size << endl;\n",
        "        uint *flag = new uint[size];\n",
        "        uint *cFlag = new uint[size];\n",
        "        for (uint i = 0; i < size; i++) {\n",
        "            flag[i] = (colors[i] == i) ? 1 : 0;\n",
        "            cFlag[i] = flag[i];\n",
        "        }\n",
        "        uint *d_flag;\n",
        "        uint smemSize = 2 * blockDim;\n",
        "\n",
        "        CHECK(cudaMalloc((void**)&d_flag, (size) * sizeof(uint)));\n",
        "\n",
        "        if (size < smemSize) {\n",
        "            cout << \"Resorting to a round of CPU scan\" << endl;\n",
        "            cpuScan(flag, 0, size);\n",
        "            CHECK(cudaMemcpy(d_flag, flag, (size) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "        }\n",
        "        else {\n",
        "            uint *d_aux, *aux, *d_ogFlag;\n",
        "\n",
        "            uint numSmemBlock = size / smemSize;\n",
        "            uint numBlock = (size + blockDim - 1) / blockDim;\n",
        "            uint gpuScanSize = numSmemBlock * smemSize;\n",
        "            uint residualSize = size - gpuScanSize;\n",
        "\n",
        "            aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
        "\n",
        "            CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
        "            CHECK(cudaMalloc((void **) &d_ogFlag, size * sizeof(uint)));\n",
        "\n",
        "            CHECK(cudaMemcpy(d_ogFlag, flag, (size) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "\n",
        "            CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
        "            CHECK(cudaMemset(d_flag, 0, (size) * sizeof(uint)));\n",
        "\n",
        "            printf(\"\\n  block scan...\\n\");\n",
        "\n",
        "            uint smem = smemSize * sizeof(uint);\n",
        "            printf(\"\\n  first prescan procedure on the Device: %d elements...\\n\", gpuScanSize);\n",
        "            cudaEventRecord(start);\n",
        "            prescan<<<  numSmemBlock, blockDim, smem >>>(d_flag, d_ogFlag, d_aux, size, smemSize);\n",
        "            printf(\"\\n  second scan procedure on the Host: %d elements...\\n\", residualSize);\n",
        "            cpuScan(flag, gpuScanSize, size);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            float milliseconds;\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime = milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            // Copy the contents of the aux array into Host memory and perform another scan\n",
        "            printf(\"\\n  third scan procedure on the Host: %d elements...\\n\", numSmemBlock);\n",
        "            CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "            cudaEventRecord(start);\n",
        "            cpuScan(aux, 0, numSmemBlock + 1);\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime += milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            // Copy the portions of the array computed on the Host to Device memory\n",
        "            CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "            CHECK(cudaMemcpy(&(d_flag[gpuScanSize]), &(flag[gpuScanSize]), residualSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "\n",
        "            printf(\"\\n  final summation procedure...\\n\");\n",
        "            cudaEventRecord(start);\n",
        "            final_sum<<< numBlock, blockDim >>>(d_flag, d_aux, size);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime += milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            printf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", spliTime);\n",
        "\n",
        "            totalTime += spliTime;\n",
        "            CHECK(cudaMemcpy(flag, d_flag, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "\n",
        "            free(aux);\n",
        "            CHECK(cudaFree(d_aux));\n",
        "            CHECK(cudaFree(d_ogFlag));\n",
        "        }\n",
        "\n",
        "        if (DEBUGGING) {\n",
        "            for (uint i = 1; i < size; i++) {\n",
        "                cFlag[i] += cFlag[i - 1];\n",
        "            }\n",
        "\n",
        "            for (uint i = 0; i < size - 1; i++) {\n",
        "                if (cFlag[i] != flag[i + 1]) {\n",
        "                    cout << \"I due array sono diversi in posizione \" << i << endl;\n",
        "                    return -1;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        delete[] cFlag;\n",
        "        cout << \"The contracted graph will contain \" << flag[size - 1] << \" supervertices\\n\\n\" << endl;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Fifth step of the algorithm\n",
        "\n",
        "        // Allocating resources for the new cumulated degrees array\n",
        "        uint newNodeSize = flag[size - 1];\n",
        "        uint cumDegSize = newNodeSize + 1;\n",
        "        uint *cumDegs = new uint[cumDegSize];\n",
        "        uint *d_cumDegs;\n",
        "        CHECK(cudaMalloc((void**)&d_cumDegs, (cumDegSize) * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
        "        /***********************************/\n",
        "\n",
        "        cout << \"Launching kernel CUMULATED DEGREE UPDATE -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        cumulatedDegreeUpdate<<<gridDim, blockDim>>>(str, d_cumDegs, d_colors, d_flag);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Doing the computation of the cumulated degrees took: %.5f seconds\\n\\n\", spliTime);\n",
        "        CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "\n",
        "        // ~Debugging~ looking for errors in the cumulated degrees array\n",
        "        if (DEBUGGING) {\n",
        "            uint *checkDegs = new uint[cumDegSize];\n",
        "            for (uint i = 0; i < cumDegSize; i++) {\n",
        "                checkDegs[i] = 0;\n",
        "            }\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                uint color = colors[i];\n",
        "                node svSuccessor = getRoot(i, flag, colors);\n",
        "                uint sum = 0;\n",
        "\n",
        "                for (uint j = 0; j < str->deg(i); j++) {\n",
        "                    node neigh = str->getNeigh(i, j);\n",
        "                    uint neighColor = colors[neigh];\n",
        "\n",
        "                    if (color != neighColor) {\n",
        "                        sum++;\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                checkDegs[svSuccessor] += sum;\n",
        "            }\n",
        "            for (uint i = 0; i < cumDegSize; i++) {\n",
        "                if (cumDegs[i] != checkDegs[i]) {\n",
        "                    cout << i << \": cumDegs - \" << cumDegs[i] << \"\\tcheckDegs - \" << checkDegs[i] << endl;\n",
        "                    return -1;\n",
        "                }\n",
        "            }\n",
        "            cout << \"The CPU check vector and the GPU computed one are the same\\n\\n\" << endl;\n",
        "            delete[] checkDegs;\n",
        "        }\n",
        "        /********************/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Perform another prefix sum on the cumDegrees array\n",
        "        cout << \"Doing a round of scan on the cumDegs vector, size: \" << cumDegSize << endl;\n",
        "\n",
        "        uint *cCumDegs = new uint[cumDegSize];\n",
        "        for (uint i = 0; i < cumDegSize; i++) {\n",
        "            cCumDegs[i] = cumDegs[i];\n",
        "        }\n",
        "\n",
        "        if (cumDegSize < smemSize) {\n",
        "            cout << \"Resorting to a round of CPU scan\" << endl;\n",
        "            cpuScan(cumDegs, 0, cumDegSize);\n",
        "            CHECK(cudaMemcpy(d_cumDegs, cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "        }\n",
        "        else {\n",
        "            uint *d_aux, *aux, *d_ogCumDegs;\n",
        "\n",
        "            uint numSmemBlock = cumDegSize / smemSize;\n",
        "            uint numBlock = (cumDegSize + blockDim - 1) / blockDim;\n",
        "            uint gpuScanSize = numSmemBlock * smemSize;\n",
        "            uint residualSize = cumDegSize - gpuScanSize;\n",
        "\n",
        "            aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
        "\n",
        "            CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
        "            CHECK(cudaMalloc((void **) &d_ogCumDegs, cumDegSize * sizeof(uint)));\n",
        "\n",
        "            CHECK(cudaMemcpy(d_ogCumDegs, cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "\n",
        "            CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
        "            CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
        "\n",
        "            printf(\"\\n  block scan...\\n\");\n",
        "\n",
        "            uint smem = smemSize * sizeof(uint);\n",
        "            printf(\"\\n  first prescan procedure on the Device: %d elements...\\n\", gpuScanSize);\n",
        "            cudaEventRecord(start);\n",
        "            prescan<<<  numSmemBlock, blockDim, smem >>>(d_cumDegs, d_ogCumDegs, d_aux, size, smemSize);\n",
        "            printf(\"\\n  second scan procedure on the Host: %d elements...\\n\", residualSize);\n",
        "            cpuScan(cumDegs, gpuScanSize, cumDegSize);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            float milliseconds;\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime = milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            // Copy the contents of the aux array into Host memory and perform another scan\n",
        "            printf(\"\\n  third scan procedure on the Host: %d elements...\\n\", numSmemBlock);\n",
        "            CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "            cudaEventRecord(start);\n",
        "            cpuScan(aux, 0, numSmemBlock + 1);\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime += milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            // Copy the portions of the array computed on the Host to Device memory\n",
        "            CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "            CHECK(cudaMemcpy(&(d_cumDegs[gpuScanSize]), &(cumDegs[gpuScanSize]), residualSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "\n",
        "            printf(\"\\n  final summation procedure...\\n\");\n",
        "            cudaEventRecord(start);\n",
        "            final_sum<<< numBlock, blockDim >>>(d_cumDegs, d_aux, cumDegSize);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime += milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            printf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", spliTime);\n",
        "\n",
        "            totalTime += spliTime;\n",
        "            CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "\n",
        "            free(aux);\n",
        "            CHECK(cudaFree(d_aux));\n",
        "            CHECK(cudaFree(d_ogCumDegs));\n",
        "        }\n",
        "\n",
        "        if (DEBUGGING) {\n",
        "            for (uint i = 1; i < cumDegSize; i++) {\n",
        "                cCumDegs[i] += cCumDegs[i - 1];\n",
        "            }\n",
        "\n",
        "            for (uint i = 0; i < cumDegSize - 1; i++) {\n",
        "                if (cCumDegs[i] != cumDegs[i + 1]) {\n",
        "                    cout << \"I due array sono diversi in posizione \" << i << endl;\n",
        "                    cout << cCumDegs[i] << \"   \" << cumDegs[i + 1];\n",
        "                    return -1;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        cout << \"The contracted graph will contain \" << cumDegs[cumDegSize - 1] << \" edges\" << endl;\n",
        "        cout << \"The old graph structure contained \" << str->edgeSize << \" edges\\n\\n\" << endl;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Allocating space for the arrays in the newly contracted graph\n",
        "        uint newEdgeSize = cumDegs[cumDegSize - 1];\n",
        "        node *newNeighs = new node[newEdgeSize];\n",
        "        uint *newWeights = new uint[newEdgeSize];\n",
        "\n",
        "        uint *d_newNeighs, *d_newWeights;\n",
        "        CHECK(cudaMalloc((void **)&d_newNeighs, newEdgeSize * sizeof(node)));\n",
        "        CHECK(cudaMalloc((void **)&d_newWeights, newEdgeSize * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_newNeighs, 0, newEdgeSize * sizeof(node)));\n",
        "        CHECK(cudaMemset(d_newWeights, 0, newEdgeSize * sizeof(uint)));\n",
        "\n",
        "        cout << \"Launching kernel GRAPH CONSTRUCTION -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "        cudaEventRecord(start);\n",
        "        graphContraction<<<gridDim, blockDim>>>(str, d_colors, d_flag, d_cumDegs, d_newNeighs, d_newWeights);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        printf(\"The construction of the new neighbour and weight arrays took: %.5f seconds\\n\\n\", milliseconds/1000);\n",
        "        spliTime += milliseconds / 1000.0;\n",
        "        CHECK(cudaMemcpy(newNeighs, d_newNeighs, newEdgeSize * sizeof(node), cudaMemcpyDeviceToHost));\n",
        "        CHECK(cudaMemcpy(newWeights, d_newWeights, newEdgeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "\n",
        "        if (DEBUGGING) {\n",
        "            node *checkNewNeighs = new node[newEdgeSize];\n",
        "            uint *checkNewWeights = new uint[newEdgeSize];\n",
        "            // Copy the contents of cumDegs into a new array\n",
        "            for (uint i = 0; i < cumDegSize; i++) {\n",
        "                cCumDegs[i] = cumDegs[i];\n",
        "            }\n",
        "\n",
        "            cudaEventRecord(start);\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                uint color = colors[i];\n",
        "                node superVertex = getRoot(i, flag, colors);\n",
        "\n",
        "                for (uint j = 0; j < str->deg(i); j++) {\n",
        "                    node neigh = str->getNeigh(i, j);\n",
        "                    uint neighColor = colors[neigh];\n",
        "\n",
        "                    if (color != neighColor) {\n",
        "                        int weight = str->getWeight(i, j);\n",
        "                        uint position = cCumDegs[superVertex];\n",
        "                        checkNewNeighs[position] = getRoot(neigh, flag, colors);\n",
        "                        checkNewWeights[position] = weight;\n",
        "                        cCumDegs[superVertex]++;\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "\n",
        "            cout << \"I due array sono uguali\" << endl;\n",
        "            delete[] cCumDegs;\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Reconstructing the graph\n",
        "        graphPointer->copyConstructor(newNodeSize, newEdgeSize, newNeighs, newWeights, cumDegs);\n",
        "\n",
        "        //graphPointer->print(true);\n",
        "\n",
        "        printf(\"----------------------------------\\n\\n\");\n",
        "        /***********************************************/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Updating the iteration information\n",
        "        totalTime += spliTime;\n",
        "        iterations++;\n",
        "        /*****************************************/\n",
        "\n",
        "\n",
        "        // Cuda memory deallocation\n",
        "        CHECK(cudaFree(d_candidates));\n",
        "        CHECK(cudaFree(d_colors));\n",
        "        CHECK(cudaFree(d_flag));\n",
        "        CHECK(cudaFree(d_cumDegs));\n",
        "        CHECK(cudaFree(d_newNeighs));\n",
        "        CHECK(cudaFree(d_newWeights));\n",
        "        /****************************/\n",
        "\n",
        "        // Host memory deallocation\n",
        "        delete[] candidates;\n",
        "        delete[] colors;\n",
        "        delete[] flag;\n",
        "        delete[] cumDegs;\n",
        "        delete[] newNeighs;\n",
        "        delete[] newWeights;\n",
        "        /******************/\n",
        "    }\n",
        "\n",
        "    printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
        "    printf(\"The calculation of the MST took %d iterations\\n\\n\", iterations);\n",
        "    printf(\"The total weight of the tree is %d\\n\", mstWeight);\n",
        "\n",
        "\n",
        "    CHECK(cudaEventDestroy(start));\n",
        "    CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFqTJpGeXKtv",
        "outputId": "eb2910a3-b862-4cba-af8a-edadc3f5c6b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas warning : Stack size for entry function '_Z17colorationProcessP11GraphStructPjS1_' cannot be statically determined\n",
            "Processing a graph of size: 20000 with 199990050 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (20, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 0.34496 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (20, 1, 1)\n",
            "Removing the mirrored edges required: 0.10074 seconds\n",
            "\n",
            "The MST weight at the end of iteration 1 is: 80484\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (20, 1, 1)\n",
            "Removing the mirrored edges required: 0.00008 seconds\n",
            "\n",
            "Doing a round of scan on the flag vector, size: 20000\n",
            "\n",
            "  block scan...\n",
            "\n",
            "  first prescan procedure on the Device: 18432 elements...\n",
            "\n",
            "  second scan procedure on the Host: 1568 elements...\n",
            "   elapsed time:   0.00006 (sec)\n",
            "\n",
            "  third scan procedure on the Host: 9 elements...\n",
            "   elapsed time:   0.00000 (sec)\n",
            "\n",
            "  final summation procedure...\n",
            "   elapsed time:   0.00003 (sec)\n",
            "\n",
            "\n",
            "Total elapsed time:   0.00009 (sec)\n",
            "The contracted graph will contain 4995 supervertices\n",
            "\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (20, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.01134 seconds\n",
            "\n",
            "Doing a round of scan on the cumDegs vector, size: 4996\n",
            "\n",
            "  block scan...\n",
            "\n",
            "  first prescan procedure on the Device: 4096 elements...\n",
            "\n",
            "  second scan procedure on the Host: 900 elements...\n",
            "   elapsed time:   0.00003 (sec)\n",
            "\n",
            "  third scan procedure on the Host: 2 elements...\n",
            "   elapsed time:   0.00000 (sec)\n",
            "\n",
            "  final summation procedure...\n",
            "   elapsed time:   0.00001 (sec)\n",
            "\n",
            "\n",
            "Total elapsed time:   0.00005 (sec)\n",
            "The contracted graph will contain 199931944 edges\n",
            "The old graph structure contained 199990050 edges\n",
            "\n",
            "\n",
            "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (20, 1, 1)\n",
            "The construction of the new neighbour and weight arrays took: 0.33487 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 4995 with 199931944 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (5, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 0.28553 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (5, 1, 1)\n",
            "Removing the mirrored edges required: 0.06334 seconds\n",
            "\n",
            "The MST weight at the end of iteration 2 is: 105640\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (5, 1, 1)\n",
            "Removing the mirrored edges required: 0.00003 seconds\n",
            "\n",
            "Doing a round of scan on the flag vector, size: 4995\n",
            "\n",
            "  block scan...\n",
            "\n",
            "  first prescan procedure on the Device: 4096 elements...\n",
            "\n",
            "  second scan procedure on the Host: 899 elements...\n",
            "   elapsed time:   0.00004 (sec)\n",
            "\n",
            "  third scan procedure on the Host: 2 elements...\n",
            "   elapsed time:   0.00000 (sec)\n",
            "\n",
            "  final summation procedure...\n",
            "   elapsed time:   0.00001 (sec)\n",
            "\n",
            "\n",
            "Total elapsed time:   0.00005 (sec)\n",
            "The contracted graph will contain 970 supervertices\n",
            "\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (5, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.06943 seconds\n",
            "\n",
            "Doing a round of scan on the cumDegs vector, size: 971\n",
            "Resorting to a round of CPU scan\n",
            "The contracted graph will contain 199629554 edges\n",
            "The old graph structure contained 199931944 edges\n",
            "\n",
            "\n",
            "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (5, 1, 1)\n",
            "The construction of the new neighbour and weight arrays took: 0.32876 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 970 with 199629554 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 1.02212 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.01577 seconds\n",
            "\n",
            "The MST weight at the end of iteration 3 is: 110463\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00005 seconds\n",
            "\n",
            "Doing a round of scan on the flag vector, size: 970\n",
            "Resorting to a round of CPU scan\n",
            "The contracted graph will contain 149 supervertices\n",
            "\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.43263 seconds\n",
            "\n",
            "Doing a round of scan on the cumDegs vector, size: 150\n",
            "Resorting to a round of CPU scan\n",
            "The contracted graph will contain 197456180 edges\n",
            "The old graph structure contained 199629554 edges\n",
            "\n",
            "\n",
            "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1, 1, 1)\n",
            "The construction of the new neighbour and weight arrays took: 1.36324 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 149 with 197456180 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 1.71494 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00200 seconds\n",
            "\n",
            "The MST weight at the end of iteration 4 is: 111169\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00003 seconds\n",
            "\n",
            "Doing a round of scan on the flag vector, size: 149\n",
            "Resorting to a round of CPU scan\n",
            "The contracted graph will contain 16 supervertices\n",
            "\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.76046 seconds\n",
            "\n",
            "Doing a round of scan on the cumDegs vector, size: 17\n",
            "Resorting to a round of CPU scan\n",
            "The contracted graph will contain 173633880 edges\n",
            "The old graph structure contained 197456180 edges\n",
            "\n",
            "\n",
            "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1, 1, 1)\n",
            "The construction of the new neighbour and weight arrays took: 4.02843 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 16 with 173633880 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 5.52134 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00031 seconds\n",
            "\n",
            "The MST weight at the end of iteration 5 is: 111226\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00002 seconds\n",
            "\n",
            "Doing a round of scan on the flag vector, size: 16\n",
            "Resorting to a round of CPU scan\n",
            "The contracted graph will contain 4 supervertices\n",
            "\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 2.54791 seconds\n",
            "\n",
            "Doing a round of scan on the cumDegs vector, size: 5\n",
            "Resorting to a round of CPU scan\n",
            "The contracted graph will contain 107168814 edges\n",
            "The old graph structure contained 173633880 edges\n",
            "\n",
            "\n",
            "Launching kernel GRAPH CONSTRUCTION -- (1024, 1, 1) -- (1, 1, 1)\n",
            "The construction of the new neighbour and weight arrays took: 17.69275 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 4 with 107168814 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 5.04158 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00018 seconds\n",
            "\n",
            "The MST weight at the end of iteration 6 is: 111239\n",
            "Launching kernel COLORATION PROCESS -- (1024, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00002 seconds\n",
            "\n",
            "THE CALCULATION OF THE MST IS COMPLETE\n",
            "THE MST WEIGHT IS: 111239\n",
            "Total elapsed time: 41.67176 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compilazione ed esecuzione\n",
        "\n",
        "!nvcc -arch=sm_75 GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/GPU/mstGPU.cu -o mstGPU\n",
        "!./mstGPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UpcpuS7gkow",
        "outputId": "96e273fe-10ad-4da6-9a89-9192e1cd7f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ptxas warning : Stack size for entry function '_Z17colorationProcessP11GraphStructPjS1_' cannot be statically determined\n",
            "==PROF== Connected to process 32208 (/content/mstGPU)\n",
            "Processing a graph of size: 20000 with 199987170 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (256, 1, 1) -- (79, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 0.25828 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (256, 1, 1) -- (79, 1, 1)\n",
            "Removing the mirrored edges required: 0.07163 seconds\n",
            "\n",
            "Launching kernel COLORATION PROCESS -- (256, 1, 1) -- (79, 1, 1)\n",
            "Removing the mirrored edges required: 0.00052 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "Doing the prefix sum of the auxiliary flag array took: 0.00008 seconds\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (256, 1, 1) -- (79, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.00856 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "Doing the scan of the new cumDegs array took: 0.00003 seconds\n",
            "\n",
            "==PROF== Profiling \"graphContraction\": 0%....50%....100% - 9 passes\n",
            "The construction of the new neighbour and weight arrays took: 3.62918 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 4941 with 199928460 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (256, 1, 1) -- (20, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 0.27415 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (256, 1, 1) -- (20, 1, 1)\n",
            "Removing the mirrored edges required: 0.08644 seconds\n",
            "\n",
            "Launching kernel COLORATION PROCESS -- (256, 1, 1) -- (20, 1, 1)\n",
            "Removing the mirrored edges required: 0.00008 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "Doing the prefix sum of the auxiliary flag array took: 0.00002 seconds\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (256, 1, 1) -- (20, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.04076 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "Doing the scan of the new cumDegs array took: 0.00002 seconds\n",
            "\n",
            "==PROF== Profiling \"graphContraction\": 0%....50%....100% - 9 passes\n",
            "The construction of the new neighbour and weight arrays took: 3.61948 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 1016 with 199655238 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (256, 1, 1) -- (4, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 0.50049 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (256, 1, 1) -- (4, 1, 1)\n",
            "Removing the mirrored edges required: 0.01457 seconds\n",
            "\n",
            "Launching kernel COLORATION PROCESS -- (256, 1, 1) -- (4, 1, 1)\n",
            "Removing the mirrored edges required: 0.00009 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "Doing the prefix sum of the auxiliary flag array took: 0.00001 seconds\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (256, 1, 1) -- (4, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.21745 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "Doing the scan of the new cumDegs array took: 0.00001 seconds\n",
            "\n",
            "==PROF== Profiling \"graphContraction\": 0%....50%....100% - 9 passes\n",
            "The construction of the new neighbour and weight arrays took: 16.00290 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 165 with 197332800 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (256, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 1.84447 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (256, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00276 seconds\n",
            "\n",
            "Launching kernel COLORATION PROCESS -- (256, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00012 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "Doing the prefix sum of the auxiliary flag array took: 0.00001 seconds\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (256, 1, 1) -- (1, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 0.88378 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "Doing the scan of the new cumDegs array took: 0.00001 seconds\n",
            "\n",
            "The construction of the new neighbour and weight arrays took: 4.80523 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 24 with 180277880 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (256, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 5.46273 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (256, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00063 seconds\n",
            "\n",
            "Launching kernel COLORATION PROCESS -- (256, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00020 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "Doing the prefix sum of the auxiliary flag array took: 0.00000 seconds\n",
            "\n",
            "Launching kernel CUMULATED DEGREE UPDATE -- (256, 1, 1) -- (1, 1, 1)\n",
            "Doing the computation of the cumulated degrees took: 2.32462 seconds\n",
            "\n",
            "Launching a round of CPU scan\n",
            "Doing the scan of the new cumDegs array took: 0.00001 seconds\n",
            "\n",
            "The construction of the new neighbour and weight arrays took: 16.66794 seconds\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Processing a graph of size: 2 with 95507518 edges.\n",
            "\n",
            "Launching kernel FIND CHEAPEST -- (256, 1, 1) -- (1, 1, 1)\n",
            "Finding the cheapest edge for every vertex took: 5.17927 seconds\n",
            "\n",
            "Launching kernel MIRRORED EDGES REMOVAL -- (256, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00012 seconds\n",
            "\n",
            "Launching kernel COLORATION PROCESS -- (256, 1, 1) -- (1, 1, 1)\n",
            "Removing the mirrored edges required: 0.00007 seconds\n",
            "\n",
            "THE CALCULATION OF THE MST IS COMPLETE\n",
            "THE MST WEIGHT IS: 110477\n",
            "Total elapsed time: 61.89671 seconds\n",
            "\n",
            "==PROF== Disconnected from process 32208\n",
            "[32208] mstGPU@127.0.0.1\n",
            "  graphContraction(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *) (79, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ------------- --------------\n",
            "    Metric Name               Metric Unit   Metric Value\n",
            "    ----------------------- ------------- --------------\n",
            "    DRAM Frequency          cycle/nsecond           4.99\n",
            "    SM Frequency            cycle/usecond         583.85\n",
            "    Elapsed Cycles                  cycle    198,239,419\n",
            "    Memory Throughput                   %          57.60\n",
            "    DRAM Throughput                     %          57.60\n",
            "    Duration                      msecond         339.54\n",
            "    L1/TEX Cache Throughput             %          38.98\n",
            "    L2 Cache Throughput                 %          16.83\n",
            "    SM Active Cycles                cycle 194,197,410.07\n",
            "    Compute (SM) Throughput             %           3.04\n",
            "    ----------------------- ------------- --------------\n",
            "\n",
            "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                     79\n",
            "    Registers Per Thread             register/thread              30\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    Threads                                   thread          20,224\n",
            "    Waves Per SM                                                0.49\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the \n",
            "          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   \n",
            "          hardware busy.                                                                                                \n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            8\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        48.75\n",
            "    Achieved Active Warps Per SM           warp        15.60\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Estimated Speedup: 51.25%                                                                                     \n",
            "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
            "          theoretical (100.0%) and measured achieved occupancy (48.8%) can be the result of warp scheduling overheads   \n",
            "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
            "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
            "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "  graphContraction(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *) (20, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ------------- -------------\n",
            "    Metric Name               Metric Unit  Metric Value\n",
            "    ----------------------- ------------- -------------\n",
            "    DRAM Frequency          cycle/nsecond          5.00\n",
            "    SM Frequency            cycle/usecond        585.38\n",
            "    Elapsed Cycles                  cycle   207,524,595\n",
            "    Memory Throughput                   %         18.11\n",
            "    DRAM Throughput                     %          8.82\n",
            "    Duration                      msecond        354.51\n",
            "    L1/TEX Cache Throughput             %         40.70\n",
            "    L2 Cache Throughput                 %         15.72\n",
            "    SM Active Cycles                cycle 92,341,799.67\n",
            "    Compute (SM) Throughput             %          5.30\n",
            "    ----------------------- ------------- -------------\n",
            "\n",
            "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                     20\n",
            "    Registers Per Thread             register/thread              30\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    Threads                                   thread           5,120\n",
            "    Waves Per SM                                                0.12\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    OPT   Estimated Speedup: 50%                                                                                        \n",
            "          The grid for this launch is configured to execute only 20 blocks, which is less than the GPU's 40             \n",
            "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
            "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
            "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
            "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
            "          description for more details on launch configurations.                                                        \n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            8\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        20.98\n",
            "    Achieved Active Warps Per SM           warp         6.71\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Estimated Speedup: 79.02%                                                                                     \n",
            "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
            "          theoretical (100.0%) and measured achieved occupancy (21.0%) can be the result of warp scheduling overheads   \n",
            "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
            "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
            "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "  graphContraction(GraphStruct *, unsigned int *, unsigned int *, unsigned int *, unsigned int *, unsigned int *) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ------------- -------------\n",
            "    Metric Name               Metric Unit  Metric Value\n",
            "    ----------------------- ------------- -------------\n",
            "    DRAM Frequency          cycle/nsecond          5.00\n",
            "    SM Frequency            cycle/usecond        585.16\n",
            "    Elapsed Cycles                  cycle 1,015,797,375\n",
            "    Memory Throughput                   %          2.88\n",
            "    DRAM Throughput                     %          1.78\n",
            "    Duration                       second          1.74\n",
            "    L1/TEX Cache Throughput             %         31.84\n",
            "    L2 Cache Throughput                 %          2.47\n",
            "    SM Active Cycles                cycle 91,824,182.78\n",
            "    Compute (SM) Throughput             %          1.40\n",
            "    ----------------------- ------------- -------------\n",
            "\n",
            "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                      4\n",
            "    Registers Per Thread             register/thread              30\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    Threads                                   thread           1,024\n",
            "    Waves Per SM                                                0.03\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    OPT   Estimated Speedup: 90%                                                                                        \n",
            "          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 40              \n",
            "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
            "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
            "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
            "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
            "          description for more details on launch configurations.                                                        \n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            8\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        18.68\n",
            "    Achieved Active Warps Per SM           warp         5.98\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Estimated Speedup: 81.32%                                                                                     \n",
            "          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
            "          theoretical (100.0%) and measured achieved occupancy (18.7%) can be the result of warp scheduling overheads   \n",
            "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
            "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
            "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ncu profiling\n",
        "\n",
        "!nvcc -arch=sm_75 GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/GPU/mstGPU.cu -o mstGPU\n",
        "!ncu --kernel-id ::graphContraction: -c 3 ./mstGPU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU efficient approach"
      ],
      "metadata": {
        "id": "fKk2Iwm4J90R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda_group_save --name \"mstGPUE.cu\" --group \"GPU\"\n",
        "\n",
        "// Header file di C++\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <vector>\n",
        "#include <algorithm>\n",
        "\n",
        "// Header file C\n",
        "#include <time.h>\n",
        "#include <limits.h>\n",
        "\n",
        "// Custom files\n",
        "#include \"../../GPUcomputing/utils/graph/graph_d.h\"\n",
        "#include \"../../GPUcomputing/utils/graph/graph.h\"\n",
        "#include \"../../GPUcomputing/utils/common.h\"\n",
        "#include \"../COMMON/sharedMacros.h\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/*****\n",
        "* Device function that gets the degree of a certain node\n",
        "* @param str - The structure of the graph\n",
        "* @param i - The node we are interested in\n",
        "*****/\n",
        "__device__ node d_deg (GraphStruct *str, node i) {\n",
        "    return str->cumDegs[i + 1] - str->cumDegs[i];\n",
        "}\n",
        "\n",
        "/*****\n",
        "* Device function that gets the weight of a certain edge\n",
        "* @param str - The structure of the graph\n",
        "* @param i - The source node of the edge\n",
        "* @param offset - The offset of the destination node in the adjacency list of\n",
        "*                 the source\n",
        "*****/\n",
        "__device__ int d_getWeight (GraphStruct *str, node i, uint offset) {\n",
        "    return str->weights[str->cumDegs[i] + offset];\n",
        "}\n",
        "\n",
        "/*****\n",
        "* Device function that gets the neighbour of a certain node\n",
        "* @param str - The structure of the graph\n",
        "* @param i - The source node of the edge\n",
        "* @param offset - The offset of the destination node in the adjacency list of\n",
        "*                 the source\n",
        "*****/\n",
        "__device__ node d_getNeigh (GraphStruct *str, node i, uint offset) {\n",
        "    return str->neighs[str->cumDegs[i] + offset];\n",
        "}\n",
        "\n",
        "__device__ uint d_getRoot (uint i, uint *d_flag, uint *d_colors) {\n",
        "    return max(0, d_flag[d_colors[i]]);\n",
        "}\n",
        "\n",
        "uint getRoot (uint i, uint *flag, uint *colors) {\n",
        "    return max(0, flag[colors[i]]);\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Kernel that finds the cheapest edge in the adjacency list of every node\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree (edges saved as offsets in the CSR\n",
        "*                       representation of the graph)\n",
        "*****/\n",
        "__global__ void findCheapest (GraphStruct *str, uint *d_candidates) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    // Initialize the minimum value\n",
        "    uint minimum = UINT_MAX;\n",
        "    int minimumWeight = INT_MAX;\n",
        "\n",
        "    // Find the cheapest edge in each adjacency list\n",
        "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
        "        int edgeWeight = d_getWeight(str, idx, i);\n",
        "        if (edgeWeight < minimumWeight) {\n",
        "            minimumWeight = edgeWeight;\n",
        "            minimum = i;\n",
        "        }\n",
        "        else if (edgeWeight == minimumWeight &&\n",
        "                 d_getNeigh(str, idx, i) < d_getNeigh(str, idx, minimum)) {\n",
        "            minimumWeight = edgeWeight;\n",
        "            minimum = i;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Update the return vector\n",
        "    d_candidates[idx] = minimum;\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Kernel that removes the mirrored edges from the graph. A mirrored edge is\n",
        "* simply an edge pointing from the source to the destination and vice versa in\n",
        "* an oriented graph, the removal logic is to cut the edge with the lowest source\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree (edges saved as offsets in the CSR\n",
        "*                       representation of the graph)\n",
        "*****/\n",
        "__global__ void mirroredEdgesRemoval (GraphStruct *str, uint *d_candidates, int *d_weight) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    uint destinationOffset = d_candidates[idx];\n",
        "    node destination = d_getNeigh(str, idx, destinationOffset);\n",
        "    if (idx < destination) {\n",
        "        uint sourceOffset = d_candidates[destination];\n",
        "        node destinationNeigh = d_getNeigh(str, destination, sourceOffset);\n",
        "\n",
        "        // The vertex cannot be a candidate anymore because it would create a cycle\n",
        "        if (destinationNeigh == idx) {\n",
        "            d_candidates[idx] = UINT_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (d_candidates[idx] != UINT_MAX) {\n",
        "        atomicAdd(d_weight, d_getWeight(str, idx, d_candidates[idx]));\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Helper device function that recursively colors the nodes of the graph\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree (edges saved as offsets in the CSR\n",
        "*                       representation of the graph)\n",
        "* @param i - The index of the node to be colored\n",
        "* @param d_colors - The device-level array of colors assigned to each vertex\n",
        "*****/\n",
        "__device__ uint *d_recursiveColorationHelper (GraphStruct *str, uint *d_candidates, node i, uint *d_colors) {\n",
        "    uint color = UINT_MAX;\n",
        "    if (d_candidates[i] == UINT_MAX) {\n",
        "        color = i;\n",
        "    }\n",
        "    else {\n",
        "        node neigh = d_getNeigh(str, i, d_candidates[i]);\n",
        "        color = d_recursiveColorationHelper(str, d_candidates, neigh, d_colors)[neigh];\n",
        "    }\n",
        "\n",
        "    if (color != UINT_MAX) {\n",
        "        d_colors[i] = color;\n",
        "    }\n",
        "    return d_colors;\n",
        "}\n",
        "\n",
        "\n",
        "/*****\n",
        "* Kernel that recognizes the connected components in the graph and colors them\n",
        "* @param str - The structure of the graph\n",
        "* @param d_candidates - The device-level array of candidates to become part of\n",
        "*                       the spanning tree\n",
        "* @param d_colors - The device-level array of colors assigned to each vertex\n",
        "*****/\n",
        "__global__ void colorationProcess(GraphStruct *str, uint *d_candidates, uint *d_colors) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    d_recursiveColorationHelper(str, d_candidates, idx, d_colors);\n",
        "}\n",
        "\n",
        "\n",
        "/**\n",
        "* Kernel that computes the prefix sun of the auxiliary flag array, code taken\n",
        "* from the lectures and rearranged to follow the logic required for the\n",
        "* implementation of the algorithm\n",
        "* @param str - The structure of the graph\n",
        "* @param d_colors - The device-level array of colors assigned to each vertex\n",
        "* @param d_flag - The device-level array of flag values for the prefix sum.\n",
        "*                 d_flag[i] = 1 if and only if the vertex in position i has the\n",
        "*                 same color as the index => I recognize the root of the\n",
        "*                 connected component\n",
        "* @param d_auxiliarVector - The device-level array containing the last value of\n",
        "*                           the prefix sum calculation for every block\n",
        "**/\n",
        "__global__ void blockScan(uint *size, uint *input, uint *auxiliarVector) {\n",
        "   __shared__ uint smem[BLOCK_SIZE];\n",
        "   uint tid = threadIdx.x;\n",
        "   uint idx = tid + blockIdx.x * blockDim.x;\n",
        "\n",
        "   // If the index is out of bounds returns immediately\n",
        "    if (idx >= *size) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "   // Load input into shared memory.\n",
        "   smem[tid] = input[idx];\n",
        "   __syncthreads();\n",
        "\n",
        "   // do recursive sums\n",
        "   for (uint d = 1; d < BLOCK_SIZE; d *= 2) {\n",
        "      if (tid >= d)\n",
        "         smem[tid] += smem[tid - d];\n",
        "      __syncthreads();\n",
        "   }\n",
        "   input[idx] = smem[tid];\n",
        "   if (idx == ((blockIdx.x + 1) * blockDim.x - 1))\n",
        "      auxiliarVector[blockIdx.x] = input[idx];\n",
        "}\n",
        "\n",
        "\n",
        "/**\n",
        "* Auxiliary kernel that computes the sum of the partial values calculated using\n",
        "* the blockScan kernel\n",
        "* str - The structure of the graph\n",
        "* @param d_flag - The device-level array containing intermediate sums obtained\n",
        "*                 with the previous kernel\n",
        "* @param d_auxiliarVector - The device-level array containing the last value of\n",
        "*                           the prefix sum calculation for every block\n",
        "**/\n",
        "__global__ void sumBlockScan(uint *size, uint *input, uint *auxiliarVector) {\n",
        "   uint idx = threadIdx.x + blockIdx.x * blockDim.x;  // global index 0:n-1\n",
        "   uint s = 0;\n",
        "\n",
        "   // If the index is out of bounds returns immediately\n",
        "    if (idx >= *size) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "   if (blockIdx.x == 0) return;\n",
        "\n",
        "   for (uint j = 0; j < blockIdx.x; j++)\n",
        "      s += auxiliarVector[j];\n",
        "\n",
        "   // add term to input\n",
        "   input[idx] += s;\n",
        "}\n",
        "\n",
        "//*** SCAN FUNCTIONS ***//\n",
        "\n",
        "__global__ void prescan(uint *g_odata, uint *g_idata, uint *aux, int n, int smemSize)\n",
        "{\n",
        "  extern __shared__ int temp[];// allocated on invocation\n",
        "  int thid = threadIdx.x;\n",
        "  int offset = 1;\n",
        "  int idx = blockIdx.x * blockDim.x + thid;\n",
        "\n",
        "  temp[2*thid] = g_idata[2*idx]; // load input into shared memory\n",
        "  temp[2*thid+1] = g_idata[2*idx+1];\n",
        "\n",
        "  for (int d = n>>1; d > 0; d >>= 1) // build sum in place up the tree\n",
        "  {\n",
        "    __syncthreads();\n",
        "    if (thid < d)\n",
        "    {\n",
        "      int ai = offset*(2*thid+1)-1;\n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      if (bi < smemSize && ai < smemSize) {\n",
        "        temp[bi] += temp[ai];\n",
        "      }\n",
        "    }\n",
        "    offset *= 2;\n",
        "  }\n",
        "\n",
        "  if (thid == 0)\n",
        "  {\n",
        "    aux[blockIdx.x] = temp[smemSize - 1];\n",
        "    temp[smemSize - 1] = 0;\n",
        "  } // clear the last element\n",
        "\n",
        "  for (int d = 1; d < n; d *= 2) // traverse down tree & build scan\n",
        "  {\n",
        "    __syncthreads();\n",
        "    if (thid < d && offset > 0)\n",
        "    {\n",
        "      int ai = offset*(2*thid+1)-1;\n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      if (bi < smemSize && ai < smemSize) {\n",
        "        int t = temp[ai];\n",
        "        temp[ai] = temp[bi];\n",
        "        temp[bi] += t;\n",
        "      }\n",
        "    }\n",
        "    offset >>= 1;\n",
        "  }\n",
        "\n",
        "\n",
        "  __syncthreads();\n",
        "  if (idx <= (n / 2) - 1) {\n",
        "      g_odata[2*idx] = temp[2*thid]; // write results to device memory\n",
        "      g_odata[2*idx+1] = temp[2*thid+1];\n",
        "  }\n",
        "}\n",
        "\n",
        "void cpuScan(uint *array, int start, int end) {\n",
        "    if (end - start <= 1) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    int temp = array[start + 1];\n",
        "    array[start + 1] = array[start];\n",
        "    array[start] = 0;\n",
        "\n",
        "    for (uint i = start + 1; i < end - 1; i++) {\n",
        "        int sum = array[i] + temp;\n",
        "        temp = array[i + 1];\n",
        "        array[i + 1] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void final_sum(uint *g_odata, uint *aux, uint n)\n",
        "{\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "  if (blockIdx.x == 0 || 2 * idx >= n) {\n",
        "      return;\n",
        "  }\n",
        "\n",
        "  //printf(\"%d: ls - %d  rs - %d  aux - %d\\n\", idx, g_odata[2 * idx], g_odata[2 * idx + 1], aux[blockIdx.x - 1]);\n",
        "\n",
        "  if (2 * idx == n - 1) {\n",
        "      g_odata[2 * idx] += aux[blockIdx.x];\n",
        "      return;\n",
        "  }\n",
        "  g_odata[2 * idx] += aux[blockIdx.x];\n",
        "  g_odata[2 * idx + 1] += aux[blockIdx.x];\n",
        "}\n",
        "\n",
        "//****************//\n",
        "\n",
        "\n",
        "__global__ void cumulatedDegreeUpdate(GraphStruct *str, uint *d_cumDegs, uint *d_colors, uint *d_flag) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    uint color = d_colors[idx];\n",
        "    node svSuccessor = d_getRoot(idx, d_flag, d_colors);\n",
        "    uint sum = 0;\n",
        "\n",
        "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
        "        node neigh = d_getNeigh(str, idx, i);\n",
        "        uint neighColor = d_colors[neigh];\n",
        "\n",
        "        if (color != neighColor) {\n",
        "            sum++;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    atomicAdd(&(d_cumDegs[svSuccessor]), sum);\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void graphContraction(GraphStruct *str, uint *d_colors, uint *d_flag,\n",
        "                                 uint *d_cumDegs, node *d_newNeighs, uint *d_newWeights) {\n",
        "    uint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // If the index is out of bounds returns immediately\n",
        "    if (idx >= str->nodeSize) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    uint color = d_colors[idx];\n",
        "    node superVertex = d_getRoot(idx, d_flag, d_colors);\n",
        "\n",
        "    for (uint i = 0; i < d_deg(str, idx); i++) {\n",
        "        node neigh = d_getNeigh(str, idx, i);\n",
        "        uint neighColor = d_colors[neigh];\n",
        "\n",
        "        if (color != neighColor) {\n",
        "            int weight = d_getWeight(str, idx, i);\n",
        "            uint position = atomicAdd(&(d_cumDegs[superVertex]), 1);\n",
        "            d_newNeighs[position] = d_getRoot(neigh, d_flag, d_colors);\n",
        "            d_newWeights[position] = weight;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main () {\n",
        "    // Generation of a random graph\n",
        "    std::random_device rd;\n",
        "    std::default_random_engine eng(FIXED_SEED);\n",
        "    uint maxWeight = MAX_WEIGHT;\n",
        "    float prob = .5;\n",
        "    bool GPUEnabled = 1;\n",
        "    Graph *graphPointer;\n",
        "    Graph graph(SIZE, GPUEnabled);\n",
        "    graphPointer = &graph;\n",
        "  \tgraphPointer->randGraph(prob, true, maxWeight, eng);\n",
        "    /**************************************************/\n",
        "\n",
        "\n",
        "    // Checking if the random graph is connected\n",
        "    if (!graphPointer->isConnected()) {\n",
        "        cout << \"The graph is not connected\" << endl;\n",
        "        return -1;\n",
        "    }\n",
        "    /************/\n",
        "\n",
        "\n",
        "    uint iterations = 0;\n",
        "\n",
        "\n",
        "    // Configuration of the GPU kernel\n",
        "    uint blockDim = BLOCK_SIZE;\n",
        "    uint *candidates;\n",
        "    /***************/\n",
        "\n",
        "\n",
        "    // Events to measure time\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    float milliseconds;\n",
        "    float spliTime = 0;\n",
        "    float totalTime = 0;\n",
        "    /******************/\n",
        "\n",
        "\n",
        "    // Variables calculating the MST weight\n",
        "    int mstWeight = 0;\n",
        "    int *d_mstWeight;\n",
        "    CHECK(cudaMalloc((void **)&d_mstWeight, sizeof(int)));\n",
        "    CHECK(cudaMemcpy(d_mstWeight, &mstWeight, sizeof(int), cudaMemcpyHostToDevice));\n",
        "    /******************************************************************************/\n",
        "\n",
        "\n",
        "    // Main block of the algorithm\n",
        "    while (graphPointer->getStruct()->nodeSize > 1) {\n",
        "        // Initialization of the variables associated with the graph\n",
        "        GraphStruct *str = graphPointer->getStruct();\n",
        "        uint size = str->nodeSize;\n",
        "        uint edgeSize = str->edgeSize;\n",
        "        cout << \"Processing a graph of size: \" << size << \" with \" << edgeSize << \" edges.\\n\\n\";\n",
        "        uint gridDim = (size + blockDim - 1) / blockDim;\n",
        "        if (DEBUGGING && size < 15 && str->edgeSize < 100) {\n",
        "            graphPointer->print(true);\n",
        "            print_d<<<1, 1>>>(str, 1);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "        }\n",
        "        candidates = new uint[size];\n",
        "        /******************************/\n",
        "\n",
        "        // First setp of the algorithm\n",
        "        uint *d_candidates;\n",
        "        CHECK(cudaMalloc((void**)&d_candidates, (size) * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_candidates, 0, (size) * sizeof(uint)));\n",
        "        cout << \"Launching kernel FIND CHEAPEST -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "        cudaEventRecord(start);\n",
        "        findCheapest<<<gridDim, blockDim>>>(str, d_candidates);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Finding the cheapest edge for every vertex took: %.5f seconds\\n\\n\", spliTime);\n",
        "        totalTime += spliTime;\n",
        "        /********************/\n",
        "\n",
        "        // ~Debugging~ print the cheapest edge for every vertex\n",
        "        if (DEBUGGING && size < 15) {\n",
        "            cout << \"The cheapest edge for every vertex\" << endl;\n",
        "            CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                cout << \"node (\" << i << \") -> \" << str->getNeigh(i, candidates[i]) << \"(\"\n",
        "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
        "            }\n",
        "            cout << \"\\n\\n\\n\";\n",
        "        }\n",
        "        /*******************/\n",
        "\n",
        "\n",
        "\n",
        "        // Second step of the algorithm\n",
        "        cout << \"Launching kernel MIRRORED EDGES REMOVAL -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "        cudaEventRecord(start);\n",
        "        mirroredEdgesRemoval<<<gridDim, blockDim>>>(str, d_candidates, d_mstWeight);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        CHECK(cudaMemcpy(candidates, d_candidates, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "        CHECK(cudaMemcpy(&mstWeight, d_mstWeight, sizeof(int), cudaMemcpyDeviceToHost));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
        "        totalTime += spliTime;\n",
        "        /********************/\n",
        "\n",
        "        // ~Debugging~ print the cheapest edge for every vertex update\n",
        "        if (DEBUGGING && size < 15) {\n",
        "            cout << \"Update of the cheapest edge for every vertex\" << endl;\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                cout << \"node (\" << i << \") -> \";\n",
        "                if (candidates[i] != UINT_MAX) {\n",
        "                    cout << str->getNeigh(i, candidates[i]) << \"(\"\n",
        "                    << str->getWeight(i, candidates[i]) << \")\" << endl;\n",
        "                }\n",
        "                else {\n",
        "                    cout << \"NULL\" << endl;\n",
        "                }\n",
        "            }\n",
        "            printf (\"%d\\n\", mstWeight);\n",
        "        }\n",
        "        /*****************************/\n",
        "\n",
        "        cout << \"The MST weight at the end of iteration \" << iterations + 1 << \" is: \" << mstWeight << endl;\n",
        "\n",
        "\n",
        "\n",
        "        // Third step of the algorithm\n",
        "        cout << \"Launching kernel COLORATION PROCESS -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "\n",
        "        // Initialize the color array\n",
        "        uint *colors = new uint[size];\n",
        "        uint *d_colors;\n",
        "        CHECK(cudaMalloc((void**)&d_colors, size * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_colors, UINT_MAX, size * sizeof(uint)));\n",
        "        /**************************************************/\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        colorationProcess<<<gridDim, blockDim>>>(str, d_candidates, d_colors);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        CHECK(cudaMemcpy(colors, d_colors, size * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Removing the mirrored edges required: %.5f seconds\\n\\n\", spliTime);\n",
        "        totalTime += spliTime;\n",
        "\n",
        "        // Print the coloring\n",
        "        if (DEBUGGING) {\n",
        "            uint *checkColoring = new uint[size];\n",
        "\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                checkColoring[i] = 0;\n",
        "            }\n",
        "\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                checkColoring[colors[i]]++;\n",
        "            }\n",
        "\n",
        "            uint nonZeroColors = 0;\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                if (checkColoring[i] != 0) {\n",
        "                    nonZeroColors++;\n",
        "                }\n",
        "            }\n",
        "\n",
        "            cout << \"There is a total of \" << nonZeroColors << \" colors\" << endl;\n",
        "\n",
        "            cout << \"\\n\\n\\n\";\n",
        "        }\n",
        "        /*******************/\n",
        "\n",
        "        /**\n",
        "         * If the coloring coming out of the last kernel contains only one color\n",
        "         * then it means that the edge added in the last step was the one needed\n",
        "         * to merge the partial trees\n",
        "         **/\n",
        "        uint color = colors[0];\n",
        "        bool uniqueColor = true;\n",
        "        for (uint i = 1; i < size; i++) {\n",
        "            if (colors[i] != color) {\n",
        "                uniqueColor = false;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "        if (uniqueColor) {\n",
        "            cout << \"THE CALCULATION OF THE MST IS COMPLETE\\n\";\n",
        "            cout << \"THE MST WEIGHT IS: \" << mstWeight << endl;\n",
        "            printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
        "\n",
        "            // Cuda memory deallocation\n",
        "            CHECK(cudaEventDestroy(start));\n",
        "            CHECK(cudaEventDestroy(stop));\n",
        "            CHECK(cudaFree(d_candidates));\n",
        "            CHECK(cudaFree(d_colors));\n",
        "\n",
        "            // Host memory deallocation\n",
        "            delete[] candidates;\n",
        "            delete[] colors;\n",
        "\n",
        "            return 0;\n",
        "        }\n",
        "        /***********/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Fourth step of the algorithm\n",
        "        cout << \"Doing a round of scan on the flag vector, size: \" << size << endl;\n",
        "        uint *flag = new uint[size];\n",
        "        uint *cFlag = new uint[size];\n",
        "        for (uint i = 0; i < size; i++) {\n",
        "            flag[i] = (colors[i] == i) ? 1 : 0;\n",
        "            cFlag[i] = flag[i];\n",
        "        }\n",
        "        uint *d_flag;\n",
        "        uint smemSize = 2 * blockDim;\n",
        "\n",
        "        CHECK(cudaMalloc((void**)&d_flag, (size) * sizeof(uint)));\n",
        "\n",
        "        if (size < smemSize) {\n",
        "            cout << \"Resorting to a round of CPU scan\" << endl;\n",
        "            cpuScan(flag, 0, size);\n",
        "            CHECK(cudaMemcpy(d_flag, flag, (size) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "        }\n",
        "        else {\n",
        "            uint *d_aux, *aux, *d_ogFlag;\n",
        "\n",
        "            uint numSmemBlock = size / smemSize;\n",
        "            uint numBlock = (size + blockDim - 1) / blockDim;\n",
        "            uint gpuScanSize = numSmemBlock * smemSize;\n",
        "            uint residualSize = size - gpuScanSize;\n",
        "\n",
        "            aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
        "\n",
        "            CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
        "            CHECK(cudaMalloc((void **) &d_ogFlag, size * sizeof(uint)));\n",
        "\n",
        "            CHECK(cudaMemcpy(d_ogFlag, flag, (size) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "\n",
        "            CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
        "            CHECK(cudaMemset(d_flag, 0, (size) * sizeof(uint)));\n",
        "\n",
        "            printf(\"\\n  block scan...\\n\");\n",
        "\n",
        "            uint smem = smemSize * sizeof(uint);\n",
        "            printf(\"\\n  first prescan procedure on the Device: %d elements...\\n\", gpuScanSize);\n",
        "            cudaEventRecord(start);\n",
        "            prescan<<<  numSmemBlock, blockDim, smem >>>(d_flag, d_ogFlag, d_aux, size, smemSize);\n",
        "            printf(\"\\n  second scan procedure on the Host: %d elements...\\n\", residualSize);\n",
        "            cpuScan(flag, gpuScanSize, size);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            float milliseconds;\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime = milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            // Copy the contents of the aux array into Host memory and perform another scan\n",
        "            printf(\"\\n  third scan procedure on the Host: %d elements...\\n\", numSmemBlock);\n",
        "            CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "            cudaEventRecord(start);\n",
        "            cpuScan(aux, 0, numSmemBlock + 1);\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime += milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            // Copy the portions of the array computed on the Host to Device memory\n",
        "            CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "            CHECK(cudaMemcpy(&(d_flag[gpuScanSize]), &(flag[gpuScanSize]), residualSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "\n",
        "            printf(\"\\n  final summation procedure...\\n\");\n",
        "            cudaEventRecord(start);\n",
        "            final_sum<<< numBlock, blockDim >>>(d_flag, d_aux, size);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime += milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            printf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", spliTime);\n",
        "\n",
        "            totalTime += spliTime;\n",
        "            CHECK(cudaMemcpy(flag, d_flag, (size) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "\n",
        "            free(aux);\n",
        "            CHECK(cudaFree(d_aux));\n",
        "            CHECK(cudaFree(d_ogFlag));\n",
        "        }\n",
        "\n",
        "        if (DEBUGGING) {\n",
        "            for (uint i = 1; i < size; i++) {\n",
        "                cFlag[i] += cFlag[i - 1];\n",
        "            }\n",
        "\n",
        "            for (uint i = 0; i < size - 1; i++) {\n",
        "                if (cFlag[i] != flag[i + 1]) {\n",
        "                    cout << \"I due array sono diversi in posizione \" << i << endl;\n",
        "                    return -1;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        delete[] cFlag;\n",
        "        cout << \"The contracted graph will contain \" << flag[size - 1] << \" supervertices\\n\\n\" << endl;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Fifth step of the algorithm\n",
        "\n",
        "        // Allocating resources for the new cumulated degrees array\n",
        "        uint newNodeSize = flag[size - 1];\n",
        "        uint cumDegSize = newNodeSize + 1;\n",
        "        uint *cumDegs = new uint[cumDegSize];\n",
        "        uint *d_cumDegs;\n",
        "        CHECK(cudaMalloc((void**)&d_cumDegs, (cumDegSize) * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
        "        /***********************************/\n",
        "\n",
        "        cout << \"Launching kernel CUMULATED DEGREE UPDATE -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        cumulatedDegreeUpdate<<<gridDim, blockDim>>>(str, d_cumDegs, d_colors, d_flag);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        spliTime = milliseconds / 1000.0;\n",
        "        printf(\"Doing the computation of the cumulated degrees took: %.5f seconds\\n\\n\", spliTime);\n",
        "        CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "\n",
        "        // ~Debugging~ looking for errors in the cumulated degrees array\n",
        "        if (DEBUGGING) {\n",
        "            uint *checkDegs = new uint[cumDegSize];\n",
        "            for (uint i = 0; i < cumDegSize; i++) {\n",
        "                checkDegs[i] = 0;\n",
        "            }\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                uint color = colors[i];\n",
        "                node svSuccessor = getRoot(i, flag, colors);\n",
        "                uint sum = 0;\n",
        "\n",
        "                for (uint j = 0; j < str->deg(i); j++) {\n",
        "                    node neigh = str->getNeigh(i, j);\n",
        "                    uint neighColor = colors[neigh];\n",
        "\n",
        "                    if (color != neighColor) {\n",
        "                        sum++;\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                checkDegs[svSuccessor] += sum;\n",
        "            }\n",
        "            for (uint i = 0; i < cumDegSize; i++) {\n",
        "                if (cumDegs[i] != checkDegs[i]) {\n",
        "                    cout << i << \": cumDegs - \" << cumDegs[i] << \"\\tcheckDegs - \" << checkDegs[i] << endl;\n",
        "                    return -1;\n",
        "                }\n",
        "            }\n",
        "            cout << \"The CPU check vector and the GPU computed one are the same\\n\\n\" << endl;\n",
        "            delete[] checkDegs;\n",
        "        }\n",
        "        /********************/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Perform another prefix sum on the cumDegrees array\n",
        "        cout << \"Doing a round of scan on the cumDegs vector, size: \" << cumDegSize << endl;\n",
        "\n",
        "        uint *cCumDegs = new uint[cumDegSize];\n",
        "        for (uint i = 0; i < cumDegSize; i++) {\n",
        "            cCumDegs[i] = cumDegs[i];\n",
        "        }\n",
        "\n",
        "        if (cumDegSize < smemSize) {\n",
        "            cout << \"Resorting to a round of CPU scan\" << endl;\n",
        "            cpuScan(cumDegs, 0, cumDegSize);\n",
        "            CHECK(cudaMemcpy(d_cumDegs, cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "        }\n",
        "        else {\n",
        "            uint *d_aux, *aux, *d_ogCumDegs;\n",
        "\n",
        "            uint numSmemBlock = cumDegSize / smemSize;\n",
        "            uint numBlock = (cumDegSize + blockDim - 1) / blockDim;\n",
        "            uint gpuScanSize = numSmemBlock * smemSize;\n",
        "            uint residualSize = cumDegSize - gpuScanSize;\n",
        "\n",
        "            aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
        "\n",
        "            CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
        "            CHECK(cudaMalloc((void **) &d_ogCumDegs, cumDegSize * sizeof(uint)));\n",
        "\n",
        "            CHECK(cudaMemcpy(d_ogCumDegs, cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "\n",
        "            CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
        "            CHECK(cudaMemset(d_cumDegs, 0, (cumDegSize) * sizeof(uint)));\n",
        "\n",
        "            printf(\"\\n  block scan...\\n\");\n",
        "\n",
        "            uint smem = smemSize * sizeof(uint);\n",
        "            printf(\"\\n  first prescan procedure on the Device: %d elements...\\n\", gpuScanSize);\n",
        "            cudaEventRecord(start);\n",
        "            prescan<<<  numSmemBlock, blockDim, smem >>>(d_cumDegs, d_ogCumDegs, d_aux, size, smemSize);\n",
        "            printf(\"\\n  second scan procedure on the Host: %d elements...\\n\", residualSize);\n",
        "            cpuScan(cumDegs, gpuScanSize, cumDegSize);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            float milliseconds;\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime = milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            // Copy the contents of the aux array into Host memory and perform another scan\n",
        "            printf(\"\\n  third scan procedure on the Host: %d elements...\\n\", numSmemBlock);\n",
        "            CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "            cudaEventRecord(start);\n",
        "            cpuScan(aux, 0, numSmemBlock + 1);\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime += milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            // Copy the portions of the array computed on the Host to Device memory\n",
        "            CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "            CHECK(cudaMemcpy(&(d_cumDegs[gpuScanSize]), &(cumDegs[gpuScanSize]), residualSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "\n",
        "            printf(\"\\n  final summation procedure...\\n\");\n",
        "            cudaEventRecord(start);\n",
        "            final_sum<<< numBlock, blockDim >>>(d_cumDegs, d_aux, cumDegSize);\n",
        "            CHECK(cudaDeviceSynchronize());\n",
        "            CHECK(cudaEventRecord(stop));\n",
        "            CHECK(cudaEventSynchronize(stop));\n",
        "            CHECK(cudaGetLastError());\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            spliTime += milliseconds / 1000.0;\n",
        "            printf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
        "\n",
        "            printf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", spliTime);\n",
        "\n",
        "            totalTime += spliTime;\n",
        "            CHECK(cudaMemcpy(cumDegs, d_cumDegs, (cumDegSize) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "\n",
        "            free(aux);\n",
        "            CHECK(cudaFree(d_aux));\n",
        "            CHECK(cudaFree(d_ogCumDegs));\n",
        "        }\n",
        "\n",
        "        if (DEBUGGING) {\n",
        "            for (uint i = 1; i < cumDegSize; i++) {\n",
        "                cCumDegs[i] += cCumDegs[i - 1];\n",
        "            }\n",
        "\n",
        "            for (uint i = 0; i < cumDegSize - 1; i++) {\n",
        "                if (cCumDegs[i] != cumDegs[i + 1]) {\n",
        "                    cout << \"I due array sono diversi in posizione \" << i << endl;\n",
        "                    cout << cCumDegs[i] << \"   \" << cumDegs[i + 1];\n",
        "                    return -1;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        cout << \"The contracted graph will contain \" << cumDegs[cumDegSize - 1] << \" edges\" << endl;\n",
        "        cout << \"The old graph structure contained \" << str->edgeSize << \" edges\\n\\n\" << endl;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Allocating space for the arrays in the newly contracted graph\n",
        "        uint newEdgeSize = cumDegs[cumDegSize - 1];\n",
        "        node *newNeighs = new node[newEdgeSize];\n",
        "        uint *newWeights = new uint[newEdgeSize];\n",
        "\n",
        "        uint *d_newNeighs, *d_newWeights;\n",
        "        CHECK(cudaMalloc((void **)&d_newNeighs, newEdgeSize * sizeof(node)));\n",
        "        CHECK(cudaMalloc((void **)&d_newWeights, newEdgeSize * sizeof(uint)));\n",
        "        CHECK(cudaMemset(d_newNeighs, 0, newEdgeSize * sizeof(node)));\n",
        "        CHECK(cudaMemset(d_newWeights, 0, newEdgeSize * sizeof(uint)));\n",
        "\n",
        "        cout << \"Launching kernel GRAPH CONSTRUCTION -- (\" << blockDim << \", 1, 1) -- (\" << gridDim << \", 1, 1)\" << endl;\n",
        "        cudaEventRecord(start);\n",
        "        graphContraction<<<gridDim, blockDim>>>(str, d_colors, d_flag, d_cumDegs, d_newNeighs, d_newWeights);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        CHECK(cudaEventRecord(stop));\n",
        "        CHECK(cudaEventSynchronize(stop));\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "        printf(\"The construction of the new neighbour and weight arrays took: %.5f seconds\\n\\n\", milliseconds/1000);\n",
        "        spliTime += milliseconds / 1000.0;\n",
        "        CHECK(cudaMemcpy(newNeighs, d_newNeighs, newEdgeSize * sizeof(node), cudaMemcpyDeviceToHost));\n",
        "        CHECK(cudaMemcpy(newWeights, d_newWeights, newEdgeSize * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "\n",
        "        if (DEBUGGING) {\n",
        "            node *checkNewNeighs = new node[newEdgeSize];\n",
        "            uint *checkNewWeights = new uint[newEdgeSize];\n",
        "            // Copy the contents of cumDegs into a new array\n",
        "            for (uint i = 0; i < cumDegSize; i++) {\n",
        "                cCumDegs[i] = cumDegs[i];\n",
        "            }\n",
        "\n",
        "            cudaEventRecord(start);\n",
        "            for (uint i = 0; i < size; i++) {\n",
        "                uint color = colors[i];\n",
        "                node superVertex = getRoot(i, flag, colors);\n",
        "\n",
        "                for (uint j = 0; j < str->deg(i); j++) {\n",
        "                    node neigh = str->getNeigh(i, j);\n",
        "                    uint neighColor = colors[neigh];\n",
        "\n",
        "                    if (color != neighColor) {\n",
        "                        int weight = str->getWeight(i, j);\n",
        "                        uint position = cCumDegs[superVertex];\n",
        "                        checkNewNeighs[position] = getRoot(neigh, flag, colors);\n",
        "                        checkNewWeights[position] = weight;\n",
        "                        cCumDegs[superVertex]++;\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "\n",
        "            cout << \"I due array sono uguali\" << endl;\n",
        "            delete[] cCumDegs;\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Reconstructing the graph\n",
        "        graphPointer->copyConstructor(newNodeSize, newEdgeSize, newNeighs, newWeights, cumDegs);\n",
        "\n",
        "        //graphPointer->print(true);\n",
        "\n",
        "        printf(\"----------------------------------\\n\\n\");\n",
        "        /***********************************************/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        // Updating the iteration information\n",
        "        totalTime += spliTime;\n",
        "        iterations++;\n",
        "        /*****************************************/\n",
        "\n",
        "\n",
        "        // Cuda memory deallocation\n",
        "        CHECK(cudaFree(d_candidates));\n",
        "        CHECK(cudaFree(d_colors));\n",
        "        CHECK(cudaFree(d_flag));\n",
        "        CHECK(cudaFree(d_cumDegs));\n",
        "        CHECK(cudaFree(d_newNeighs));\n",
        "        CHECK(cudaFree(d_newWeights));\n",
        "        /****************************/\n",
        "\n",
        "        // Host memory deallocation\n",
        "        delete[] candidates;\n",
        "        delete[] colors;\n",
        "        delete[] flag;\n",
        "        delete[] cumDegs;\n",
        "        delete[] newNeighs;\n",
        "        delete[] newWeights;\n",
        "        /******************/\n",
        "    }\n",
        "\n",
        "    printf(\"Total elapsed time: %.5f seconds\\n\\n\", totalTime);\n",
        "    printf(\"The calculation of the MST took %d iterations\\n\\n\", iterations);\n",
        "    printf(\"The total weight of the tree is %d\\n\", mstWeight);\n",
        "\n",
        "\n",
        "    CHECK(cudaEventDestroy(start));\n",
        "    CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "1ki-gfLXKB8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilazione ed esecuzione\n",
        "\n",
        "!nvcc -arch=sm_75 GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu src/GPU/mstGPU.cu -o mstGPU\n",
        "!./mstGPU"
      ],
      "metadata": {
        "id": "dDwnHcvWKIo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as7C0GYCIAQO"
      },
      "source": [
        "# Kernel testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHkAGz_qIEP_"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save --name \"scanTesting.cu\" --group \"TESTING\"\n",
        "\n",
        "// Header file di C++\n",
        "#include <iostream>\n",
        "\n",
        "// Header file C\n",
        "#include <time.h>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "\n",
        "// Custom files\n",
        "#include \"../../GPUcomputing/utils/common.h\"\n",
        "#include \"../COMMON/sharedMacros.h\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void prescan(uint *g_odata, uint *g_idata, uint *aux, int n, int smemSize)\n",
        "{\n",
        "  extern __shared__ int temp[];// allocated on invocation\n",
        "  int thid = threadIdx.x;\n",
        "  int offset = 1;\n",
        "  int idx = blockIdx.x * blockDim.x + thid;\n",
        "\n",
        "  temp[2*thid] = g_idata[2*idx]; // load input into shared memory\n",
        "  temp[2*thid+1] = g_idata[2*idx+1];\n",
        "\n",
        "  for (int d = n>>1; d > 0; d >>= 1) // build sum in place up the tree\n",
        "  {\n",
        "    __syncthreads();\n",
        "    if (thid < d)\n",
        "    {\n",
        "      int ai = offset*(2*thid+1)-1;\n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      if (bi < smemSize && ai < smemSize) {\n",
        "        temp[bi] += temp[ai];\n",
        "      }\n",
        "    }\n",
        "    offset *= 2;\n",
        "  }\n",
        "\n",
        "  if (thid == 0)\n",
        "  {\n",
        "    aux[blockIdx.x] = temp[smemSize - 1];\n",
        "    temp[smemSize - 1] = 0;\n",
        "  } // clear the last element\n",
        "\n",
        "  for (int d = 1; d < n; d *= 2) // traverse down tree & build scan\n",
        "  {\n",
        "    __syncthreads();\n",
        "    if (thid < d && offset > 0)\n",
        "    {\n",
        "      int ai = offset*(2*thid+1)-1;\n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      if (bi < smemSize && ai < smemSize) {\n",
        "        int t = temp[ai];\n",
        "        temp[ai] = temp[bi];\n",
        "        temp[bi] += t;\n",
        "      }\n",
        "    }\n",
        "    offset >>= 1;\n",
        "  }\n",
        "\n",
        "\n",
        "  __syncthreads();\n",
        "  if (idx <= (n / 2) - 1) {\n",
        "      g_odata[2*idx] = temp[2*thid]; // write results to device memory\n",
        "      g_odata[2*idx+1] = temp[2*thid+1];\n",
        "  }\n",
        "}\n",
        "\n",
        "void cpuScan(uint *array, int start, int end) {\n",
        "    if (end - start <= 1) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    int temp = array[start + 1];\n",
        "    array[start + 1] = array[start];\n",
        "    array[start] = 0;\n",
        "\n",
        "    for (uint i = start + 1; i < end - 1; i++) {\n",
        "        int sum = array[i] + temp;\n",
        "        temp = array[i + 1];\n",
        "        array[i + 1] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void final_sum(uint *g_odata, uint *aux, uint n)\n",
        "{\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "  if (blockIdx.x == 0 || 2 * idx >= n) {\n",
        "      return;\n",
        "  }\n",
        "\n",
        "  //printf(\"%d: ls - %d  rs - %d  aux - %d\\n\", idx, g_odata[2 * idx], g_odata[2 * idx + 1], aux[blockIdx.x - 1]);\n",
        "\n",
        "  if (2 * idx == n - 1) {\n",
        "      g_odata[2 * idx] += aux[blockIdx.x];\n",
        "      return;\n",
        "  }\n",
        "  g_odata[2 * idx] += aux[blockIdx.x];\n",
        "  g_odata[2 * idx + 1] += aux[blockIdx.x];\n",
        "}\n",
        "\n",
        "\n",
        "/*\n",
        " * MAIN: test on parallel reduction\n",
        " */\n",
        "int main(void) {\n",
        "  uint *cpuArray, *gpuArray, *d_gpuArray, *gpuOutput, *d_gpuOutput, *aux, *d_aux;\n",
        "  uint blockSize = 1024;\n",
        "  uint smemSize = 2 * blockSize;\n",
        "  uint n = 987423564;\n",
        "\n",
        "  uint numSmemBlock = n / smemSize;\n",
        "  uint numBlock = (n + blockSize - 1) / blockSize;\n",
        "  uint gpuScanSize = numSmemBlock * smemSize;\n",
        "  uint residualSize = n - gpuScanSize;\n",
        "\n",
        "  // Memory allocation for the Host side\n",
        "  cpuArray = (uint *) malloc(n * sizeof(uint));\n",
        "  gpuArray = (uint *) malloc(n * sizeof(uint));\n",
        "  gpuOutput = (uint *) malloc(n * sizeof(uint));\n",
        "  aux = (uint *) malloc((numSmemBlock + 1) * sizeof(uint));\n",
        "\n",
        "  // Memory allocation for the Device side\n",
        "  CHECK(cudaMalloc((void **) &d_gpuArray, gpuScanSize * sizeof(uint)));\n",
        "  CHECK(cudaMalloc((void **) &d_gpuOutput, n * sizeof(uint)));\n",
        "  CHECK(cudaMalloc((void **) &d_aux, (numSmemBlock + 1) * sizeof(uint)));\n",
        "\n",
        "  printf(\"\\n****  test on parallel scan  ****\\n\");\n",
        "\tprintf(\"  Vector length: %d\\n\", n);\n",
        "\n",
        "  cudaEvent_t start, stop;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEventCreate(&stop);\n",
        "\n",
        "  // Generate the original array\n",
        "  srand(0);\n",
        "\tfor (uint i = 0; i < n; i++){\n",
        "     cpuArray[i] = 1;\n",
        "     gpuArray[i] = cpuArray[i];\n",
        "  }\n",
        "\n",
        "\tprintf(\"\\n  CPU procedure...\\n\");\n",
        "\tdouble go = seconds();\n",
        "  for (uint i = 1; i < n; i++) {\n",
        "      cpuArray[i] += cpuArray[i - 1];\n",
        "  }\n",
        "\tdouble CPUtime = seconds() - go;\n",
        "\tprintf(\"    Elapsed time: %f (sec) \\n\", CPUtime);\n",
        "\n",
        "  // Copy the contents of gpuArray in the Device memory\n",
        "  CHECK(cudaMemcpy(d_gpuArray, gpuArray, gpuScanSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "  CHECK(cudaMemset(d_aux, 0, (numSmemBlock + 1) * sizeof(uint)));\n",
        "\n",
        "  printf(\"\\n  block scan...\\n\");\n",
        "\n",
        "  uint smem = smemSize * sizeof(uint);\n",
        "  printf(\"\\n  first prescan procedure on the Device: %d elements...\\n\", gpuScanSize);\n",
        "  cudaEventRecord(start);\n",
        "  prescan<<<  numSmemBlock, blockSize, smem >>>(d_gpuOutput, d_gpuArray, d_aux, n, smemSize);\n",
        "  printf(\"\\n  second scan procedure on the Host: %d elements...\\n\", residualSize);\n",
        "  cpuScan(gpuArray, gpuScanSize, n);\n",
        "  CHECK(cudaDeviceSynchronize());\n",
        "\tCHECK(cudaEventRecord(stop));\n",
        "\tCHECK(cudaEventSynchronize(stop));\n",
        "\tCHECK(cudaGetLastError());\n",
        "  float milliseconds;\n",
        "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\tdouble GPUtime = milliseconds / 1000.0;\n",
        "\tprintf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
        "\n",
        "  // Copy the contents of the aux array into Host memory and perform another scan\n",
        "  printf(\"\\n  third scan procedure on the Host: %d elements...\\n\", numSmemBlock);\n",
        "  CHECK(cudaMemcpy(aux, d_aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "  cudaEventRecord(start);\n",
        "  cpuScan(aux, 0, numSmemBlock + 1);\n",
        "  CHECK(cudaEventRecord(stop));\n",
        "  CHECK(cudaEventSynchronize(stop));\n",
        "  CHECK(cudaGetLastError());\n",
        "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\tGPUtime += milliseconds / 1000.0;\n",
        "\tprintf(\"   elapsed time:   %.5f (sec)\\n\", milliseconds / 1000.0);\n",
        "\n",
        "  // Copy the portions of the array computed on the Host to Device memory\n",
        "  CHECK(cudaMemcpy(d_aux, aux, (numSmemBlock + 1) * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "  CHECK(cudaMemcpy(&(d_gpuOutput[gpuScanSize]), &(gpuArray[gpuScanSize]), residualSize * sizeof(uint), cudaMemcpyHostToDevice));\n",
        "\n",
        "  printf(\"\\n  final summation procedure...\\n\");\n",
        "  cudaEventRecord(start);\n",
        "  final_sum<<< numBlock, blockSize >>>(d_gpuOutput, d_aux, n);\n",
        "  CHECK(cudaDeviceSynchronize());\n",
        "\tCHECK(cudaEventRecord(stop));\n",
        "\tCHECK(cudaEventSynchronize(stop));\n",
        "\tCHECK(cudaGetLastError());\n",
        "\tcudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\tGPUtime += milliseconds / 1000.0;\n",
        "\tprintf(\"   elapsed time:   %.5f (sec)\\n\\n\", milliseconds / 1000.0);\n",
        "\n",
        " \tprintf(\"\\nTotal elapsed time:   %.5f (sec)\\n\", GPUtime);\n",
        "\n",
        "\tdouble speedup = CPUtime/GPUtime;\n",
        "\tprintf(\"    Speedup %.1f\\n\", speedup);\n",
        "\n",
        "  CHECK(cudaMemcpy(gpuOutput, d_gpuOutput, n * sizeof(uint), cudaMemcpyDeviceToHost));\n",
        "\n",
        "\n",
        "  for (uint i = 0; i < n - 1; i++) {\n",
        "      if (gpuOutput[i + 1] != cpuArray[i]) {\n",
        "          printf(\"%d: %d\\t%d\\n\", i - 1, gpuOutput[i - 1], cpuArray[i - 1]);\n",
        "          printf(\"%d: %d\\t%d\\n\", i, gpuOutput[i], cpuArray[i]);\n",
        "          printf(\"%d: %d\\t%d\\n\", i + 1, gpuOutput[i + 1], cpuArray[i + 1]);\n",
        "          return -1;\n",
        "      }\n",
        "  }\n",
        "\n",
        "  printf(\"%d - %d\\n\", gpuOutput[n - 1], cpuArray[n - 2]);\n",
        "  printf(\"È andato tutto bene\\n\");\n",
        "\n",
        "  // Host memory deallocation\n",
        "  free(cpuArray);\n",
        "  free(gpuArray);\n",
        "  free(gpuOutput);\n",
        "  free(aux);\n",
        "\n",
        "  // Device memory deallocation\n",
        "  CHECK(cudaFree(d_gpuArray));\n",
        "  CHECK(cudaFree(d_gpuOutput));\n",
        "  CHECK(cudaFree(d_aux));\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2vSA87DOeCr",
        "outputId": "bb9994b0-0b02-4b91-c147-dee5a99e2c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "****  test on parallel scan  ****\n",
            "  Vector length: 987423564\n",
            "\n",
            "  CPU procedure...\n",
            "    Elapsed time: 2.873964 (sec) \n",
            "\n",
            "  block scan...\n",
            "\n",
            "  first prescan procedure on the Device: 987422720 elements...\n",
            "\n",
            "  second scan procedure on the Host: 844 elements...\n",
            "   elapsed time:   0.31906 (sec)\n",
            "\n",
            "  third scan procedure on the Host: 482140 elements...\n",
            "   elapsed time:   0.00198 (sec)\n",
            "\n",
            "  final summation procedure...\n",
            "   elapsed time:   0.03480 (sec)\n",
            "\n",
            "\n",
            "Total elapsed time:   0.35583 (sec)\n",
            "    Speedup 8.1\n",
            "987423563 - 987423563\n",
            "È andato tutto bene\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 src/TESTING/scanTesting.cu -o scanTesting\n",
        "!./scanTesting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1k1xuRwgC9t"
      },
      "source": [
        "# Python Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "csPluGuggFuM",
        "outputId": "92b2d74a-47d7-4349-d945-ef87acb6e73f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/testing/primTest.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-174-d3a469f194a9>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mresultsGPU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/testing/gpuTest.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpointerCPU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultsCPU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/testing/primTest.txt'"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "resultsCPU = \"/content/testing/primTest.txt\"\n",
        "resultsGPU = \"/content/testing/gpuTest.txt\"\n",
        "\n",
        "pointerCPU = open(resultsCPU, \"r\")\n",
        "\n",
        "sizes = []\n",
        "times = []\n",
        "\n",
        "bar_width = 0.35\n",
        "bar_spacing = 0.5\n",
        "\n",
        "for line in pointerCPU:\n",
        "    splitLine = re.split(\",\", line)\n",
        "    size = splitLine[0]\n",
        "    time = float(splitLine[2])\n",
        "    sizes.append(size)\n",
        "    times.append(time)\n",
        "\n",
        "logTimes = np.log2(times)\n",
        "indices = np.arange(len(sizes)) * (1 + bar_spacing)\n",
        "\n",
        "plt.bar(indices, logTimes, width=bar_width, edgecolor=\"white\", linewidth=1,\n",
        "        label=\"CPU\")\n",
        "\n",
        "pointerGPU = open(resultsGPU, \"r\")\n",
        "\n",
        "sizes = []\n",
        "times = []\n",
        "\n",
        "for line in pointerGPU:\n",
        "    splitLine = re.split(\",\", line)\n",
        "    size = splitLine[0]\n",
        "    time = float(splitLine[2])\n",
        "    sizes.append(size)\n",
        "    times.append(time)\n",
        "\n",
        "logTimes = np.log2(times)\n",
        "indices = np.arange(len(sizes)) * (1 + bar_spacing) + bar_width\n",
        "\n",
        "\n",
        "plt.bar(indices, logTimes, width=bar_width, edgecolor=\"white\", color=\"green\",\n",
        "        linewidth=1, label=\"GPU\")\n",
        "plt.xticks(indices - (bar_width / 2), sizes)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "close(pointerCPU)\n",
        "close(pointerGPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InyO4kjwqjdO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "0Y_SjlAhe6L-",
        "FmgJ3ZD9TZka",
        "fEIZ7tyYPNfB",
        "6OLIQlpVKwJZ",
        "RKuIUG8HKquY",
        "AlgeSiIHTcFA",
        "4KqoBgM--a13",
        "v1k1xuRwgC9t"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}