\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{src/preamble}
\usepackage[
	backend=biber,
	maxalphanames=10,
]{biblatex}
\bibliography{bibliography.bib}

\begin{document}

\noindent
\begin{center}
	\textbf{{PARALLEL SOLUTION FOR THE MST PROBLEM}} \\
\end{center}

\noindent
\textbf{Author: Alessandro Biagiotti} \hfill \textit{Milan university}
\\

\noindent
\textbf{ABSTRACT:}
\\

\noindent
\textbf{KEYWORDS:}
\\

\noindent
\textbf{STATEMENT OF ORIGINALITY:}

\bigskip

\phantomsection
\makeatletter\def\@currentlabel{\texttt{(I)}}\makeatother
\label{sec:intro}
\noindent
\textbf{INTRODUCTION TO THE PROBLEM:}
\\
The Minimum Spanning Tree Problem (\mstp for short) is a problem that has been studied for years and to this day finds many real world applications,to name a few:
\begin{enumerate}
	\item It's possible to find different \mst-based techniques that can be used to do image segmentation~\cite{maze-generation}~\cite{mst-segmentation-heuristic}.
	\item Finding the \mst allows us to solve the Clustering problem, all we need to do is to compute an \mst and then drop the $k - 1$ most expensive edges of the \mst~\cite{mst-applications}.
	\item Finding the \mst is an important step of Christofides's algorithm, which is a 2-approximation for the widely known Travelling Salesman Problem (\textsc{Tsp} for short)~\cite{tsp-christofides}.
\end{enumerate}

Many different solutions have been found for the problem in the years, the more basic implementations were Prim's~\cite{prim-algorithm} and Kruskal's~\cite{kruskal-algorithm}.

Prim's algorithm is the simplest solver for \mstp, given a graph $G= (V, E)$, let us suppose that the size of the graph $|V|$ is $n$ and the number of edges $|E|$ is $m$, then, based on the implementation, the computational complexity ranges between the following values:
\begin{itemize}
	% TODO Fix the ï not showing properly
	\item Naïve implementation: $\O(n^2)$
	\item Binary heap and adjacency list: $\O(m\log{n})$
	\item Fibonacci heap and adjacency list: $\O(m + n\log{n})$
\end{itemize}
In my implementation I have implemented both the Naïve version and the one using a binary heap, more on this in the next section.

Kruskal's algorithm is the alternative to Prim's algorithm and it works in time $\O(m\log{m})$ if implemented using classical data structures.

\brka's algorithm is a solver for the \mstp based on forests, a more verbose version of the algorithm shown in~\cite{boruvka-pseudocode} can be seen in~\ref{algo:boruvka-pseudocode}
\begin{algorithm}
	\caption{\brka's algorithm}
	\label{algo:boruvka-pseudocode}
	\begin{algorithmic}[1]
		\REQUIRE An undirected, connected and weighted graph $G$, a set of empty edges $T$
		\ENSURE An \mst$T$ built on graph $G$
		\WHILE{vertices in $G$ connected by $T$ are disjoint}
			\STATE start with an empty set of edges $E$
			\FOR{every connected component}
				\STATE start with an empty set of edges $S$
				\FOR{every vertex $v$ in the component}
					\STATE add the cheapest edge going from $v$ to any other component to $S$
				\ENDFOR
				\STATE add the cheapest edge in $S$ to $E$
			\ENDFOR
			\STATE add the set of edges from $E$ to $T$ 
		\ENDWHILE
		\STATE\RETURN $T$
	\end{algorithmic}
\end{algorithm}

Let us suppose that the size of the graph $|V|$ is $n$ and the number of edges $E$ is $m$, then the computational complexity of the pseudocode shown in~\ref{algo:boruvka-pseudocode} is $\O(m\log{n})$. This algorithm has been later reused in combination with other techniques to compute a solution for the \mstp very efficiently~\cite{boruvka-ackermann}~\cite{karger-klein-tarjan}. As for the solutions previously proposed for the sequential resolution of the problem there is different parallel implementations that are based on \brka's solution, this is due to the inherent parallelizability of the algorithm.

Regardless of the implementation the core of the algorithm can be identified in the following four steps as identified in~\cite{boruvka-steps}:
\begin{enumerate}
	\item\label{item:first-step} (\textit{choose lightest}) for every vertex the lightest edge is chosen in parallel.
	\item\label{item:second-step} (\textit{find root}) for every vertex we find the root of the tree to which it belongs\footnote{It's important to keep in mind that vertices are actually supervertices.}.
	\item\label{item:third-step} (\textit{rename vertices}) Since the graph after~\ref{item:fourth-step} is compressed, which means that the number of vertices decreases, then the roots in the graph need to be renamed. 
	\item\label{item:fourth-step} (\textit{graph compression}) The graph undergoes a compression step, the result a compressed version of the graph containing only the roots identified in~\ref{item:second-step} and the edges that connect a component $C_i$ to any other component $C_j$, therefore the graph only loses the edges contained in the original graph.
\end{enumerate}

The specific implementation that I chose to follow is shown in~\cite{generic-he-boruvka} and is summarized by algorithm~\ref{algo:boruvka-parallel}

\begin{algorithm}
	\caption{\brka's algorithm}
	\label{algo:boruvka-parallel}
	\begin{algorithmic}[1]
		\REQUIRE An undirected, connected and weighted graph $G(V, E)$
		\ENSURE An \mst$T$ built on graph $G$
		\WHILE{$|V| > 1$}
			\STATE find the minimum edge per vertex (\ref{item:first-step})
			\STATE remove mirrored edges
			\STATE initialize the colors
			\WHILE{the coloring hasn't converged}
				\STATE color propagation (\ref{item:second-step})
			\ENDWHILE
			\STATE create new vertex ids (\ref{item:third-step})
			\STATE do graph compression (\ref{item:fourth-step})
		\ENDWHILE
		\STATE\RETURN $G$
	\end{algorithmic}
\end{algorithm}

The graph returned in the last step is a single supervertex containing the \mst.

\bigskip
\phantomsection
\makeatletter\def\@currentlabel{\texttt{(II)}}\makeatother
\label{sec:graph-structure}
\noindent
\textbf{GRAPH STRUCTURE:}
\\

\bigskip
\phantomsection
\makeatletter\def\@currentlabel{\texttt{(III)}}\makeatother
\label{sec:cpu-implementation}
\noindent
\textbf{CPU IMPLEMENTATION:}
\\
I will not cover at length the CPU implementation since it's quite straightforward, at first I opted
for an extremely naive implementation of Prim's algorithm, consisting of two \texttt{for} cycles.
Since the implementation worked but was in fact extremely slow if compared to finer solvers I
decided to scrap it in favour of a more efficient implementation of the Prim's algorithm based on
the use of a simple heap to sort the edges needed to build the \mst.

As I showed in~\ref{sec:intro} the time complexity of Prim's solver thus implemented is $\O(m \cdot
\log{n})$. I decided to implement Prim's algorithm instead of \brka's solver since the first one is
much simpler as far as efficiency goes the two solvers have comparable speeds.

\bigskip
\phantomsection
\makeatletter\def\@currentlabel{\texttt{(IV)}}\makeatother
\label{sec:gpu-implementation}
\noindent
\textbf{GPU IMPLEMENTATION:}
\\
As far as the GPU implementation goes I chose to follow, as I alluded to in ~\ref{sec:intro}, the
implementation in \cite{generic-he-boruvka} which is meant to be a highly generic and highly
efficient parallel variant of \brka's solver to implement on the GPU.

Provided that I do not have enough knowledge in the field to reliably criticize somebody else's work
in the field I can state that the solution they provide is not as general as the authors want it to
be. The reason behind my statement is hidden in how the solution is computed. Per
\cite{generic-he-boruvka} every part of the solution can be implemented as a distinct kernel
containing a thread per vertex (such an approach is referred to as \textit{topologic} in the
literature)
\begin{enumerate}
	\item\label{item:choose-lightest} (\textit{choose lightest}) this operation picks the
		lightest connection for every vertex to the neighbourhood by simpling cycling over
		the outgoing edges, to have improved locality if two edges share the same weight pick the one with the destination id. The results are stored in the \texttt{d\_candidates} array.
	\item\label{item:mirror-removal} (\textit{Remove mirrored edges}) this operation is meant to
		remove cycles from the graph. To understand how it works let's suppose for a moment
		that the candidate edge for vertex $v$ is $(v, u)$, let's now suppose that the
		candidate edge for $u$ is the mirrored edge $(u, v)$, then the kernel will replace
		$(v, u)$ contained in \texttt{d\_candidates} with the default value
		\texttt{UINT\_MAX}.
	\item\label{item:coloration} (\textit{Initialize and propagate the colors}) this operation
		is meant to identify the connected components inside the graph and can be
		implemented as a recursive procedure having a kernel as the recursion head and then
		a series of \texttt{\_\_device\_\_} function calls to propagate the colors in the nodes.
	\item\label{item:vertex-rename} (\textit{Create new vertex ids}) to rename the vertices a
		new array is created (in my implementation is \texttt{d\_flag}) that contains a $0$
		in every position where the color of the vertex is different from the vertex id and
		a $1$ otherwise.
		
		To understand why the re-labelling is necessary we can consider for instance a graph
		in which we only have $2$ colors but one of the colored vertices is $0$ and the
		other one is $750$, if the vertex id did not change some other technique would need
		to be invented to solve the next step.
	\item\label{item:graph-contraction} (\textit{Count, assign and insert new edges}) this
		operation needs to be split in a series of simpler kernels
		\begin{itemize}
			\item\label{item:count-edges} (\textit{Count edges}) A simple kernel will be
				going through the neighbourhood of every vertex and it compares the
				color of the vertex with the color of the supervertex of the
				destination. If the colors are different it means that the two
				supervertices belong to different components.

				The result of the process will be cumulated inside an array (in my
				implementation is \texttt{d\_cumDegs})

				Afterwards a scan procedure is computed on the \texttt{d\_cumDegs}
				array, the result is going to be a fully functioning cumulated
				degree array as shown in ~\ref{sec:graph-structure}.
			\item\label{item:graph-regen} (\textit{Graph regeneration}) This step
				generates the new neighbour and weight array, this is done by
				visiting every neighbour for every vertex as shown in
				~\ref{item:count-edges}. Edges intra-component are removed while
				duplicated ones are kept because it's easier than handling their removal.
		\end{itemize}
\end{enumerate}
Most of the kernels proposed in the solution can be written as \texttt{for} loops that go through
the various neighbours in the adjacency lists, while this solution works well (as will be shown in a
future section) the results for this kind of approach are far from generalizable whenever the graph
structure is not uniform. Even if the implementation uses texture memory to increment memory access
speeds ~\cite{gpu-programming-cuda} for the fundamental arrays shown in ~\ref{sec:graph-structure}, 
due to the strong locality of the memory accesses, the solver's performance suffer deeply because of 
the non-uniformity of the graph structure because it makes some cycles within the kernels to have a 
longer runtime compared to others and this implies a very strong imbalance in the work of the threads.



\begin{enumerate}
	\item The solution originally written for the CPU could not keep up with the GPU solver I therefore implemented a small Heap class that was able to move the CPU solver to the next level
	\item The GPU implementation found itself struggling essentially because of the nature of the problem and the not-so-efficient implementation
	\item Changed the GPU implementation to use an hybrid of CPU code and GPU kernels, the CPU code is used in settings such as the scan, which is more efficient than using a naive GPU kernel, as well as the contraction operation
	\item Reimplemented the contraction operation using a GPU kernel and I obtained a minor speedup. The GPU performance is still far inferior if compared with the efficient CPU version that I talked about earlier
	\item Reimplemented the scan operation to work in a work efficient way, as a source I used the preprefix file and implemented the various sequential operations in a naïve way.
	\item Reimplemented the fifth step of the algorithm, changed the logic from topological (one thread per vertex) to data centered (one thread per edge) each thread goes through a binary search of the origin of the edge in the cumDegs array.
\end{enumerate}

\bigskip
\phantomsection
\makeatletter\def\@currentlabel{\texttt{(II)}}\makeatother
\label{sec:parallel-scan}
\noindent
\textbf{EXCLUSIVE PARALLEL SCAN IMPLEMENTATION:}
\\

\bigskip
\phantomsection
\makeatletter\def\@currentlabel{\texttt{(III)}}\makeatother
\label{sec:performance-analysis}
\noindent
\textbf{PERFORMANCE ANALYSIS:}
\\

\bigskip
\phantomsection
\makeatletter\def\@currentlabel{\texttt{(IV)}}\makeatother
\label{sec:final-thoughts}
\noindent
\textbf{FINAL THOUGHTS:}
\\

\clearpage

\printbibliography

\end{document}
